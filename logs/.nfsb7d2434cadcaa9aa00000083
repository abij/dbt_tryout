2020-11-18 14:51:07.313325 (MainThread): Running with dbt=0.18.1
2020-11-18 14:51:07.643926 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.rpc.server.RPCServerTask'>, debug=False, defer=None, exclude=None, host='0.0.0.0', log_cache_events=False, log_format='default', models=None, partial_parse=True, port=8580, profile='user', profiles_dir='/usr/src/develop/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, state=None, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, use_colors=None, vars='{}', version_check=True, warn_error=False, which='rpc', write_json=True)
2020-11-18 14:51:07.658613 (MainThread): Tracking: tracking
2020-11-18 14:51:07.671427 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8c8ea58>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8ca5630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8ca55f8>]}
2020-11-18 14:51:07.671954 (MainThread): Serving RPC server at 0.0.0.0:8580, pid=14
2020-11-18 14:51:07.672593 (MainThread): Supported methods: ['cli_args', 'compile', 'compile_sql', 'deps', 'docs.generate', 'gc', 'get-manifest', 'kill', 'poll', 'ps', 'run', 'run-operation', 'run_sql', 'seed', 'snapshot', 'snapshot-freshness', 'status', 'test']
2020-11-18 14:51:07.673013 (MainThread): Send requests to http://localhost:8580/jsonrpc
2020-11-18 14:51:07.682041 (Thread-1): Parsing macros/adapters.sql
2020-11-18 14:51:07.704621 (Thread-1): Parsing macros/etc.sql
2020-11-18 14:51:07.706070 (Thread-1): Parsing macros/catalog.sql
2020-11-18 14:51:07.712207 (Thread-1): Parsing macros/materializations/table.sql
2020-11-18 14:51:07.722631 (Thread-1): Parsing macros/materializations/view.sql
2020-11-18 14:51:07.725612 (Thread-1): Parsing macros/materializations/copy.sql
2020-11-18 14:51:07.730881 (Thread-1): Parsing macros/materializations/seed.sql
2020-11-18 14:51:07.733860 (Thread-1): Parsing macros/materializations/incremental.sql
2020-11-18 14:51:07.747640 (Thread-1): Parsing macros/materializations/snapshot.sql
2020-11-18 14:51:07.753886 (Thread-1): Parsing macros/core.sql
2020-11-18 14:51:07.758313 (Thread-1): Parsing macros/adapters/common.sql
2020-11-18 14:51:07.805459 (Thread-1): Parsing macros/materializations/helpers.sql
2020-11-18 14:51:07.815400 (Thread-1): Parsing macros/materializations/table/table.sql
2020-11-18 14:51:07.822887 (Thread-1): Parsing macros/materializations/seed/seed.sql
2020-11-18 14:51:07.845532 (Thread-1): Parsing macros/materializations/view/view.sql
2020-11-18 14:51:07.852305 (Thread-1): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 14:51:07.857791 (Thread-1): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 14:51:07.859877 (Thread-1): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 14:51:07.866396 (Thread-1): Parsing macros/materializations/common/merge.sql
2020-11-18 14:51:07.881096 (Thread-1): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 14:51:07.898839 (Thread-1): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 14:51:07.900882 (Thread-1): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 14:51:07.931463 (Thread-1): Parsing macros/schema_tests/relationships.sql
2020-11-18 14:51:07.933698 (Thread-1): Parsing macros/schema_tests/not_null.sql
2020-11-18 14:51:07.935478 (Thread-1): Parsing macros/schema_tests/unique.sql
2020-11-18 14:51:07.937434 (Thread-1): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 14:51:07.940381 (Thread-1): Parsing macros/etc/get_custom_database.sql
2020-11-18 14:51:07.942232 (Thread-1): Parsing macros/etc/query.sql
2020-11-18 14:51:07.943367 (Thread-1): Parsing macros/etc/datetime.sql
2020-11-18 14:51:07.953167 (Thread-1): Parsing macros/etc/get_custom_alias.sql
2020-11-18 14:51:07.954494 (Thread-1): Parsing macros/etc/is_incremental.sql
2020-11-18 14:51:07.956381 (Thread-1): Parsing macros/etc/get_custom_schema.sql
2020-11-18 14:51:08.033723 (Thread-1): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 14:51:08.065732 (Thread-1): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 14:51:08.084102 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 14:51:08.102620 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 14:51:08.122691 (Thread-1): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 14:51:08.147723 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 14:51:08.167094 (Thread-1): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 14:51:08.186848 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 14:51:08.216601 (Thread-1): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 14:51:08.239385 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 14:51:08.260081 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 14:51:08.279447 (Thread-1): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 14:51:08.301842 (Thread-1): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 14:51:08.321108 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 14:51:08.341271 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 14:51:08.362125 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 14:51:08.381832 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 14:51:08.402229 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 14:51:08.422543 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 14:51:08.443205 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 14:51:08.463492 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 14:51:08.484232 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 14:51:08.504839 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 14:51:08.525020 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 14:51:08.768364 (Thread-2): handling status request
2020-11-18 14:51:08.779261 (Thread-2): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82aedd8>]}
2020-11-18 14:51:08.792362 (Thread-2): sending response (<Response 184 bytes [200 OK]>) to 10.0.21.190
2020-11-18 14:51:09.578234 (Thread-1): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github
- models.github.intermediate

2020-11-18 14:51:11.309795 (Thread-3): handling status request
2020-11-18 14:51:11.310312 (Thread-3): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82ba588>]}
2020-11-18 14:51:11.318364 (Thread-3): sending response (<Response 16806 bytes [200 OK]>) to 10.0.41.79
2020-11-18 14:51:37.650783 (Thread-4): handling status request
2020-11-18 14:51:37.652836 (Thread-4): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82bad30>]}
2020-11-18 14:51:37.659419 (Thread-4): sending response (<Response 16806 bytes [200 OK]>) to 10.0.23.22
2020-11-18 14:51:37.663664 (Thread-5): handling status request
2020-11-18 14:51:37.664072 (Thread-5): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82617f0>]}
2020-11-18 14:51:37.670552 (Thread-5): sending response (<Response 16806 bytes [200 OK]>) to 10.0.14.186
2020-11-18 14:51:38.040108 (Thread-6): handling cli_args request
2020-11-18 14:51:38.040642 (Thread-6): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8473550>]}
2020-11-18 14:51:38.052305 (Thread-6): Connection 'model.github_source.stg_github_pull_request_review' was properly closed.
2020-11-18 14:51:39.089812 (Thread-6): sending response (<Response 137 bytes [200 OK]>) to 10.0.14.29
2020-11-18 14:51:39.161621 (MainThread): Partial parsing not enabled
2020-11-18 14:51:39.163137 (MainThread): Parsing macros/adapters.sql
2020-11-18 14:51:39.184019 (MainThread): Parsing macros/etc.sql
2020-11-18 14:51:39.185579 (MainThread): Parsing macros/catalog.sql
2020-11-18 14:51:39.191786 (MainThread): Parsing macros/materializations/table.sql
2020-11-18 14:51:39.202435 (MainThread): Parsing macros/materializations/view.sql
2020-11-18 14:51:39.205507 (MainThread): Parsing macros/materializations/copy.sql
2020-11-18 14:51:39.210162 (MainThread): Parsing macros/materializations/seed.sql
2020-11-18 14:51:39.213136 (MainThread): Parsing macros/materializations/incremental.sql
2020-11-18 14:51:39.226834 (MainThread): Parsing macros/materializations/snapshot.sql
2020-11-18 14:51:39.229856 (MainThread): Parsing macros/core.sql
2020-11-18 14:51:39.233801 (MainThread): Parsing macros/adapters/common.sql
2020-11-18 14:51:39.279702 (MainThread): Parsing macros/materializations/helpers.sql
2020-11-18 14:51:39.289550 (MainThread): Parsing macros/materializations/table/table.sql
2020-11-18 14:51:39.297181 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-11-18 14:51:39.319439 (MainThread): Parsing macros/materializations/view/view.sql
2020-11-18 14:51:39.326366 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 14:51:39.331827 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 14:51:39.333935 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 14:51:39.340739 (MainThread): Parsing macros/materializations/common/merge.sql
2020-11-18 14:51:39.356779 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 14:51:39.374410 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 14:51:39.380450 (Thread-7): handling poll request
2020-11-18 14:51:39.380996 (Thread-7): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3742358>]}
2020-11-18 14:51:39.376433 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 14:51:39.386913 (Thread-7): sending response (<Response 6319 bytes [200 OK]>) to 10.0.21.190
2020-11-18 14:51:39.406491 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-11-18 14:51:39.408740 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-11-18 14:51:39.410518 (MainThread): Parsing macros/schema_tests/unique.sql
2020-11-18 14:51:39.412428 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 14:51:39.415355 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-11-18 14:51:39.417241 (MainThread): Parsing macros/etc/query.sql
2020-11-18 14:51:39.418442 (MainThread): Parsing macros/etc/datetime.sql
2020-11-18 14:51:39.427919 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-11-18 14:51:39.429018 (MainThread): Parsing macros/etc/is_incremental.sql
2020-11-18 14:51:39.430814 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-11-18 14:51:39.442236 (MainThread): Partial parsing not enabled
2020-11-18 14:51:39.494890 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 14:51:39.525519 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 14:51:39.542552 (MainThread): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 14:51:39.560122 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 14:51:39.579286 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 14:51:39.603844 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 14:51:39.621542 (MainThread): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 14:51:39.640554 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 14:51:39.669701 (MainThread): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 14:51:39.699922 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 14:51:39.728433 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 14:51:39.754484 (MainThread): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 14:51:39.777709 (MainThread): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 14:51:39.795680 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 14:51:39.814326 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 14:51:39.833602 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 14:51:39.852072 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 14:51:39.870387 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 14:51:39.888268 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 14:51:39.906175 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 14:51:39.923852 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 14:51:39.941982 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 14:51:39.960700 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 14:51:39.979045 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 14:51:40.774068 (Thread-8): handling poll request
2020-11-18 14:51:40.774576 (Thread-8): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37b7a58>]}
2020-11-18 14:51:40.779207 (Thread-8): sending response (<Response 11066 bytes [200 OK]>) to 10.0.41.79
2020-11-18 14:51:40.937259 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github.intermediate
- models.github

2020-11-18 14:51:41.178949 (MainThread): Found 24 models, 26 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 11 sources
2020-11-18 14:51:41.191052 (MainThread): 
2020-11-18 14:51:41.191661 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 14:51:41.252085 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_abij-playground_dbt_abij".
2020-11-18 14:51:41.252245 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-11-18 14:51:41.253017 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-18 14:51:41.498774 (MainThread): 14:51:41 | Concurrency: 1 threads (target='default')
2020-11-18 14:51:41.498920 (MainThread): 14:51:41 | 
2020-11-18 14:51:41.501124 (Thread-1): Began running node model.github_source.stg_github_issue
2020-11-18 14:51:41.501554 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 14:51:41.501670 (Thread-1): Compiling model.github_source.stg_github_issue
2020-11-18 14:51:41.520020 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue"
2020-11-18 14:51:41.539951 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.540684 (Thread-1): Finished running node model.github_source.stg_github_issue
2020-11-18 14:51:41.540849 (Thread-1): Began running node model.github_source.stg_github_issue_assignee
2020-11-18 14:51:41.541081 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 14:51:41.541197 (Thread-1): Compiling model.github_source.stg_github_issue_assignee
2020-11-18 14:51:41.551295 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_assignee"
2020-11-18 14:51:41.568975 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.569666 (Thread-1): Finished running node model.github_source.stg_github_issue_assignee
2020-11-18 14:51:41.569819 (Thread-1): Began running node model.github_source.stg_github_issue_closed_history
2020-11-18 14:51:41.570057 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 14:51:41.570147 (Thread-1): Compiling model.github_source.stg_github_issue_closed_history
2020-11-18 14:51:41.579514 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_closed_history"
2020-11-18 14:51:41.597785 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.598395 (Thread-1): Finished running node model.github_source.stg_github_issue_closed_history
2020-11-18 14:51:41.598541 (Thread-1): Began running node model.github_source.stg_github_issue_comment
2020-11-18 14:51:41.598765 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 14:51:41.598850 (Thread-1): Compiling model.github_source.stg_github_issue_comment
2020-11-18 14:51:41.610361 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_comment"
2020-11-18 14:51:41.629486 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.630332 (Thread-1): Finished running node model.github_source.stg_github_issue_comment
2020-11-18 14:51:41.630576 (Thread-1): Began running node model.github_source.stg_github_issue_label
2020-11-18 14:51:41.630979 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 14:51:41.631124 (Thread-1): Compiling model.github_source.stg_github_issue_label
2020-11-18 14:51:41.645836 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_label"
2020-11-18 14:51:41.664848 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.665548 (Thread-1): Finished running node model.github_source.stg_github_issue_label
2020-11-18 14:51:41.665703 (Thread-1): Began running node model.github_source.stg_github_issue_merged
2020-11-18 14:51:41.665934 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 14:51:41.666022 (Thread-1): Compiling model.github_source.stg_github_issue_merged
2020-11-18 14:51:41.675673 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_merged"
2020-11-18 14:51:41.692962 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.693694 (Thread-1): Finished running node model.github_source.stg_github_issue_merged
2020-11-18 14:51:41.693856 (Thread-1): Began running node model.github_source.stg_github_pull_request
2020-11-18 14:51:41.694108 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 14:51:41.694201 (Thread-1): Compiling model.github_source.stg_github_pull_request
2020-11-18 14:51:41.698801 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 54470), raddr=('172.217.8.10', 443)>
2020-11-18 14:51:41.699072 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 48280), raddr=('172.217.9.202', 443)>
2020-11-18 14:51:41.705571 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_pull_request"
2020-11-18 14:51:41.723335 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.723952 (Thread-1): Finished running node model.github_source.stg_github_pull_request
2020-11-18 14:51:41.724110 (Thread-1): Began running node model.github_source.stg_github_pull_request_review
2020-11-18 14:51:41.724350 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 14:51:41.724440 (Thread-1): Compiling model.github_source.stg_github_pull_request_review
2020-11-18 14:51:41.733940 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_pull_request_review"
2020-11-18 14:51:41.752850 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.753680 (Thread-1): Finished running node model.github_source.stg_github_pull_request_review
2020-11-18 14:51:41.753853 (Thread-1): Began running node model.github_source.stg_github_repository
2020-11-18 14:51:41.754103 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 14:51:41.754196 (Thread-1): Compiling model.github_source.stg_github_repository
2020-11-18 14:51:41.763509 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_repository"
2020-11-18 14:51:41.782690 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.783331 (Thread-1): Finished running node model.github_source.stg_github_repository
2020-11-18 14:51:41.783492 (Thread-1): Began running node model.github_source.stg_github_requested_reviewer_history
2020-11-18 14:51:41.783740 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 14:51:41.783832 (Thread-1): Compiling model.github_source.stg_github_requested_reviewer_history
2020-11-18 14:51:41.793192 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_requested_reviewer_history"
2020-11-18 14:51:41.811018 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.811627 (Thread-1): Finished running node model.github_source.stg_github_requested_reviewer_history
2020-11-18 14:51:41.811781 (Thread-1): Began running node model.github_source.stg_github_user
2020-11-18 14:51:41.812026 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 14:51:41.812115 (Thread-1): Compiling model.github_source.stg_github_user
2020-11-18 14:51:41.821420 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_user"
2020-11-18 14:51:41.840242 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.840877 (Thread-1): Finished running node model.github_source.stg_github_user
2020-11-18 14:51:41.841027 (Thread-1): Began running node model.github_source.github_issue_open_length
2020-11-18 14:51:41.841292 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 14:51:41.841384 (Thread-1): Compiling model.github_source.github_issue_open_length
2020-11-18 14:51:41.851343 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.851829 (Thread-1): Compilation Error in model github_issue_open_length (models/github/github_issue_open_length.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 29, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_open_length (models/github/github_issue_open_length.sql)
  'dbt_utils' is undefined
2020-11-18 14:51:41.853224 (Thread-1): Finished running node model.github_source.github_issue_open_length
2020-11-18 14:51:41.853366 (Thread-1): Began running node model.github_source.github_issue_comments
2020-11-18 14:51:41.853630 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 14:51:41.853721 (Thread-1): Compiling model.github_source.github_issue_comments
2020-11-18 14:51:41.863961 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_comments"
2020-11-18 14:51:41.882399 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.883007 (Thread-1): Finished running node model.github_source.github_issue_comments
2020-11-18 14:51:41.883163 (Thread-1): Began running node model.github_source.github_issue_labels
2020-11-18 14:51:41.883417 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 14:51:41.883510 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 14:51:41.891230 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.891656 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 14:51:41.892326 (Thread-1): Finished running node model.github_source.github_issue_labels
2020-11-18 14:51:41.892458 (Thread-1): Began running node model.github_source.github_pull_request_times
2020-11-18 14:51:41.892702 (Thread-1): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 14:51:41.892788 (Thread-1): Compiling model.github_source.github_pull_request_times
2020-11-18 14:51:41.905668 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.906123 (Thread-1): Compilation Error in model github_pull_request_times (models/github/github_pull_request_times.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 53, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_pull_request_times (models/github/github_pull_request_times.sql)
  'dbt_utils' is undefined
2020-11-18 14:51:41.906923 (Thread-1): Finished running node model.github_source.github_pull_request_times
2020-11-18 14:51:41.907055 (Thread-1): Began running node model.github_source.github_issue_assignees
2020-11-18 14:51:41.907301 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 14:51:41.907390 (Thread-1): Compiling model.github_source.github_issue_assignees
2020-11-18 14:51:41.915703 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.916123 (Thread-1): Compilation Error in model github_issue_assignees (models/github/github_issue_assignees.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 15, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_assignees (models/github/github_issue_assignees.sql)
  'fivetran_utils' is undefined
2020-11-18 14:51:41.916780 (Thread-1): Finished running node model.github_source.github_issue_assignees
2020-11-18 14:51:41.916909 (Thread-1): Began running node model.github_source.github_pull_request_reviewers
2020-11-18 14:51:41.917171 (Thread-1): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 14:51:41.917259 (Thread-1): Compiling model.github_source.github_pull_request_reviewers
2020-11-18 14:51:41.925400 (Thread-1): finished collecting timing info
2020-11-18 14:51:41.925815 (Thread-1): Compilation Error in model github_pull_request_reviewers (models/github/github_pull_request_reviewers.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 15, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_pull_request_reviewers (models/github/github_pull_request_reviewers.sql)
  'fivetran_utils' is undefined
2020-11-18 14:51:41.926439 (Thread-1): Finished running node model.github_source.github_pull_request_reviewers
2020-11-18 14:51:41.927027 (Thread-1): Began running node model.github_source.github_issue_joined
2020-11-18 14:51:41.927144 (Thread-1): Finished running node model.github_source.github_issue_joined
2020-11-18 14:51:41.927582 (Thread-1): Began running node model.github_source.github_issues
2020-11-18 14:51:41.927686 (Thread-1): Finished running node model.github_source.github_issues
2020-11-18 14:51:41.927782 (Thread-1): Began running node model.github_source.github_pull_requests
2020-11-18 14:51:41.927859 (Thread-1): Finished running node model.github_source.github_pull_requests
2020-11-18 14:51:41.928321 (Thread-1): Began running node model.github_source.github_daily_metrics
2020-11-18 14:51:41.928420 (Thread-1): Finished running node model.github_source.github_daily_metrics
2020-11-18 14:51:41.928825 (Thread-1): Began running node model.github_source.github_monthly_metrics
2020-11-18 14:51:41.928923 (Thread-1): Finished running node model.github_source.github_monthly_metrics
2020-11-18 14:51:41.929015 (Thread-1): Began running node model.github_source.github_quarterly_metrics
2020-11-18 14:51:41.929091 (Thread-1): Finished running node model.github_source.github_quarterly_metrics
2020-11-18 14:51:41.929189 (Thread-1): Began running node model.github_source.github_weekly_metrics
2020-11-18 14:51:41.929266 (Thread-1): Finished running node model.github_source.github_weekly_metrics
2020-11-18 14:51:42.007121 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 14:51:42.007463 (MainThread): 14:51:42 | 
2020-11-18 14:51:42.007542 (MainThread): 14:51:42 | Finished running  in 0.82s.
2020-11-18 14:51:42.007607 (MainThread): Connection 'master' was properly closed.
2020-11-18 14:51:42.007655 (MainThread): Connection 'model.github_source.github_pull_request_reviewers' was properly closed.
2020-11-18 14:51:42.126529 (Thread-9): handling poll request
2020-11-18 14:51:42.127039 (Thread-9): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37f2048>]}
2020-11-18 14:51:42.141955 (Thread-9): sending response (<Response 72884 bytes [200 OK]>) to 10.0.3.20
2020-11-18 14:51:43.464370 (Thread-10): handling poll request
2020-11-18 14:51:43.464896 (Thread-10): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37f26a0>]}
2020-11-18 14:51:43.466116 (Thread-10): sending response (<Response 409 bytes [200 OK]>) to 10.0.3.20
2020-11-18 14:51:43.749778 (Thread-11): handling status request
2020-11-18 14:51:43.750315 (Thread-11): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37f2c50>]}
2020-11-18 14:51:43.757000 (Thread-11): sending response (<Response 16806 bytes [200 OK]>) to 10.0.23.22
2020-11-18 14:54:36.772927 (Thread-12): handling status request
2020-11-18 14:54:36.773636 (Thread-13): handling status request
2020-11-18 14:54:36.774869 (Thread-12): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37800f0>]}
2020-11-18 14:54:36.775251 (Thread-13): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8349dd8>]}
2020-11-18 14:54:36.781773 (Thread-12): sending response (<Response 16806 bytes [200 OK]>) to 10.0.34.62
2020-11-18 14:54:36.788418 (Thread-13): sending response (<Response 16806 bytes [200 OK]>) to 10.0.34.62
2020-11-18 14:54:37.095156 (Thread-14): handling cli_args request
2020-11-18 14:54:37.095661 (Thread-14): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc378d9e8>]}
2020-11-18 14:54:38.145938 (Thread-14): sending response (<Response 137 bytes [200 OK]>) to 10.0.44.246
2020-11-18 14:54:38.218410 (MainThread): Partial parsing not enabled
2020-11-18 14:54:38.219932 (MainThread): Parsing macros/adapters.sql
2020-11-18 14:54:38.241613 (MainThread): Parsing macros/etc.sql
2020-11-18 14:54:38.243193 (MainThread): Parsing macros/catalog.sql
2020-11-18 14:54:38.249527 (MainThread): Parsing macros/materializations/table.sql
2020-11-18 14:54:38.260279 (MainThread): Parsing macros/materializations/view.sql
2020-11-18 14:54:38.263475 (MainThread): Parsing macros/materializations/copy.sql
2020-11-18 14:54:38.268238 (MainThread): Parsing macros/materializations/seed.sql
2020-11-18 14:54:38.271277 (MainThread): Parsing macros/materializations/incremental.sql
2020-11-18 14:54:38.284878 (MainThread): Parsing macros/materializations/snapshot.sql
2020-11-18 14:54:38.287922 (MainThread): Parsing macros/core.sql
2020-11-18 14:54:38.291984 (MainThread): Parsing macros/adapters/common.sql
2020-11-18 14:54:38.338847 (MainThread): Parsing macros/materializations/helpers.sql
2020-11-18 14:54:38.348839 (MainThread): Parsing macros/materializations/table/table.sql
2020-11-18 14:54:38.356616 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-11-18 14:54:38.379236 (MainThread): Parsing macros/materializations/view/view.sql
2020-11-18 14:54:38.386186 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 14:54:38.391782 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 14:54:38.393944 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 14:54:38.400767 (MainThread): Parsing macros/materializations/common/merge.sql
2020-11-18 14:54:38.415658 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 14:54:38.433182 (Thread-15): handling poll request
2020-11-18 14:54:38.433845 (Thread-15): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc373f668>]}
2020-11-18 14:54:38.438358 (Thread-15): sending response (<Response 6050 bytes [200 OK]>) to 10.0.44.246
2020-11-18 14:54:38.434077 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 14:54:38.436289 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 14:54:38.466534 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-11-18 14:54:38.468859 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-11-18 14:54:38.470778 (MainThread): Parsing macros/schema_tests/unique.sql
2020-11-18 14:54:38.472776 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 14:54:38.476075 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-11-18 14:54:38.477958 (MainThread): Parsing macros/etc/query.sql
2020-11-18 14:54:38.479154 (MainThread): Parsing macros/etc/datetime.sql
2020-11-18 14:54:38.488697 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-11-18 14:54:38.489847 (MainThread): Parsing macros/etc/is_incremental.sql
2020-11-18 14:54:38.491646 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-11-18 14:54:38.503602 (MainThread): Partial parsing not enabled
2020-11-18 14:54:38.562943 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 14:54:38.593396 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 14:54:38.611479 (MainThread): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 14:54:38.631653 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 14:54:38.653172 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 14:54:38.676788 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 14:54:38.693649 (MainThread): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 14:54:38.711579 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 14:54:38.739595 (MainThread): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 14:54:38.763473 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 14:54:38.783983 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 14:54:38.801863 (MainThread): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 14:54:38.825715 (MainThread): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 14:54:38.853495 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 14:54:38.872537 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 14:54:38.890661 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 14:54:38.909330 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 14:54:38.928354 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 14:54:38.946694 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 14:54:38.964807 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 14:54:38.983494 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 14:54:39.002568 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 14:54:39.021179 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 14:54:39.040808 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 14:54:39.730140 (Thread-16): handling poll request
2020-11-18 14:54:39.730846 (Thread-16): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc379d0b8>]}
2020-11-18 14:54:39.737878 (Thread-16): sending response (<Response 11395 bytes [200 OK]>) to 10.0.34.241
2020-11-18 14:54:40.031433 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github.intermediate
- models.github

2020-11-18 14:54:40.156932 (MainThread): Found 24 models, 26 tests, 0 snapshots, 0 analyses, 155 macros, 0 operations, 0 seed files, 11 sources
2020-11-18 14:54:40.163886 (MainThread): 
2020-11-18 14:54:40.164257 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 14:54:40.201742 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_abij-playground_dbt_abij".
2020-11-18 14:54:40.201891 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-11-18 14:54:40.202567 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-18 14:54:40.423187 (MainThread): 14:54:40 | Concurrency: 1 threads (target='default')
2020-11-18 14:54:40.423332 (MainThread): 14:54:40 | 
2020-11-18 14:54:40.425813 (Thread-1): Began running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 14:54:40.426016 (Thread-1): 14:54:40 | 1 of 26 START test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id [RUN]
2020-11-18 14:54:40.426312 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id".
2020-11-18 14:54:40.426409 (Thread-1): Compiling test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 14:54:40.447233 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.447773 (Thread-1): Compilation Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 1, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
  'dbt_utils' is undefined
2020-11-18 14:54:40.449271 (Thread-1): 14:54:40 | 1 of 26 ERROR dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id [ERROR in 0.02s]
2020-11-18 14:54:40.449368 (Thread-1): Finished running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 14:54:40.449506 (Thread-1): Began running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 14:54:40.449623 (Thread-1): 14:54:40 | 2 of 26 START test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at [RUN]
2020-11-18 14:54:40.449865 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at".
2020-11-18 14:54:40.449947 (Thread-1): Compiling test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 14:54:40.459900 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.460548 (Thread-1): Compilation Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 1, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
  'dbt_utils' is undefined
2020-11-18 14:54:40.461419 (Thread-1): 14:54:40 | 2 of 26 ERROR dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at [ERROR in 0.01s]
2020-11-18 14:54:40.461504 (Thread-1): Finished running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 14:54:40.461624 (Thread-1): Began running node test.github_source.not_null_github_daily_metrics_day
2020-11-18 14:54:40.461740 (Thread-1): 14:54:40 | 3 of 26 START test not_null_github_daily_metrics_day................. [RUN]
2020-11-18 14:54:40.461954 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_daily_metrics_day".
2020-11-18 14:54:40.462036 (Thread-1): Compiling test.github_source.not_null_github_daily_metrics_day
2020-11-18 14:54:40.470622 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 14:54:40.493117 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.493677 (Thread-1): Compilation Error in model github_daily_metrics (models/github/github_daily_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 14, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_daily_metrics (models/github/github_daily_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:40.494450 (Thread-1): 14:54:40 | 3 of 26 ERROR not_null_github_daily_metrics_day...................... [ERROR in 0.03s]
2020-11-18 14:54:40.494539 (Thread-1): Finished running node test.github_source.not_null_github_daily_metrics_day
2020-11-18 14:54:40.494671 (Thread-1): Began running node test.github_source.not_null_github_issues_issue_id
2020-11-18 14:54:40.494766 (Thread-1): 14:54:40 | 4 of 26 START test not_null_github_issues_issue_id................... [RUN]
2020-11-18 14:54:40.494992 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_issues_issue_id".
2020-11-18 14:54:40.495073 (Thread-1): Compiling test.github_source.not_null_github_issues_issue_id
2020-11-18 14:54:40.501270 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 52926), raddr=('172.217.164.170', 443)>
2020-11-18 14:54:40.501723 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 58896), raddr=('142.250.73.202', 443)>
2020-11-18 14:54:40.506049 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 14:54:40.522030 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 14:54:40.538030 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.538579 (Thread-1): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 55, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:40.539175 (Thread-1): 14:54:40 | 4 of 26 ERROR not_null_github_issues_issue_id........................ [ERROR in 0.04s]
2020-11-18 14:54:40.539265 (Thread-1): Finished running node test.github_source.not_null_github_issues_issue_id
2020-11-18 14:54:40.539395 (Thread-1): Began running node test.github_source.not_null_github_monthly_metrics_month
2020-11-18 14:54:40.539492 (Thread-1): 14:54:40 | 5 of 26 START test not_null_github_monthly_metrics_month............. [RUN]
2020-11-18 14:54:40.539713 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_monthly_metrics_month".
2020-11-18 14:54:40.539795 (Thread-1): Compiling test.github_source.not_null_github_monthly_metrics_month
2020-11-18 14:54:40.548528 (Thread-1): Compiling model.github_source.github_monthly_metrics
2020-11-18 14:54:40.560607 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.561102 (Thread-1): Compilation Error in model github_monthly_metrics (models/github/github_monthly_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 9, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_monthly_metrics (models/github/github_monthly_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:40.561931 (Thread-1): 14:54:40 | 5 of 26 ERROR not_null_github_monthly_metrics_month.................. [ERROR in 0.02s]
2020-11-18 14:54:40.562030 (Thread-1): Finished running node test.github_source.not_null_github_monthly_metrics_month
2020-11-18 14:54:40.562167 (Thread-1): Began running node test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 14:54:40.562267 (Thread-1): 14:54:40 | 6 of 26 START test not_null_github_pull_requests_issue_id............ [RUN]
2020-11-18 14:54:40.562496 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_pull_requests_issue_id".
2020-11-18 14:54:40.562581 (Thread-1): Compiling test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 14:54:40.571247 (Thread-1): Compiling model.github_source.github_pull_requests
2020-11-18 14:54:40.587252 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 14:54:40.602578 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.603140 (Thread-1): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 55, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:40.603763 (Thread-1): 14:54:40 | 6 of 26 ERROR not_null_github_pull_requests_issue_id................. [ERROR in 0.04s]
2020-11-18 14:54:40.603851 (Thread-1): Finished running node test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 14:54:40.603979 (Thread-1): Began running node test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 14:54:40.604072 (Thread-1): 14:54:40 | 7 of 26 START test not_null_github_quarterly_metrics_quarter......... [RUN]
2020-11-18 14:54:40.604296 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_quarterly_metrics_quarter".
2020-11-18 14:54:40.604378 (Thread-1): Compiling test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 14:54:40.612705 (Thread-1): Compiling model.github_source.github_quarterly_metrics
2020-11-18 14:54:40.624907 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.625383 (Thread-1): Compilation Error in model github_quarterly_metrics (models/github/github_quarterly_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_quarterly_metrics (models/github/github_quarterly_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:40.626134 (Thread-1): 14:54:40 | 7 of 26 ERROR not_null_github_quarterly_metrics_quarter.............. [ERROR in 0.02s]
2020-11-18 14:54:40.626219 (Thread-1): Finished running node test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 14:54:40.626342 (Thread-1): Began running node test.github_source.not_null_github_weekly_metrics_week
2020-11-18 14:54:40.626442 (Thread-1): 14:54:40 | 8 of 26 START test not_null_github_weekly_metrics_week............... [RUN]
2020-11-18 14:54:40.626660 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_weekly_metrics_week".
2020-11-18 14:54:40.626740 (Thread-1): Compiling test.github_source.not_null_github_weekly_metrics_week
2020-11-18 14:54:40.635054 (Thread-1): Compiling model.github_source.github_weekly_metrics
2020-11-18 14:54:40.647251 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.647726 (Thread-1): Compilation Error in model github_weekly_metrics (models/github/github_weekly_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_weekly_metrics (models/github/github_weekly_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:40.648504 (Thread-1): 14:54:40 | 8 of 26 ERROR not_null_github_weekly_metrics_week.................... [ERROR in 0.02s]
2020-11-18 14:54:40.648597 (Thread-1): Finished running node test.github_source.not_null_github_weekly_metrics_week
2020-11-18 14:54:40.648723 (Thread-1): Began running node test.github_source.source_not_null_github_issue_comment_id
2020-11-18 14:54:40.648821 (Thread-1): 14:54:40 | 9 of 26 START test source_not_null_github_issue_comment_id........... [RUN]
2020-11-18 14:54:40.649031 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_issue_comment_id".
2020-11-18 14:54:40.649110 (Thread-1): Compiling test.github_source.source_not_null_github_issue_comment_id
2020-11-18 14:54:40.659199 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_issue_comment_id"
2020-11-18 14:54:40.690012 (Thread-1): finished collecting timing info
2020-11-18 14:54:40.690458 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:40.690868 (Thread-1): On test.github_source.source_not_null_github_issue_comment_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue_comment`
where id is null



2020-11-18 14:54:41.015070 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue_comment`
where id is null



2020-11-18 14:54:41.015311 (Thread-1): finished collecting timing info
2020-11-18 14:54:41.015874 (Thread-1): Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: 35a85c76-09af-4430-be18-ba8f0c58925f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_comment was not found in location EU

(job ID: 35a85c76-09af-4430-be18-ba8f0c58925f)

                                                                       -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`issue_comment`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: 35a85c76-09af-4430-be18-ba8f0c58925f)
2020-11-18 14:54:41.018521 (Thread-1): 14:54:41 | 9 of 26 ERROR source_not_null_github_issue_comment_id................ [ERROR in 0.37s]
2020-11-18 14:54:41.018635 (Thread-1): Finished running node test.github_source.source_not_null_github_issue_comment_id
2020-11-18 14:54:41.018769 (Thread-1): Began running node test.github_source.source_not_null_github_issue_id
2020-11-18 14:54:41.018872 (Thread-1): 14:54:41 | 10 of 26 START test source_not_null_github_issue_id.................. [RUN]
2020-11-18 14:54:41.019139 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_issue_id".
2020-11-18 14:54:41.019230 (Thread-1): Compiling test.github_source.source_not_null_github_issue_id
2020-11-18 14:54:41.029066 (Thread-17): handling poll request
2020-11-18 14:54:41.029520 (Thread-17): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36ebb00>]}
2020-11-18 14:54:41.021479 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45452), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:41.041641 (Thread-17): sending response (<Response 76884 bytes [200 OK]>) to 10.0.37.56
2020-11-18 14:54:41.021704 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 52260), raddr=('172.217.15.74', 443)>
2020-11-18 14:54:41.031471 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_issue_id"
2020-11-18 14:54:41.043807 (Thread-1): finished collecting timing info
2020-11-18 14:54:41.044226 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:41.044707 (Thread-1): On test.github_source.source_not_null_github_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue`
where id is null



2020-11-18 14:54:41.338388 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue`
where id is null



2020-11-18 14:54:41.338629 (Thread-1): finished collecting timing info
2020-11-18 14:54:41.339184 (Thread-1): Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: be9ed975-a43a-4c5f-bf07-ed9e70ec065c)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue was not found in location EU

(job ID: be9ed975-a43a-4c5f-bf07-ed9e70ec065c)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`issue`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: be9ed975-a43a-4c5f-bf07-ed9e70ec065c)
2020-11-18 14:54:41.340203 (Thread-1): 14:54:41 | 10 of 26 ERROR source_not_null_github_issue_id....................... [ERROR in 0.32s]
2020-11-18 14:54:41.340291 (Thread-1): Finished running node test.github_source.source_not_null_github_issue_id
2020-11-18 14:54:41.340429 (Thread-1): Began running node test.github_source.source_not_null_github_pull_request_id
2020-11-18 14:54:41.340524 (Thread-1): 14:54:41 | 11 of 26 START test source_not_null_github_pull_request_id........... [RUN]
2020-11-18 14:54:41.340767 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_pull_request_id".
2020-11-18 14:54:41.340855 (Thread-1): Compiling test.github_source.source_not_null_github_pull_request_id
2020-11-18 14:54:41.344059 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 52952), raddr=('172.217.164.170', 443)>
2020-11-18 14:54:41.344388 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 52270), raddr=('172.217.15.74', 443)>
2020-11-18 14:54:41.352420 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_pull_request_id"
2020-11-18 14:54:41.364196 (Thread-1): finished collecting timing info
2020-11-18 14:54:41.364524 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:41.364894 (Thread-1): On test.github_source.source_not_null_github_pull_request_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request`
where id is null



2020-11-18 14:54:41.666138 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request`
where id is null



2020-11-18 14:54:41.666377 (Thread-1): finished collecting timing info
2020-11-18 14:54:41.666949 (Thread-1): Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: fef2d03b-aa9a-4296-aebf-3c65d9c36d2a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request was not found in location EU

(job ID: fef2d03b-aa9a-4296-aebf-3c65d9c36d2a)

                                                                      -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`pull_request`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: fef2d03b-aa9a-4296-aebf-3c65d9c36d2a)
2020-11-18 14:54:41.667909 (Thread-1): 14:54:41 | 11 of 26 ERROR source_not_null_github_pull_request_id................ [ERROR in 0.33s]
2020-11-18 14:54:41.667999 (Thread-1): Finished running node test.github_source.source_not_null_github_pull_request_id
2020-11-18 14:54:41.668128 (Thread-1): Began running node test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 14:54:41.668231 (Thread-1): 14:54:41 | 12 of 26 START test source_not_null_github_pull_request_review_id.... [RUN]
2020-11-18 14:54:41.668460 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_pull_request_review_id".
2020-11-18 14:54:41.668544 (Thread-1): Compiling test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 14:54:41.672193 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45476), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:41.672553 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 52282), raddr=('172.217.15.74', 443)>
2020-11-18 14:54:41.680148 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_pull_request_review_id"
2020-11-18 14:54:41.694199 (Thread-1): finished collecting timing info
2020-11-18 14:54:41.694625 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:41.695080 (Thread-1): On test.github_source.source_not_null_github_pull_request_review_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request_review`
where id is null



2020-11-18 14:54:42.059944 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request_review`
where id is null



2020-11-18 14:54:42.060182 (Thread-1): finished collecting timing info
2020-11-18 14:54:42.060754 (Thread-1): Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: 2e876b3c-5b85-4c64-be97-ebfd6199a793)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request_review was not found in location EU

(job ID: 2e876b3c-5b85-4c64-be97-ebfd6199a793)

                                                                          -----Query Job SQL Follows-----                                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`pull_request_review`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: 2e876b3c-5b85-4c64-be97-ebfd6199a793)
2020-11-18 14:54:42.061862 (Thread-1): 14:54:42 | 12 of 26 ERROR source_not_null_github_pull_request_review_id......... [ERROR in 0.39s]
2020-11-18 14:54:42.061968 (Thread-1): Finished running node test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 14:54:42.062102 (Thread-1): Began running node test.github_source.source_not_null_github_repository_id
2020-11-18 14:54:42.062202 (Thread-1): 14:54:42 | 13 of 26 START test source_not_null_github_repository_id............. [RUN]
2020-11-18 14:54:42.062465 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_repository_id".
2020-11-18 14:54:42.062553 (Thread-1): Compiling test.github_source.source_not_null_github_repository_id
2020-11-18 14:54:42.073619 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_repository_id"
2020-11-18 14:54:42.085418 (Thread-1): finished collecting timing info
2020-11-18 14:54:42.085775 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:42.086171 (Thread-1): On test.github_source.source_not_null_github_repository_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_repository_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`repository`
where id is null



2020-11-18 14:54:42.147532 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 52294), raddr=('172.217.15.74', 443)>
2020-11-18 14:54:42.147872 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45486), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:42.322787 (Thread-18): handling poll request
2020-11-18 14:54:42.323299 (Thread-18): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36fd978>]}
2020-11-18 14:54:42.328930 (Thread-18): sending response (<Response 35196 bytes [200 OK]>) to 10.0.23.22
2020-11-18 14:54:43.609082 (Thread-19): handling poll request
2020-11-18 14:54:43.609609 (Thread-19): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc367f6d8>]}
2020-11-18 14:54:43.610637 (Thread-19): sending response (<Response 288 bytes [200 OK]>) to 10.0.5.154
2020-11-18 14:54:43.628900 (Thread-1): finished collecting timing info
2020-11-18 14:54:43.629596 (Thread-1): 14:54:43 | 13 of 26 PASS source_not_null_github_repository_id................... [PASS in 1.57s]
2020-11-18 14:54:43.629693 (Thread-1): Finished running node test.github_source.source_not_null_github_repository_id
2020-11-18 14:54:43.629816 (Thread-1): Began running node test.github_source.source_not_null_github_user_id
2020-11-18 14:54:43.629914 (Thread-1): 14:54:43 | 14 of 26 START test source_not_null_github_user_id................... [RUN]
2020-11-18 14:54:43.630114 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_user_id".
2020-11-18 14:54:43.630247 (Thread-1): Compiling test.github_source.source_not_null_github_user_id
2020-11-18 14:54:43.640826 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_user_id"
2020-11-18 14:54:43.652811 (Thread-1): finished collecting timing info
2020-11-18 14:54:43.653237 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:43.653667 (Thread-1): On test.github_source.source_not_null_github_user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_user_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`user`
where id is null



2020-11-18 14:54:44.733086 (Thread-1): finished collecting timing info
2020-11-18 14:54:44.733800 (Thread-1): 14:54:44 | 14 of 26 PASS source_not_null_github_user_id......................... [PASS in 1.10s]
2020-11-18 14:54:44.733897 (Thread-1): Finished running node test.github_source.source_not_null_github_user_id
2020-11-18 14:54:44.734025 (Thread-1): Began running node test.github_source.source_unique_github_issue_comment_id
2020-11-18 14:54:44.734125 (Thread-1): 14:54:44 | 15 of 26 START test source_unique_github_issue_comment_id............ [RUN]
2020-11-18 14:54:44.734327 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_issue_comment_id".
2020-11-18 14:54:44.734412 (Thread-1): Compiling test.github_source.source_unique_github_issue_comment_id
2020-11-18 14:54:44.745490 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_issue_comment_id"
2020-11-18 14:54:44.759032 (Thread-1): finished collecting timing info
2020-11-18 14:54:44.759479 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:44.759964 (Thread-1): On test.github_source.source_unique_github_issue_comment_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue_comment`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:44.872907 (Thread-20): handling poll request
2020-11-18 14:54:44.873630 (Thread-20): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3688908>]}
2020-11-18 14:54:44.878637 (Thread-20): sending response (<Response 10673 bytes [200 OK]>) to 10.0.23.22
2020-11-18 14:54:45.065675 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue_comment`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:45.065912 (Thread-1): finished collecting timing info
2020-11-18 14:54:45.066468 (Thread-1): Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: c30524b1-826f-4098-bed7-da2615fee82c)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_comment was not found in location EU

(job ID: c30524b1-826f-4098-bed7-da2615fee82c)

                                                                      -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`issue_comment`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: c30524b1-826f-4098-bed7-da2615fee82c)
2020-11-18 14:54:45.067825 (Thread-1): 14:54:45 | 15 of 26 ERROR source_unique_github_issue_comment_id................. [ERROR in 0.33s]
2020-11-18 14:54:45.067929 (Thread-1): Finished running node test.github_source.source_unique_github_issue_comment_id
2020-11-18 14:54:45.068063 (Thread-1): Began running node test.github_source.source_unique_github_issue_id
2020-11-18 14:54:45.068161 (Thread-1): 14:54:45 | 16 of 26 START test source_unique_github_issue_id.................... [RUN]
2020-11-18 14:54:45.068410 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_issue_id".
2020-11-18 14:54:45.068494 (Thread-1): Compiling test.github_source.source_unique_github_issue_id
2020-11-18 14:54:45.069068 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 53068), raddr=('172.217.164.170', 443)>
2020-11-18 14:54:45.069564 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59036), raddr=('142.250.73.202', 443)>
2020-11-18 14:54:45.084435 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_issue_id"
2020-11-18 14:54:45.097575 (Thread-1): finished collecting timing info
2020-11-18 14:54:45.097950 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:45.098432 (Thread-1): On test.github_source.source_unique_github_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:45.372586 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:45.372821 (Thread-1): finished collecting timing info
2020-11-18 14:54:45.373396 (Thread-1): Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: 28240463-807b-46f6-9ccf-b6dbe5e290e1)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue was not found in location EU

(job ID: 28240463-807b-46f6-9ccf-b6dbe5e290e1)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`issue`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: 28240463-807b-46f6-9ccf-b6dbe5e290e1)
2020-11-18 14:54:45.374559 (Thread-1): 14:54:45 | 16 of 26 ERROR source_unique_github_issue_id......................... [ERROR in 0.31s]
2020-11-18 14:54:45.374647 (Thread-1): Finished running node test.github_source.source_unique_github_issue_id
2020-11-18 14:54:45.374780 (Thread-1): Began running node test.github_source.source_unique_github_pull_request_id
2020-11-18 14:54:45.374885 (Thread-1): 14:54:45 | 17 of 26 START test source_unique_github_pull_request_id............. [RUN]
2020-11-18 14:54:45.375111 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_pull_request_id".
2020-11-18 14:54:45.375195 (Thread-1): Compiling test.github_source.source_unique_github_pull_request_id
2020-11-18 14:54:45.377920 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45590), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:45.378320 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59050), raddr=('142.250.73.202', 443)>
2020-11-18 14:54:45.387648 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_pull_request_id"
2020-11-18 14:54:45.399837 (Thread-1): finished collecting timing info
2020-11-18 14:54:45.400222 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:45.400629 (Thread-1): On test.github_source.source_unique_github_pull_request_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:45.690666 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:45.690907 (Thread-1): finished collecting timing info
2020-11-18 14:54:45.691487 (Thread-1): Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: 8bde89d2-b4b5-4f1d-ad48-cb3307077cac)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request was not found in location EU

(job ID: 8bde89d2-b4b5-4f1d-ad48-cb3307077cac)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`pull_request`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: 8bde89d2-b4b5-4f1d-ad48-cb3307077cac)
2020-11-18 14:54:45.692771 (Thread-1): 14:54:45 | 17 of 26 ERROR source_unique_github_pull_request_id.................. [ERROR in 0.32s]
2020-11-18 14:54:45.692876 (Thread-1): Finished running node test.github_source.source_unique_github_pull_request_id
2020-11-18 14:54:45.693011 (Thread-1): Began running node test.github_source.source_unique_github_pull_request_review_id
2020-11-18 14:54:45.693122 (Thread-1): 14:54:45 | 18 of 26 START test source_unique_github_pull_request_review_id...... [RUN]
2020-11-18 14:54:45.693405 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_pull_request_review_id".
2020-11-18 14:54:45.693494 (Thread-1): Compiling test.github_source.source_unique_github_pull_request_review_id
2020-11-18 14:54:45.696575 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45600), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:45.697114 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 52410), raddr=('172.217.15.74', 443)>
2020-11-18 14:54:45.706072 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_pull_request_review_id"
2020-11-18 14:54:45.717938 (Thread-1): finished collecting timing info
2020-11-18 14:54:45.718329 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:45.718817 (Thread-1): On test.github_source.source_unique_github_pull_request_review_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request_review`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:46.021798 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request_review`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:46.022047 (Thread-1): finished collecting timing info
2020-11-18 14:54:46.022610 (Thread-1): Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: 69084b10-1f87-4d84-ae57-b4b996d6bd9b)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request_review was not found in location EU

(job ID: 69084b10-1f87-4d84-ae57-b4b996d6bd9b)

                                                                         -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`pull_request_review`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: 69084b10-1f87-4d84-ae57-b4b996d6bd9b)
2020-11-18 14:54:46.023880 (Thread-1): 14:54:46 | 18 of 26 ERROR source_unique_github_pull_request_review_id........... [ERROR in 0.33s]
2020-11-18 14:54:46.023981 (Thread-1): Finished running node test.github_source.source_unique_github_pull_request_review_id
2020-11-18 14:54:46.024115 (Thread-1): Began running node test.github_source.source_unique_github_repository_id
2020-11-18 14:54:46.024214 (Thread-1): 14:54:46 | 19 of 26 START test source_unique_github_repository_id............... [RUN]
2020-11-18 14:54:46.024471 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_repository_id".
2020-11-18 14:54:46.024557 (Thread-1): Compiling test.github_source.source_unique_github_repository_id
2020-11-18 14:54:46.028572 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45612), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:46.029044 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59072), raddr=('142.250.73.202', 443)>
2020-11-18 14:54:46.037133 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_repository_id"
2020-11-18 14:54:46.050512 (Thread-1): finished collecting timing info
2020-11-18 14:54:46.050949 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:46.051481 (Thread-1): On test.github_source.source_unique_github_repository_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_repository_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`repository`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:46.160607 (Thread-21): handling poll request
2020-11-18 14:54:46.161196 (Thread-21): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc369cc50>]}
2020-11-18 14:54:46.168127 (Thread-21): sending response (<Response 45496 bytes [200 OK]>) to 10.0.3.20
2020-11-18 14:54:47.475168 (Thread-22): handling poll request
2020-11-18 14:54:47.475690 (Thread-22): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc367f400>]}
2020-11-18 14:54:47.476744 (Thread-22): sending response (<Response 289 bytes [200 OK]>) to 10.0.41.79
2020-11-18 14:54:47.971555 (Thread-1): finished collecting timing info
2020-11-18 14:54:47.972273 (Thread-1): 14:54:47 | 19 of 26 PASS source_unique_github_repository_id..................... [PASS in 1.95s]
2020-11-18 14:54:47.972415 (Thread-1): Finished running node test.github_source.source_unique_github_repository_id
2020-11-18 14:54:47.972614 (Thread-1): Began running node test.github_source.source_unique_github_user_id
2020-11-18 14:54:47.972766 (Thread-1): 14:54:47 | 20 of 26 START test source_unique_github_user_id..................... [RUN]
2020-11-18 14:54:47.973013 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_user_id".
2020-11-18 14:54:47.973127 (Thread-1): Compiling test.github_source.source_unique_github_user_id
2020-11-18 14:54:47.978241 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45538), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:47.978846 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 58998), raddr=('142.250.73.202', 443)>
2020-11-18 14:54:47.988568 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 53112), raddr=('172.217.164.170', 443)>
2020-11-18 14:54:47.988998 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59084), raddr=('142.250.73.202', 443)>
2020-11-18 14:54:47.998169 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_user_id"
2020-11-18 14:54:48.010240 (Thread-1): finished collecting timing info
2020-11-18 14:54:48.010718 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 14:54:48.011293 (Thread-1): On test.github_source.source_unique_github_user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`user`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 14:54:48.762727 (Thread-23): handling poll request
2020-11-18 14:54:48.763258 (Thread-23): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36a3e10>]}
2020-11-18 14:54:48.765630 (Thread-23): sending response (<Response 5444 bytes [200 OK]>) to 10.0.34.241
2020-11-18 14:54:49.751191 (Thread-1): finished collecting timing info
2020-11-18 14:54:49.751885 (Thread-1): 14:54:49 | 20 of 26 PASS source_unique_github_user_id........................... [PASS in 1.78s]
2020-11-18 14:54:49.751983 (Thread-1): Finished running node test.github_source.source_unique_github_user_id
2020-11-18 14:54:49.752117 (Thread-1): Began running node test.github_source.unique_github_daily_metrics_day
2020-11-18 14:54:49.752220 (Thread-1): 14:54:49 | 21 of 26 START test unique_github_daily_metrics_day.................. [RUN]
2020-11-18 14:54:49.752457 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_daily_metrics_day".
2020-11-18 14:54:49.752542 (Thread-1): Compiling test.github_source.unique_github_daily_metrics_day
2020-11-18 14:54:49.762159 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 14:54:49.778227 (Thread-1): finished collecting timing info
2020-11-18 14:54:49.778755 (Thread-1): Compilation Error in model github_daily_metrics (models/github/github_daily_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 14, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_daily_metrics (models/github/github_daily_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:49.779526 (Thread-1): 14:54:49 | 21 of 26 ERROR unique_github_daily_metrics_day....................... [ERROR in 0.03s]
2020-11-18 14:54:49.779623 (Thread-1): Finished running node test.github_source.unique_github_daily_metrics_day
2020-11-18 14:54:49.779759 (Thread-1): Began running node test.github_source.unique_github_issues_issue_id
2020-11-18 14:54:49.779857 (Thread-1): 14:54:49 | 22 of 26 START test unique_github_issues_issue_id.................... [RUN]
2020-11-18 14:54:49.780085 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_issues_issue_id".
2020-11-18 14:54:49.780172 (Thread-1): Compiling test.github_source.unique_github_issues_issue_id
2020-11-18 14:54:49.789020 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 14:54:49.804458 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 14:54:49.821007 (Thread-1): finished collecting timing info
2020-11-18 14:54:49.821585 (Thread-1): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 55, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:49.822523 (Thread-1): 14:54:49 | 22 of 26 ERROR unique_github_issues_issue_id......................... [ERROR in 0.04s]
2020-11-18 14:54:49.822625 (Thread-1): Finished running node test.github_source.unique_github_issues_issue_id
2020-11-18 14:54:49.822758 (Thread-1): Began running node test.github_source.unique_github_monthly_metrics_month
2020-11-18 14:54:49.822858 (Thread-1): 14:54:49 | 23 of 26 START test unique_github_monthly_metrics_month.............. [RUN]
2020-11-18 14:54:49.823086 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_monthly_metrics_month".
2020-11-18 14:54:49.823172 (Thread-1): Compiling test.github_source.unique_github_monthly_metrics_month
2020-11-18 14:54:49.832032 (Thread-1): Compiling model.github_source.github_monthly_metrics
2020-11-18 14:54:49.845062 (Thread-1): finished collecting timing info
2020-11-18 14:54:49.845624 (Thread-1): Compilation Error in model github_monthly_metrics (models/github/github_monthly_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 9, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_monthly_metrics (models/github/github_monthly_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:49.846604 (Thread-1): 14:54:49 | 23 of 26 ERROR unique_github_monthly_metrics_month................... [ERROR in 0.02s]
2020-11-18 14:54:49.846762 (Thread-1): Finished running node test.github_source.unique_github_monthly_metrics_month
2020-11-18 14:54:49.846977 (Thread-1): Began running node test.github_source.unique_github_pull_requests_issue_id
2020-11-18 14:54:49.847130 (Thread-1): 14:54:49 | 24 of 26 START test unique_github_pull_requests_issue_id............. [RUN]
2020-11-18 14:54:49.847375 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_pull_requests_issue_id".
2020-11-18 14:54:49.847460 (Thread-1): Compiling test.github_source.unique_github_pull_requests_issue_id
2020-11-18 14:54:49.856355 (Thread-1): Compiling model.github_source.github_pull_requests
2020-11-18 14:54:49.866261 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 45680), raddr=('172.217.12.234', 443)>
2020-11-18 14:54:49.866701 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 52486), raddr=('172.217.15.74', 443)>
2020-11-18 14:54:49.874363 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 14:54:49.890601 (Thread-1): finished collecting timing info
2020-11-18 14:54:49.891146 (Thread-1): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 55, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:49.891805 (Thread-1): 14:54:49 | 24 of 26 ERROR unique_github_pull_requests_issue_id.................. [ERROR in 0.04s]
2020-11-18 14:54:49.891904 (Thread-1): Finished running node test.github_source.unique_github_pull_requests_issue_id
2020-11-18 14:54:49.892038 (Thread-1): Began running node test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 14:54:49.892136 (Thread-1): 14:54:49 | 25 of 26 START test unique_github_quarterly_metrics_quarter.......... [RUN]
2020-11-18 14:54:49.892368 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_quarterly_metrics_quarter".
2020-11-18 14:54:49.892452 (Thread-1): Compiling test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 14:54:49.901326 (Thread-1): Compiling model.github_source.github_quarterly_metrics
2020-11-18 14:54:49.913872 (Thread-1): finished collecting timing info
2020-11-18 14:54:49.914392 (Thread-1): Compilation Error in model github_quarterly_metrics (models/github/github_quarterly_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_quarterly_metrics (models/github/github_quarterly_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:49.915526 (Thread-1): 14:54:49 | 25 of 26 ERROR unique_github_quarterly_metrics_quarter............... [ERROR in 0.02s]
2020-11-18 14:54:49.915683 (Thread-1): Finished running node test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 14:54:49.915895 (Thread-1): Began running node test.github_source.unique_github_weekly_metrics_week
2020-11-18 14:54:49.916070 (Thread-1): 14:54:49 | 26 of 26 START test unique_github_weekly_metrics_week................ [RUN]
2020-11-18 14:54:49.916358 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_weekly_metrics_week".
2020-11-18 14:54:49.916450 (Thread-1): Compiling test.github_source.unique_github_weekly_metrics_week
2020-11-18 14:54:49.925489 (Thread-1): Compiling model.github_source.github_weekly_metrics
2020-11-18 14:54:49.937968 (Thread-1): finished collecting timing info
2020-11-18 14:54:49.938475 (Thread-1): Compilation Error in model github_weekly_metrics (models/github/github_weekly_metrics.sql)
  'dbt_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'dbt_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_weekly_metrics (models/github/github_weekly_metrics.sql)
  'dbt_utils' is undefined
2020-11-18 14:54:49.939473 (Thread-1): 14:54:49 | 26 of 26 ERROR unique_github_weekly_metrics_week..................... [ERROR in 0.02s]
2020-11-18 14:54:49.939622 (Thread-1): Finished running node test.github_source.unique_github_weekly_metrics_week
2020-11-18 14:54:49.967350 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 14:54:49.967926 (MainThread): 14:54:49 | 
2020-11-18 14:54:49.968069 (MainThread): 14:54:49 | Finished running 26 tests in 9.80s.
2020-11-18 14:54:49.968175 (MainThread): Connection 'master' was properly closed.
2020-11-18 14:54:49.968255 (MainThread): Connection 'test.github_source.unique_github_weekly_metrics_week' was properly closed.
2020-11-18 14:54:50.042282 (Thread-24): handling poll request
2020-11-18 14:54:50.042846 (Thread-24): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36ba9e8>]}
2020-11-18 14:54:50.050720 (Thread-24): sending response (<Response 49366 bytes [200 OK]>) to 10.0.14.186
2020-11-18 14:54:50.188061 (MainThread): 
2020-11-18 14:54:50.188229 (MainThread): Completed with 22 errors and 0 warnings:
2020-11-18 14:54:50.188298 (MainThread): 
2020-11-18 14:54:50.188362 (MainThread): Compilation Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.188415 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.188469 (MainThread): 
2020-11-18 14:54:50.188528 (MainThread): Compilation Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
2020-11-18 14:54:50.188579 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.188628 (MainThread): 
2020-11-18 14:54:50.188679 (MainThread): Compilation Error in model github_daily_metrics (models/github/github_daily_metrics.sql)
2020-11-18 14:54:50.188727 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.188775 (MainThread): 
2020-11-18 14:54:50.188827 (MainThread): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
2020-11-18 14:54:50.188874 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.188924 (MainThread): 
2020-11-18 14:54:50.188977 (MainThread): Compilation Error in model github_monthly_metrics (models/github/github_monthly_metrics.sql)
2020-11-18 14:54:50.189025 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.189073 (MainThread): 
2020-11-18 14:54:50.189123 (MainThread): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
2020-11-18 14:54:50.189190 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.189242 (MainThread): 
2020-11-18 14:54:50.189298 (MainThread): Compilation Error in model github_quarterly_metrics (models/github/github_quarterly_metrics.sql)
2020-11-18 14:54:50.189344 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.189392 (MainThread): 
2020-11-18 14:54:50.189443 (MainThread): Compilation Error in model github_weekly_metrics (models/github/github_weekly_metrics.sql)
2020-11-18 14:54:50.189489 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.189537 (MainThread): 
2020-11-18 14:54:50.189588 (MainThread): Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.189638 (MainThread):   404 Not found: Table abij-playground:github.issue_comment was not found in location EU
2020-11-18 14:54:50.189683 (MainThread):   
2020-11-18 14:54:50.189727 (MainThread):   (job ID: 35a85c76-09af-4430-be18-ba8f0c58925f)
2020-11-18 14:54:50.189786 (MainThread): 
2020-11-18 14:54:50.189840 (MainThread): Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.189890 (MainThread):   404 Not found: Table abij-playground:github.issue was not found in location EU
2020-11-18 14:54:50.189955 (MainThread):   
2020-11-18 14:54:50.190018 (MainThread):   (job ID: be9ed975-a43a-4c5f-bf07-ed9e70ec065c)
2020-11-18 14:54:50.190069 (MainThread): 
2020-11-18 14:54:50.190123 (MainThread): Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.190173 (MainThread):   404 Not found: Table abij-playground:github.pull_request was not found in location EU
2020-11-18 14:54:50.190220 (MainThread):   
2020-11-18 14:54:50.190264 (MainThread):   (job ID: fef2d03b-aa9a-4296-aebf-3c65d9c36d2a)
2020-11-18 14:54:50.190319 (MainThread): 
2020-11-18 14:54:50.190374 (MainThread): Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.190420 (MainThread):   404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
2020-11-18 14:54:50.190464 (MainThread):   
2020-11-18 14:54:50.190509 (MainThread):   (job ID: 2e876b3c-5b85-4c64-be97-ebfd6199a793)
2020-11-18 14:54:50.190557 (MainThread): 
2020-11-18 14:54:50.190608 (MainThread): Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.190654 (MainThread):   404 Not found: Table abij-playground:github.issue_comment was not found in location EU
2020-11-18 14:54:50.190697 (MainThread):   
2020-11-18 14:54:50.190753 (MainThread):   (job ID: c30524b1-826f-4098-bed7-da2615fee82c)
2020-11-18 14:54:50.190803 (MainThread): 
2020-11-18 14:54:50.190855 (MainThread): Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.190901 (MainThread):   404 Not found: Table abij-playground:github.issue was not found in location EU
2020-11-18 14:54:50.190943 (MainThread):   
2020-11-18 14:54:50.190985 (MainThread):   (job ID: 28240463-807b-46f6-9ccf-b6dbe5e290e1)
2020-11-18 14:54:50.191030 (MainThread): 
2020-11-18 14:54:50.191080 (MainThread): Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.191129 (MainThread):   404 Not found: Table abij-playground:github.pull_request was not found in location EU
2020-11-18 14:54:50.191174 (MainThread):   
2020-11-18 14:54:50.191216 (MainThread):   (job ID: 8bde89d2-b4b5-4f1d-ad48-cb3307077cac)
2020-11-18 14:54:50.191261 (MainThread): 
2020-11-18 14:54:50.191312 (MainThread): Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
2020-11-18 14:54:50.191359 (MainThread):   404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
2020-11-18 14:54:50.191403 (MainThread):   
2020-11-18 14:54:50.191446 (MainThread):   (job ID: 69084b10-1f87-4d84-ae57-b4b996d6bd9b)
2020-11-18 14:54:50.191497 (MainThread): 
2020-11-18 14:54:50.191551 (MainThread): Compilation Error in model github_daily_metrics (models/github/github_daily_metrics.sql)
2020-11-18 14:54:50.191597 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.191643 (MainThread): 
2020-11-18 14:54:50.191693 (MainThread): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
2020-11-18 14:54:50.191738 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.191784 (MainThread): 
2020-11-18 14:54:50.191836 (MainThread): Compilation Error in model github_monthly_metrics (models/github/github_monthly_metrics.sql)
2020-11-18 14:54:50.191886 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.191936 (MainThread): 
2020-11-18 14:54:50.191989 (MainThread): Compilation Error in model github_issue_joined (models/github/github_issue_joined.sql)
2020-11-18 14:54:50.192035 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.192081 (MainThread): 
2020-11-18 14:54:50.192131 (MainThread): Compilation Error in model github_quarterly_metrics (models/github/github_quarterly_metrics.sql)
2020-11-18 14:54:50.192177 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.192223 (MainThread): 
2020-11-18 14:54:50.192277 (MainThread): Compilation Error in model github_weekly_metrics (models/github/github_weekly_metrics.sql)
2020-11-18 14:54:50.192324 (MainThread):   'dbt_utils' is undefined
2020-11-18 14:54:50.192389 (MainThread): 
Done. PASS=4 WARN=0 ERROR=22 SKIP=0 TOTAL=26
2020-11-18 14:54:51.343304 (Thread-25): handling poll request
2020-11-18 14:54:51.343806 (Thread-25): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3653e48>]}
2020-11-18 14:54:51.441958 (Thread-25): sending response (<Response 90246 bytes [200 OK]>) to 10.0.21.190
2020-11-18 14:54:51.737652 (Thread-26): handling status request
2020-11-18 14:54:51.738352 (Thread-26): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36bada0>]}
2020-11-18 14:54:51.748975 (Thread-26): sending response (<Response 16806 bytes [200 OK]>) to 10.0.18.208
2020-11-18 15:31:20.041043 (Thread-27): handling status request
2020-11-18 15:31:20.043045 (Thread-27): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36531d0>]}
2020-11-18 15:31:20.049741 (Thread-27): sending response (<Response 16806 bytes [200 OK]>) to 10.0.34.62
2020-11-18 15:31:20.055624 (Thread-28): handling status request
2020-11-18 15:31:20.056202 (Thread-28): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3602710>]}
2020-11-18 15:31:20.063337 (Thread-28): sending response (<Response 16806 bytes [200 OK]>) to 10.0.34.62
2020-11-18 15:31:20.369845 (Thread-29): handling cli_args request
2020-11-18 15:31:20.370386 (Thread-29): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36bab00>]}
2020-11-18 15:31:20.379758 (Thread-29): API Exception: {'type': 'InternalException', 'args': ('No matching handler found for rpc method None (which=clean)',), 'message': 'No matching handler found for rpc method None (which=clean)'}
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/jsonrpc/manager.py", line 113, in _get_responses
    result = method(*request.args, **request.kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/rpc/task_handler.py", line 503, in __call__
    return self.handle(kwargs)
  File "/usr/local/lib/python3.6/dist-packages/dbt/rpc/task_handler.py", line 466, in handle
    self.task.set_args(self.task_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/rpc/cli.py", line 60, in set_args
    self.task_type = self.get_rpc_task_cls()
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/rpc/cli.py", line 79, in get_rpc_task_cls
    .format(self.args.rpc_method, self.args.which)
dbt.exceptions.InternalException: No matching handler found for rpc method None (which=clean)
2020-11-18 15:31:20.380631 (Thread-29): sending response (<Response 308 bytes [200 OK]>) to 10.0.5.154
2020-11-18 15:31:22.178373 (Thread-30): handling status request
2020-11-18 15:31:22.186798 (Thread-30): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3635ba8>]}
2020-11-18 15:31:22.188802 (Thread-30): Checking header 'user-agent' tracing in whitelist set(), 44 additional messages skipped
2020-11-18 15:31:22.259594 (Thread-30): writing 1 spans (enabled:True), 359 additional messages skipped
2020-11-18 15:31:22.272256 (Thread-30): 
      name requests.request
        id 13517121246312935354
  trace_id 4482031607331228975
 parent_id None
   service requests
  resource requests.request
      type http
     start 1605713482.188363
       end 1605713482.259478
  duration 0.071115s
     error 0
      tags 
           http.method:POST
           http.status_code:200
           http.url:https://fishtownanalytics.sinter-collect.com/com.snowplowanalytics.snowplow/tp2
           runtime-id:fbe41a1a9fef4dc6b4d89ae108b31842, 418 additional messages skipped
2020-11-18 15:31:22.280049 (Thread-30): sending response (<Response 16806 bytes [200 OK]>) to 10.0.18.40
2020-11-18 15:31:22.298045 (AgentWriter): reported 1 traces in 0.00375s, 3 additional messages skipped
2020-11-18 15:31:22.312405 (AgentWriter): initialized RateSampler, sample 100% of traces, 127 additional messages skipped
2020-11-18 15:32:39.122448 (Thread-31): handling status request
2020-11-18 15:32:39.124769 (Thread-31): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36027b8>]}
2020-11-18 15:32:39.131301 (Thread-31): sending response (<Response 16806 bytes [200 OK]>) to 10.0.18.208
2020-11-18 15:32:39.152957 (Thread-32): handling status request
2020-11-18 15:32:39.153487 (Thread-32): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3637160>]}
2020-11-18 15:32:39.159870 (Thread-32): sending response (<Response 16806 bytes [200 OK]>) to 10.0.41.79
2020-11-18 15:32:39.427754 (Thread-33): handling deps request
2020-11-18 15:32:39.428437 (Thread-33): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3675f60>]}
2020-11-18 15:32:39.451581 (Thread-33): writing 1 spans (enabled:True)
2020-11-18 15:32:39.451819 (Thread-33): 
      name jinja2.compile
        id 5893625060315938497
  trace_id 12331234111833341473
 parent_id None
   service None
  resource <memory>
      type template
     start 1605713559.450687
       end 1605713559.451417
  duration 0.000730s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:fbe41a1a9fef4dc6b4d89ae108b31842
2020-11-18 15:32:39.496422 (Thread-33): sending response (<Response 137 bytes [200 OK]>) to 10.0.30.126
2020-11-18 15:32:39.799810 (Thread-34): handling poll request
2020-11-18 15:32:39.800386 (Thread-34): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc841c358>]}
2020-11-18 15:32:39.802097 (Thread-34): sending response (<Response 288 bytes [200 OK]>) to 10.0.14.186
2020-11-18 15:32:40.327214 (AgentWriter): reported 25 traces in 0.00428s
2020-11-18 15:32:40.327502 (AgentWriter): initialized RateSampler, sample 100% of traces, 31 additional messages skipped
2020-11-18 15:32:40.529072 (MainThread): Set downloads directory='/tmp/dbt-downloads-8e8gpnj0'
2020-11-18 15:32:40.533995 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2020-11-18 15:32:40.596640 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2020-11-18 15:32:40.597421 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2020-11-18 15:32:40.649465 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2020-11-18 15:32:40.674638 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json
2020-11-18 15:32:40.724167 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json 200
2020-11-18 15:32:40.732170 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2020-11-18 15:32:40.777580 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2020-11-18 15:32:40.794706 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json
2020-11-18 15:32:40.837989 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json 200
2020-11-18 15:32:40.839233 (MainThread): Installing fishtown-analytics/dbt_utils@0.6.2
2020-11-18 15:32:41.126579 (Thread-35): handling poll request
2020-11-18 15:32:41.127096 (Thread-35): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8461be0>]}
2020-11-18 15:32:41.129670 (Thread-35): sending response (<Response 4144 bytes [200 OK]>) to 10.0.5.154
2020-11-18 15:32:42.404908 (Thread-36): handling poll request
2020-11-18 15:32:42.405478 (Thread-36): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8461be0>]}
2020-11-18 15:32:42.406512 (Thread-36): sending response (<Response 287 bytes [200 OK]>) to 10.0.18.208
2020-11-18 15:32:43.699597 (Thread-37): handling poll request
2020-11-18 15:32:43.700094 (Thread-37): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc80e4f98>]}
2020-11-18 15:32:43.701117 (Thread-37): sending response (<Response 288 bytes [200 OK]>) to 10.0.41.79
2020-11-18 15:32:44.981757 (Thread-38): handling poll request
2020-11-18 15:32:44.982250 (Thread-38): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc36335f8>]}
2020-11-18 15:32:44.983310 (Thread-38): sending response (<Response 288 bytes [200 OK]>) to 10.0.18.40
2020-11-18 15:32:46.310076 (Thread-39): handling poll request
2020-11-18 15:32:46.310583 (Thread-39): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3635278>]}
2020-11-18 15:32:46.311594 (Thread-39): sending response (<Response 288 bytes [200 OK]>) to 10.0.34.62
2020-11-18 15:32:46.707540 (MainThread):   Installed from version 0.6.2

2020-11-18 15:32:46.707767 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'ebc0c706-c8fe-4914-ad64-ffc8fc9bcd62', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac39ec278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ac39ec320>]}
2020-11-18 15:32:46.969552 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): project hash mismatch: values missing, cache invalidated: {'dbt_utils'}
2020-11-18 15:32:46.970617 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/adapters.sql
2020-11-18 15:32:46.992065 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/etc.sql
2020-11-18 15:32:46.993493 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/catalog.sql
2020-11-18 15:32:46.999613 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/table.sql
2020-11-18 15:32:47.010036 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/view.sql
2020-11-18 15:32:47.013076 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/copy.sql
2020-11-18 15:32:47.017730 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/seed.sql
2020-11-18 15:32:47.020601 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/incremental.sql
2020-11-18 15:32:47.034434 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/snapshot.sql
2020-11-18 15:32:47.039066 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/core.sql
2020-11-18 15:32:47.044445 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/adapters/common.sql
2020-11-18 15:32:47.105689 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/helpers.sql
2020-11-18 15:32:47.115395 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/table/table.sql
2020-11-18 15:32:47.122877 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/seed/seed.sql
2020-11-18 15:32:47.144608 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/view/view.sql
2020-11-18 15:32:47.151754 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 15:32:47.158031 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 15:32:47.160063 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 15:32:47.166720 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/common/merge.sql
2020-11-18 15:32:47.181596 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 15:32:47.199069 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 15:32:47.200999 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 15:32:47.230646 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/relationships.sql
2020-11-18 15:32:47.232879 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/not_null.sql
2020-11-18 15:32:47.234609 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/unique.sql
2020-11-18 15:32:47.236417 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 15:32:47.239308 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/etc/get_custom_database.sql
2020-11-18 15:32:47.241073 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/etc/query.sql
2020-11-18 15:32:47.242252 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/etc/datetime.sql
2020-11-18 15:32:47.251794 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/etc/get_custom_alias.sql
2020-11-18 15:32:47.252871 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/etc/is_incremental.sql
2020-11-18 15:32:47.254630 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/etc/get_custom_schema.sql
2020-11-18 15:32:47.298307 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/logger/pretty_time.sql
2020-11-18 15:32:47.313274 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/logger/log_info.sql
2020-11-18 15:32:47.319153 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/logger/pretty_log_format.sql
2020-11-18 15:32:47.325346 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/pivot.sql
2020-11-18 15:32:47.334426 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/star.sql
2020-11-18 15:32:47.343144 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/surrogate_key.sql
2020-11-18 15:32:47.351499 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/get_query_results_as_dict.sql
2020-11-18 15:32:47.360243 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/get_column_values.sql
2020-11-18 15:32:47.372583 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/groupby.sql
2020-11-18 15:32:47.379501 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/get_tables_by_pattern_sql.sql
2020-11-18 15:32:47.395864 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/nullcheck_table.sql
2020-11-18 15:32:47.402835 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/get_tables_by_prefix_sql.sql
2020-11-18 15:32:47.410062 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/get_relations_by_pattern.sql
2020-11-18 15:32:47.420281 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/get_relations_by_prefix.sql
2020-11-18 15:32:47.428740 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/safe_add.sql
2020-11-18 15:32:47.435293 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/unpivot.sql
2020-11-18 15:32:47.447429 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/generate_series.sql
2020-11-18 15:32:47.457244 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/nullcheck.sql
2020-11-18 15:32:47.463704 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/sql/union.sql
2020-11-18 15:32:47.478453 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/materializations/insert_by_period_materialization.sql
2020-11-18 15:32:47.508310 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/web/get_url_parameter.sql
2020-11-18 15:32:47.514838 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/web/get_url_path.sql
2020-11-18 15:32:47.522271 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/web/get_url_host.sql
2020-11-18 15:32:47.528839 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/datetime/date_spine.sql
2020-11-18 15:32:47.537319 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/expression_is_true.sql
2020-11-18 15:32:47.543408 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/not_constant.sql
2020-11-18 15:32:47.549223 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/at_least_one.sql
2020-11-18 15:32:47.555393 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/equality.sql
2020-11-18 15:32:47.563952 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/test_not_null_where.sql
2020-11-18 15:32:47.570321 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/equal_rowcount.sql
2020-11-18 15:32:47.577410 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/test_unique_where.sql
2020-11-18 15:32:47.585317 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2020-11-18 15:32:47.596156 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/relationships_where.sql
2020-11-18 15:32:47.603553 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/unique_combination_of_columns.sql
2020-11-18 15:32:47.612648 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/recency.sql
2020-11-18 15:32:47.621616 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/schema_tests/cardinality_equality.sql
2020-11-18 15:32:47.630235 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/geo/haversine_distance.sql
2020-11-18 15:32:47.632687 (Thread-40): handling poll request
2020-11-18 15:32:47.633355 (Thread-40): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3562cc0>]}
2020-11-18 15:32:47.635054 (Thread-40): sending response (<Response 1096 bytes [200 OK]>) to 10.0.37.56
2020-11-18 15:32:47.638478 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/split_part.sql
2020-11-18 15:32:47.646997 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/length.sql
2020-11-18 15:32:47.654887 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/current_timestamp.sql
2020-11-18 15:32:47.667799 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/_get_utils_namespaces.sql
2020-11-18 15:32:47.675485 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/right.sql
2020-11-18 15:32:47.686110 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/hash.sql
2020-11-18 15:32:47.694600 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/replace.sql
2020-11-18 15:32:47.701499 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/concat.sql
2020-11-18 15:32:47.709537 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/_is_relation.sql
2020-11-18 15:32:47.715838 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/identifier.sql
2020-11-18 15:32:47.722808 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/datediff.sql
2020-11-18 15:32:47.865379 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/dateadd.sql
2020-11-18 15:32:47.874197 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/datatypes.sql
2020-11-18 15:32:47.892861 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/position.sql
2020-11-18 15:32:47.901991 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/literal.sql
2020-11-18 15:32:47.909416 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/_is_ephemeral.sql
2020-11-18 15:32:47.917862 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/width_bucket.sql
2020-11-18 15:32:47.935418 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/date_trunc.sql
2020-11-18 15:32:47.941927 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/except.sql
2020-11-18 15:32:47.948089 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/safe_cast.sql
2020-11-18 15:32:47.955313 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/last_day.sql
2020-11-18 15:32:47.963589 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Parsing macros/cross_db_utils/intersect.sql
2020-11-18 15:32:47.986655 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): project hash mismatch: values missing, cache invalidated: {'dbt_utils'}
2020-11-18 15:32:48.038506 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 15:32:48.058972 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 15:32:48.076939 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 15:32:48.095603 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 15:32:48.115123 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 15:32:48.148200 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 15:32:48.167259 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 15:32:48.189244 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 15:32:48.221383 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 15:32:48.242510 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 15:32:48.263502 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 15:32:48.282718 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 15:32:48.300599 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 15:32:48.319083 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 15:32:48.337867 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 15:32:48.357580 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 15:32:48.376078 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 15:32:48.394598 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 15:32:48.413035 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 15:32:48.432853 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 15:32:48.453087 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 15:32:48.472299 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 15:32:48.494859 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 15:32:48.525323 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 15:32:48.950679 (Thread-41): handling poll request
2020-11-18 15:32:48.951305 (Thread-41): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8090d68>]}
2020-11-18 15:32:48.952798 (Thread-41): sending response (<Response 288 bytes [200 OK]>) to 10.0.14.29
2020-11-18 15:32:49.833697 (f8213477-0678-4551-af43-060fb9bbf139-handler-deps): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github
- models.github.intermediate

2020-11-18 15:32:50.232038 (Thread-42): handling poll request
2020-11-18 15:32:50.232566 (Thread-42): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc829bf60>]}
2020-11-18 15:32:50.233775 (Thread-42): sending response (<Response 314 bytes [200 OK]>) to 10.0.5.154
2020-11-18 15:32:50.535994 (Thread-43): handling status request
2020-11-18 15:32:50.536620 (Thread-43): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc829bc50>]}
2020-11-18 15:32:50.539010 (Thread-43): sending response (<Response 4846 bytes [200 OK]>) to 10.0.3.20
2020-11-18 15:32:54.144985 (Thread-44): handling status request
2020-11-18 15:32:54.145533 (Thread-44): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37c7e10>]}
2020-11-18 15:32:54.147775 (Thread-44): sending response (<Response 4846 bytes [200 OK]>) to 10.0.14.177
2020-11-18 15:32:54.169603 (Thread-45): handling status request
2020-11-18 15:32:54.170083 (Thread-45): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8390b00>]}
2020-11-18 15:32:54.172347 (Thread-45): sending response (<Response 4846 bytes [200 OK]>) to 10.0.44.246
2020-11-18 15:32:54.433597 (Thread-46): handling cli_args request
2020-11-18 15:32:54.434157 (Thread-46): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc83c4f98>]}
2020-11-18 15:32:54.443496 (Thread-46): Connection 'model.github_source.stg_github_pull_request_review' was properly closed.
2020-11-18 15:32:55.469728 (Thread-46): sending response (<Response 137 bytes [200 OK]>) to 10.0.14.186
2020-11-18 15:32:55.565963 (MainThread): Partial parsing not enabled
2020-11-18 15:32:55.567441 (MainThread): Parsing macros/adapters.sql
2020-11-18 15:32:55.588425 (MainThread): Parsing macros/etc.sql
2020-11-18 15:32:55.589932 (MainThread): Parsing macros/catalog.sql
2020-11-18 15:32:55.596277 (MainThread): Parsing macros/materializations/table.sql
2020-11-18 15:32:55.607017 (MainThread): Parsing macros/materializations/view.sql
2020-11-18 15:32:55.610165 (MainThread): Parsing macros/materializations/copy.sql
2020-11-18 15:32:55.614908 (MainThread): Parsing macros/materializations/seed.sql
2020-11-18 15:32:55.617909 (MainThread): Parsing macros/materializations/incremental.sql
2020-11-18 15:32:55.631585 (MainThread): Parsing macros/materializations/snapshot.sql
2020-11-18 15:32:55.634526 (MainThread): Parsing macros/core.sql
2020-11-18 15:32:55.638487 (MainThread): Parsing macros/adapters/common.sql
2020-11-18 15:32:55.683551 (MainThread): Parsing macros/materializations/helpers.sql
2020-11-18 15:32:55.693369 (MainThread): Parsing macros/materializations/table/table.sql
2020-11-18 15:32:55.700861 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-11-18 15:32:55.722727 (MainThread): Parsing macros/materializations/view/view.sql
2020-11-18 15:32:55.729517 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 15:32:55.734865 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 15:32:55.736903 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 15:32:55.748239 (Thread-47): handling poll request
2020-11-18 15:32:55.748761 (Thread-47): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc80f7080>]}
2020-11-18 15:32:55.752501 (Thread-47): sending response (<Response 5480 bytes [200 OK]>) to 10.0.5.154
2020-11-18 15:32:55.743641 (MainThread): Parsing macros/materializations/common/merge.sql
2020-11-18 15:32:55.758588 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 15:32:55.776279 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 15:32:55.778322 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 15:32:55.808117 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-11-18 15:32:55.810388 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-11-18 15:32:55.812120 (MainThread): Parsing macros/schema_tests/unique.sql
2020-11-18 15:32:55.814025 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 15:32:55.816913 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-11-18 15:32:55.818744 (MainThread): Parsing macros/etc/query.sql
2020-11-18 15:32:55.819939 (MainThread): Parsing macros/etc/datetime.sql
2020-11-18 15:32:55.829490 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-11-18 15:32:55.830601 (MainThread): Parsing macros/etc/is_incremental.sql
2020-11-18 15:32:55.832401 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-11-18 15:32:55.852003 (MainThread): Parsing macros/logger/pretty_time.sql
2020-11-18 15:32:55.856706 (MainThread): Parsing macros/logger/log_info.sql
2020-11-18 15:32:55.860788 (MainThread): Parsing macros/logger/pretty_log_format.sql
2020-11-18 15:32:55.864811 (MainThread): Parsing macros/sql/pivot.sql
2020-11-18 15:32:55.871042 (MainThread): Parsing macros/sql/star.sql
2020-11-18 15:32:55.878230 (MainThread): Parsing macros/sql/surrogate_key.sql
2020-11-18 15:32:55.884841 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2020-11-18 15:32:55.890394 (MainThread): Parsing macros/sql/get_column_values.sql
2020-11-18 15:32:55.898733 (MainThread): Parsing macros/sql/groupby.sql
2020-11-18 15:32:55.903667 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2020-11-18 15:32:55.913965 (MainThread): Parsing macros/sql/nullcheck_table.sql
2020-11-18 15:32:55.919144 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2020-11-18 15:32:55.923833 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2020-11-18 15:32:55.930330 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2020-11-18 15:32:55.937191 (MainThread): Parsing macros/sql/safe_add.sql
2020-11-18 15:32:55.941886 (MainThread): Parsing macros/sql/unpivot.sql
2020-11-18 15:32:55.952205 (MainThread): Parsing macros/sql/generate_series.sql
2020-11-18 15:32:55.959624 (MainThread): Parsing macros/sql/nullcheck.sql
2020-11-18 15:32:55.964699 (MainThread): Parsing macros/sql/union.sql
2020-11-18 15:32:55.977111 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2020-11-18 15:32:56.005593 (MainThread): Parsing macros/web/get_url_parameter.sql
2020-11-18 15:32:56.010486 (MainThread): Parsing macros/web/get_url_path.sql
2020-11-18 15:32:56.016317 (MainThread): Parsing macros/web/get_url_host.sql
2020-11-18 15:32:56.021550 (MainThread): Parsing macros/datetime/date_spine.sql
2020-11-18 15:32:56.030254 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2020-11-18 15:32:56.035199 (MainThread): Parsing macros/schema_tests/not_constant.sql
2020-11-18 15:32:56.040077 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2020-11-18 15:32:56.044662 (MainThread): Parsing macros/schema_tests/equality.sql
2020-11-18 15:32:56.052837 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2020-11-18 15:32:56.058422 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2020-11-18 15:32:56.063310 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2020-11-18 15:32:56.068446 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2020-11-18 15:32:56.078082 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2020-11-18 15:32:56.084005 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2020-11-18 15:32:56.090794 (MainThread): Parsing macros/schema_tests/recency.sql
2020-11-18 15:32:56.096421 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2020-11-18 15:32:56.102751 (MainThread): Parsing macros/geo/haversine_distance.sql
2020-11-18 15:32:56.107444 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2020-11-18 15:32:56.113005 (MainThread): Parsing macros/cross_db_utils/length.sql
2020-11-18 15:32:56.118790 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2020-11-18 15:32:56.127416 (MainThread): Parsing macros/cross_db_utils/_get_utils_namespaces.sql
2020-11-18 15:32:56.133178 (MainThread): Parsing macros/cross_db_utils/right.sql
2020-11-18 15:32:56.139271 (MainThread): Parsing macros/cross_db_utils/hash.sql
2020-11-18 15:32:56.145561 (MainThread): Parsing macros/cross_db_utils/replace.sql
2020-11-18 15:32:56.151869 (MainThread): Parsing macros/cross_db_utils/concat.sql
2020-11-18 15:32:56.158793 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2020-11-18 15:32:56.163514 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2020-11-18 15:32:56.169240 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2020-11-18 15:32:56.183567 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2020-11-18 15:32:56.190062 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2020-11-18 15:32:56.200972 (MainThread): Parsing macros/cross_db_utils/position.sql
2020-11-18 15:32:56.206278 (MainThread): Parsing macros/cross_db_utils/literal.sql
2020-11-18 15:32:56.211120 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2020-11-18 15:32:56.216959 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2020-11-18 15:32:56.226678 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2020-11-18 15:32:56.232283 (MainThread): Parsing macros/cross_db_utils/except.sql
2020-11-18 15:32:56.237190 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2020-11-18 15:32:56.243226 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2020-11-18 15:32:56.250613 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2020-11-18 15:32:56.265753 (MainThread): Partial parsing not enabled
2020-11-18 15:32:56.324439 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 15:32:56.354909 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 15:32:56.372998 (MainThread): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 15:32:56.390793 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 15:32:56.411936 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 15:32:56.446073 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 15:32:56.463894 (MainThread): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 15:32:56.485323 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 15:32:56.516429 (MainThread): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 15:32:56.538701 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 15:32:56.558531 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 15:32:56.578577 (MainThread): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 15:32:56.597130 (MainThread): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 15:32:56.616060 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 15:32:56.633863 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 15:32:56.653841 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 15:32:56.675290 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 15:32:56.695358 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 15:32:56.714792 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 15:32:56.733034 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 15:32:56.751008 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 15:32:56.770599 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 15:32:56.797509 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 15:32:56.872171 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 15:32:57.047735 (Thread-48): handling poll request
2020-11-18 15:32:57.048258 (Thread-48): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82aa358>]}
2020-11-18 15:32:57.060405 (Thread-48): sending response (<Response 28211 bytes [200 OK]>) to 10.0.41.79
2020-11-18 15:32:58.021852 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github.intermediate
- models.github

2020-11-18 15:32:58.142620 (MainThread): Found 24 models, 26 tests, 0 snapshots, 0 analyses, 287 macros, 0 operations, 0 seed files, 11 sources
2020-11-18 15:32:58.149286 (MainThread): 
2020-11-18 15:32:58.149667 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 15:32:58.187141 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_abij-playground_dbt_abij".
2020-11-18 15:32:58.187339 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-11-18 15:32:58.187920 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-18 15:32:58.342186 (Thread-49): handling poll request
2020-11-18 15:32:58.342713 (Thread-49): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82d3d68>]}
2020-11-18 15:32:58.344383 (Thread-49): sending response (<Response 2206 bytes [200 OK]>) to 10.0.14.29
2020-11-18 15:32:58.396621 (MainThread): 15:32:58 | Concurrency: 1 threads (target='default')
2020-11-18 15:32:58.396779 (MainThread): 15:32:58 | 
2020-11-18 15:32:58.399146 (Thread-1): Began running node model.github_source.stg_github_issue
2020-11-18 15:32:58.399518 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 15:32:58.399636 (Thread-1): Compiling model.github_source.stg_github_issue
2020-11-18 15:32:58.418085 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue"
2020-11-18 15:32:58.437985 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.438684 (Thread-1): Finished running node model.github_source.stg_github_issue
2020-11-18 15:32:58.438837 (Thread-1): Began running node model.github_source.stg_github_issue_assignee
2020-11-18 15:32:58.439067 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 15:32:58.439156 (Thread-1): Compiling model.github_source.stg_github_issue_assignee
2020-11-18 15:32:58.455661 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 41238), raddr=('172.217.13.74', 443)>
2020-11-18 15:32:58.455943 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 58646), raddr=('172.217.13.234', 443)>
2020-11-18 15:32:58.456631 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_assignee"
2020-11-18 15:32:58.478141 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.478831 (Thread-1): Finished running node model.github_source.stg_github_issue_assignee
2020-11-18 15:32:58.478989 (Thread-1): Began running node model.github_source.stg_github_issue_closed_history
2020-11-18 15:32:58.479217 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 15:32:58.479307 (Thread-1): Compiling model.github_source.stg_github_issue_closed_history
2020-11-18 15:32:58.489054 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_closed_history"
2020-11-18 15:32:58.508340 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.509010 (Thread-1): Finished running node model.github_source.stg_github_issue_closed_history
2020-11-18 15:32:58.509187 (Thread-1): Began running node model.github_source.stg_github_issue_comment
2020-11-18 15:32:58.509420 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 15:32:58.509513 (Thread-1): Compiling model.github_source.stg_github_issue_comment
2020-11-18 15:32:58.519268 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_comment"
2020-11-18 15:32:58.542159 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.542831 (Thread-1): Finished running node model.github_source.stg_github_issue_comment
2020-11-18 15:32:58.542987 (Thread-1): Began running node model.github_source.stg_github_issue_label
2020-11-18 15:32:58.543218 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 15:32:58.543307 (Thread-1): Compiling model.github_source.stg_github_issue_label
2020-11-18 15:32:58.553310 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_label"
2020-11-18 15:32:58.575186 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.575842 (Thread-1): Finished running node model.github_source.stg_github_issue_label
2020-11-18 15:32:58.575992 (Thread-1): Began running node model.github_source.stg_github_issue_merged
2020-11-18 15:32:58.576226 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 15:32:58.576315 (Thread-1): Compiling model.github_source.stg_github_issue_merged
2020-11-18 15:32:58.586102 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_merged"
2020-11-18 15:32:58.604225 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.604882 (Thread-1): Finished running node model.github_source.stg_github_issue_merged
2020-11-18 15:32:58.605036 (Thread-1): Began running node model.github_source.stg_github_pull_request
2020-11-18 15:32:58.605301 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 15:32:58.605394 (Thread-1): Compiling model.github_source.stg_github_pull_request
2020-11-18 15:32:58.615224 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_pull_request"
2020-11-18 15:32:58.644328 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.644990 (Thread-1): Finished running node model.github_source.stg_github_pull_request
2020-11-18 15:32:58.645142 (Thread-1): Began running node model.github_source.stg_github_pull_request_review
2020-11-18 15:32:58.645406 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 15:32:58.645501 (Thread-1): Compiling model.github_source.stg_github_pull_request_review
2020-11-18 15:32:58.655338 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_pull_request_review"
2020-11-18 15:32:58.675975 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.676639 (Thread-1): Finished running node model.github_source.stg_github_pull_request_review
2020-11-18 15:32:58.676796 (Thread-1): Began running node model.github_source.stg_github_repository
2020-11-18 15:32:58.677028 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 15:32:58.677122 (Thread-1): Compiling model.github_source.stg_github_repository
2020-11-18 15:32:58.687141 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_repository"
2020-11-18 15:32:58.705979 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.706640 (Thread-1): Finished running node model.github_source.stg_github_repository
2020-11-18 15:32:58.706793 (Thread-1): Began running node model.github_source.stg_github_requested_reviewer_history
2020-11-18 15:32:58.707019 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 15:32:58.707110 (Thread-1): Compiling model.github_source.stg_github_requested_reviewer_history
2020-11-18 15:32:58.717024 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_requested_reviewer_history"
2020-11-18 15:32:58.735863 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.736527 (Thread-1): Finished running node model.github_source.stg_github_requested_reviewer_history
2020-11-18 15:32:58.736681 (Thread-1): Began running node model.github_source.stg_github_user
2020-11-18 15:32:58.736913 (Thread-1): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 15:32:58.737004 (Thread-1): Compiling model.github_source.stg_github_user
2020-11-18 15:32:58.748225 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_user"
2020-11-18 15:32:58.767132 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.767805 (Thread-1): Finished running node model.github_source.stg_github_user
2020-11-18 15:32:58.767954 (Thread-1): Began running node model.github_source.github_issue_open_length
2020-11-18 15:32:58.768182 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 15:32:58.768273 (Thread-1): Compiling model.github_source.github_issue_open_length
2020-11-18 15:32:58.792719 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_open_length"
2020-11-18 15:32:58.804735 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.805452 (Thread-1): Finished running node model.github_source.github_issue_open_length
2020-11-18 15:32:58.805623 (Thread-1): Began running node model.github_source.github_issue_comments
2020-11-18 15:32:58.805858 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 15:32:58.805952 (Thread-1): Compiling model.github_source.github_issue_comments
2020-11-18 15:32:58.816711 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_comments"
2020-11-18 15:32:58.838504 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.839208 (Thread-1): Finished running node model.github_source.github_issue_comments
2020-11-18 15:32:58.839368 (Thread-1): Began running node model.github_source.github_issue_labels
2020-11-18 15:32:58.839603 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 15:32:58.839698 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:32:58.848655 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.849206 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:32:58.850606 (Thread-1): Finished running node model.github_source.github_issue_labels
2020-11-18 15:32:58.850759 (Thread-1): Began running node model.github_source.github_pull_request_times
2020-11-18 15:32:58.851042 (Thread-1): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 15:32:58.851135 (Thread-1): Compiling model.github_source.github_pull_request_times
2020-11-18 15:32:58.894338 (Thread-1): Writing injected SQL for node "model.github_source.github_pull_request_times"
2020-11-18 15:32:58.923036 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.923838 (Thread-1): Finished running node model.github_source.github_pull_request_times
2020-11-18 15:32:58.924027 (Thread-1): Began running node model.github_source.github_issue_assignees
2020-11-18 15:32:58.924275 (Thread-1): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 15:32:58.924386 (Thread-1): Compiling model.github_source.github_issue_assignees
2020-11-18 15:32:58.934002 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.934504 (Thread-1): Compilation Error in model github_issue_assignees (models/github/github_issue_assignees.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 15, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_assignees (models/github/github_issue_assignees.sql)
  'fivetran_utils' is undefined
2020-11-18 15:32:58.935223 (Thread-1): Finished running node model.github_source.github_issue_assignees
2020-11-18 15:32:58.935363 (Thread-1): Began running node model.github_source.github_pull_request_reviewers
2020-11-18 15:32:58.935619 (Thread-1): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 15:32:58.935713 (Thread-1): Compiling model.github_source.github_pull_request_reviewers
2020-11-18 15:32:58.946251 (Thread-1): finished collecting timing info
2020-11-18 15:32:58.946748 (Thread-1): Compilation Error in model github_pull_request_reviewers (models/github/github_pull_request_reviewers.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 15, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_pull_request_reviewers (models/github/github_pull_request_reviewers.sql)
  'fivetran_utils' is undefined
2020-11-18 15:32:58.947698 (Thread-1): Finished running node model.github_source.github_pull_request_reviewers
2020-11-18 15:32:58.948358 (Thread-1): Began running node model.github_source.github_issue_joined
2020-11-18 15:32:58.948461 (Thread-1): Finished running node model.github_source.github_issue_joined
2020-11-18 15:32:58.948933 (Thread-1): Began running node model.github_source.github_issues
2020-11-18 15:32:58.949022 (Thread-1): Finished running node model.github_source.github_issues
2020-11-18 15:32:58.949107 (Thread-1): Began running node model.github_source.github_pull_requests
2020-11-18 15:32:58.949215 (Thread-1): Finished running node model.github_source.github_pull_requests
2020-11-18 15:32:58.949727 (Thread-1): Began running node model.github_source.github_daily_metrics
2020-11-18 15:32:58.949819 (Thread-1): Finished running node model.github_source.github_daily_metrics
2020-11-18 15:32:58.950316 (Thread-1): Began running node model.github_source.github_monthly_metrics
2020-11-18 15:32:58.950401 (Thread-1): Finished running node model.github_source.github_monthly_metrics
2020-11-18 15:32:58.950484 (Thread-1): Began running node model.github_source.github_quarterly_metrics
2020-11-18 15:32:58.950571 (Thread-1): Finished running node model.github_source.github_quarterly_metrics
2020-11-18 15:32:58.950648 (Thread-1): Began running node model.github_source.github_weekly_metrics
2020-11-18 15:32:58.950722 (Thread-1): Finished running node model.github_source.github_weekly_metrics
2020-11-18 15:32:58.999908 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 15:32:59.000239 (MainThread): 15:32:58 | 
2020-11-18 15:32:59.000320 (MainThread): 15:32:58 | Finished running  in 0.85s.
2020-11-18 15:32:59.000392 (MainThread): Connection 'master' was properly closed.
2020-11-18 15:32:59.000456 (MainThread): Connection 'model.github_source.github_pull_request_reviewers' was properly closed.
2020-11-18 15:32:59.637767 (Thread-50): handling poll request
2020-11-18 15:32:59.638279 (Thread-50): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc828e358>]}
2020-11-18 15:32:59.652675 (Thread-50): sending response (<Response 65902 bytes [200 OK]>) to 10.0.44.246
2020-11-18 15:32:59.943239 (Thread-51): handling status request
2020-11-18 15:32:59.943815 (Thread-51): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82d3f60>]}
2020-11-18 15:32:59.946218 (Thread-51): sending response (<Response 4846 bytes [200 OK]>) to 10.0.5.154
2020-11-18 15:33:09.188639 (Thread-52): handling status request
2020-11-18 15:33:09.189188 (Thread-52): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82757b8>]}
2020-11-18 15:33:09.191467 (Thread-52): sending response (<Response 4846 bytes [200 OK]>) to 10.0.18.208
2020-11-18 15:33:09.234136 (Thread-53): handling status request
2020-11-18 15:33:09.234665 (Thread-53): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37ce630>]}
2020-11-18 15:33:09.237007 (Thread-53): sending response (<Response 4846 bytes [200 OK]>) to 10.0.44.246
2020-11-18 15:33:09.546518 (Thread-54): handling cli_args request
2020-11-18 15:33:09.547033 (Thread-54): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8275eb8>]}
2020-11-18 15:33:10.579360 (Thread-54): sending response (<Response 137 bytes [200 OK]>) to 10.0.14.29
2020-11-18 15:33:10.677372 (MainThread): Partial parsing not enabled
2020-11-18 15:33:10.679144 (MainThread): Parsing macros/adapters.sql
2020-11-18 15:33:10.705942 (MainThread): Parsing macros/etc.sql
2020-11-18 15:33:10.708298 (MainThread): Parsing macros/catalog.sql
2020-11-18 15:33:10.717598 (MainThread): Parsing macros/materializations/table.sql
2020-11-18 15:33:10.734945 (MainThread): Parsing macros/materializations/view.sql
2020-11-18 15:33:10.739979 (MainThread): Parsing macros/materializations/copy.sql
2020-11-18 15:33:10.747408 (MainThread): Parsing macros/materializations/seed.sql
2020-11-18 15:33:10.752125 (MainThread): Parsing macros/materializations/incremental.sql
2020-11-18 15:33:10.769857 (MainThread): Parsing macros/materializations/snapshot.sql
2020-11-18 15:33:10.772927 (MainThread): Parsing macros/core.sql
2020-11-18 15:33:10.777026 (MainThread): Parsing macros/adapters/common.sql
2020-11-18 15:33:10.822553 (MainThread): Parsing macros/materializations/helpers.sql
2020-11-18 15:33:10.832754 (MainThread): Parsing macros/materializations/table/table.sql
2020-11-18 15:33:10.840376 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-11-18 15:33:10.862409 (MainThread): Parsing macros/materializations/view/view.sql
2020-11-18 15:33:10.869370 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 15:33:10.874809 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 15:33:10.876999 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 15:33:10.885889 (Thread-55): handling poll request
2020-11-18 15:33:10.886400 (Thread-55): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8275588>]}
2020-11-18 15:33:10.889922 (Thread-55): sending response (<Response 5481 bytes [200 OK]>) to 10.0.44.246
2020-11-18 15:33:10.883965 (MainThread): Parsing macros/materializations/common/merge.sql
2020-11-18 15:33:10.899344 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 15:33:10.917118 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 15:33:10.919217 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 15:33:10.949427 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-11-18 15:33:10.951744 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-11-18 15:33:10.953598 (MainThread): Parsing macros/schema_tests/unique.sql
2020-11-18 15:33:10.955571 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 15:33:10.958645 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-11-18 15:33:10.960544 (MainThread): Parsing macros/etc/query.sql
2020-11-18 15:33:10.961826 (MainThread): Parsing macros/etc/datetime.sql
2020-11-18 15:33:10.972024 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-11-18 15:33:10.973172 (MainThread): Parsing macros/etc/is_incremental.sql
2020-11-18 15:33:10.974957 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-11-18 15:33:10.995100 (MainThread): Parsing macros/logger/pretty_time.sql
2020-11-18 15:33:11.000590 (MainThread): Parsing macros/logger/log_info.sql
2020-11-18 15:33:11.005546 (MainThread): Parsing macros/logger/pretty_log_format.sql
2020-11-18 15:33:11.011042 (MainThread): Parsing macros/sql/pivot.sql
2020-11-18 15:33:11.017692 (MainThread): Parsing macros/sql/star.sql
2020-11-18 15:33:11.025296 (MainThread): Parsing macros/sql/surrogate_key.sql
2020-11-18 15:33:11.032587 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2020-11-18 15:33:11.038306 (MainThread): Parsing macros/sql/get_column_values.sql
2020-11-18 15:33:11.047127 (MainThread): Parsing macros/sql/groupby.sql
2020-11-18 15:33:11.051713 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2020-11-18 15:33:11.062538 (MainThread): Parsing macros/sql/nullcheck_table.sql
2020-11-18 15:33:11.067398 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2020-11-18 15:33:11.072331 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2020-11-18 15:33:11.079694 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2020-11-18 15:33:11.086743 (MainThread): Parsing macros/sql/safe_add.sql
2020-11-18 15:33:11.091372 (MainThread): Parsing macros/sql/unpivot.sql
2020-11-18 15:33:11.103140 (MainThread): Parsing macros/sql/generate_series.sql
2020-11-18 15:33:11.110513 (MainThread): Parsing macros/sql/nullcheck.sql
2020-11-18 15:33:11.115684 (MainThread): Parsing macros/sql/union.sql
2020-11-18 15:33:11.128602 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2020-11-18 15:33:11.158239 (MainThread): Parsing macros/web/get_url_parameter.sql
2020-11-18 15:33:11.163871 (MainThread): Parsing macros/web/get_url_path.sql
2020-11-18 15:33:11.169854 (MainThread): Parsing macros/web/get_url_host.sql
2020-11-18 15:33:11.175464 (MainThread): Parsing macros/datetime/date_spine.sql
2020-11-18 15:33:11.183776 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2020-11-18 15:33:11.189497 (MainThread): Parsing macros/schema_tests/not_constant.sql
2020-11-18 15:33:11.194828 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2020-11-18 15:33:11.200493 (MainThread): Parsing macros/schema_tests/equality.sql
2020-11-18 15:33:11.208070 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2020-11-18 15:33:11.213695 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2020-11-18 15:33:11.218985 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2020-11-18 15:33:11.224372 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2020-11-18 15:33:11.234095 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2020-11-18 15:33:11.241257 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2020-11-18 15:33:11.247773 (MainThread): Parsing macros/schema_tests/recency.sql
2020-11-18 15:33:11.252618 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2020-11-18 15:33:11.258104 (MainThread): Parsing macros/geo/haversine_distance.sql
2020-11-18 15:33:11.262836 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2020-11-18 15:33:11.268855 (MainThread): Parsing macros/cross_db_utils/length.sql
2020-11-18 15:33:11.273796 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2020-11-18 15:33:11.281850 (MainThread): Parsing macros/cross_db_utils/_get_utils_namespaces.sql
2020-11-18 15:33:11.286984 (MainThread): Parsing macros/cross_db_utils/right.sql
2020-11-18 15:33:11.293637 (MainThread): Parsing macros/cross_db_utils/hash.sql
2020-11-18 15:33:11.299150 (MainThread): Parsing macros/cross_db_utils/replace.sql
2020-11-18 15:33:11.304453 (MainThread): Parsing macros/cross_db_utils/concat.sql
2020-11-18 15:33:11.310857 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2020-11-18 15:33:11.316177 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2020-11-18 15:33:11.321681 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2020-11-18 15:33:11.336097 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2020-11-18 15:33:11.342835 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2020-11-18 15:33:11.354498 (MainThread): Parsing macros/cross_db_utils/position.sql
2020-11-18 15:33:11.360700 (MainThread): Parsing macros/cross_db_utils/literal.sql
2020-11-18 15:33:11.365945 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2020-11-18 15:33:11.371674 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2020-11-18 15:33:11.382400 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2020-11-18 15:33:11.388054 (MainThread): Parsing macros/cross_db_utils/except.sql
2020-11-18 15:33:11.393730 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2020-11-18 15:33:11.399855 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2020-11-18 15:33:11.409427 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2020-11-18 15:33:11.425962 (MainThread): Partial parsing not enabled
2020-11-18 15:33:11.484882 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 15:33:11.515828 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 15:33:11.536695 (MainThread): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 15:33:11.555493 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 15:33:11.576947 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 15:33:11.609502 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 15:33:11.627996 (MainThread): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 15:33:11.651637 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 15:33:11.683283 (MainThread): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 15:33:11.705077 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 15:33:11.725413 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 15:33:11.744396 (MainThread): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 15:33:11.762962 (MainThread): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 15:33:11.781718 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 15:33:11.800692 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 15:33:11.823000 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 15:33:11.848528 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 15:33:11.872708 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 15:33:11.891174 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 15:33:11.910434 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 15:33:11.929511 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 15:33:11.948156 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 15:33:11.967287 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 15:33:11.995174 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 15:33:12.212144 (Thread-56): handling poll request
2020-11-18 15:33:12.212731 (Thread-56): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3444f28>]}
2020-11-18 15:33:12.224019 (Thread-56): sending response (<Response 28212 bytes [200 OK]>) to 10.0.37.56
2020-11-18 15:33:13.148422 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github
- models.github.intermediate

2020-11-18 15:33:13.275876 (MainThread): Found 24 models, 26 tests, 0 snapshots, 0 analyses, 287 macros, 0 operations, 0 seed files, 11 sources
2020-11-18 15:33:13.282556 (MainThread): 
2020-11-18 15:33:13.282939 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 15:33:13.320301 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_abij-playground_dbt_abij".
2020-11-18 15:33:13.320464 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-11-18 15:33:13.321301 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-18 15:33:13.512310 (MainThread): 15:33:13 | Concurrency: 1 threads (target='default')
2020-11-18 15:33:13.512451 (MainThread): 15:33:13 | 
2020-11-18 15:33:13.514900 (Thread-1): Began running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 15:33:13.515083 (Thread-1): 15:33:13 | 1 of 26 START test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id [RUN]
2020-11-18 15:33:13.529073 (Thread-57): handling poll request
2020-11-18 15:33:13.529530 (Thread-57): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc341e048>]}
2020-11-18 15:33:13.531623 (Thread-57): sending response (<Response 4233 bytes [200 OK]>) to 10.0.34.241
2020-11-18 15:33:13.515338 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id".
2020-11-18 15:33:13.515436 (Thread-1): Compiling test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 15:33:13.537728 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"
2020-11-18 15:33:13.549301 (Thread-1): finished collecting timing info
2020-11-18 15:33:13.549751 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:13.550282 (Thread-1): On test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"} */






with validation_errors as (

    select
        issue_id, user_id
    from `abij-playground`.`github`.`issue_assignee`

    group by issue_id, user_id
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:33:13.982961 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"} */






with validation_errors as (

    select
        issue_id, user_id
    from `abij-playground`.`github`.`issue_assignee`

    group by issue_id, user_id
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:33:13.983332 (Thread-1): finished collecting timing info
2020-11-18 15:33:13.984151 (Thread-1): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_assignee was not found in location EU
  
  (job ID: abe6a365-12f0-403a-8dd0-bf230893a8c5)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_assignee was not found in location EU

(job ID: abe6a365-12f0-403a-8dd0-bf230893a8c5)

                                                                                              -----Query Job SQL Follows-----                                                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"} */
   2:
   3:
   4:
   5:
   6:
   7:
   8:with validation_errors as (
   9:
  10:    select
  11:        issue_id, user_id
  12:    from `abij-playground`.`github`.`issue_assignee`
  13:
  14:    group by issue_id, user_id
  15:    having count(*) > 1
  16:
  17:)
  18:
  19:select count(*)
  20:from validation_errors
  21:
  22:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_assignee was not found in location EU
  
  (job ID: abe6a365-12f0-403a-8dd0-bf230893a8c5)
2020-11-18 15:33:13.986964 (Thread-1): 15:33:13 | 1 of 26 ERROR dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id [ERROR in 0.47s]
2020-11-18 15:33:13.987049 (Thread-1): Finished running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 15:33:13.987182 (Thread-1): Began running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 15:33:13.987280 (Thread-1): 15:33:13 | 2 of 26 START test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at [RUN]
2020-11-18 15:33:13.987551 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at".
2020-11-18 15:33:13.987639 (Thread-1): Compiling test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 15:33:13.991353 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42106), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:13.991664 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59700), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:13.995216 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42080), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:13.995452 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59674), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:14.005007 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"
2020-11-18 15:33:14.018670 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.019090 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:14.019568 (Thread-1): On test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"} */






with validation_errors as (

    select
        issue_id, updated_at
    from `abij-playground`.`github`.`issue_closed_history`

    group by issue_id, updated_at
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:33:14.399301 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"} */






with validation_errors as (

    select
        issue_id, updated_at
    from `abij-playground`.`github`.`issue_closed_history`

    group by issue_id, updated_at
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:33:14.399643 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.400477 (Thread-1): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU
  
  (job ID: 792427d7-264d-4b81-b9fa-e3523c9c434f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU

(job ID: 792427d7-264d-4b81-b9fa-e3523c9c434f)

                                                                                                   -----Query Job SQL Follows-----                                                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"} */
   2:
   3:
   4:
   5:
   6:
   7:
   8:with validation_errors as (
   9:
  10:    select
  11:        issue_id, updated_at
  12:    from `abij-playground`.`github`.`issue_closed_history`
  13:
  14:    group by issue_id, updated_at
  15:    having count(*) > 1
  16:
  17:)
  18:
  19:select count(*)
  20:from validation_errors
  21:
  22:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU
  
  (job ID: 792427d7-264d-4b81-b9fa-e3523c9c434f)
2020-11-18 15:33:14.401778 (Thread-1): 15:33:14 | 2 of 26 ERROR dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at [ERROR in 0.41s]
2020-11-18 15:33:14.401909 (Thread-1): Finished running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 15:33:14.402101 (Thread-1): Began running node test.github_source.not_null_github_daily_metrics_day
2020-11-18 15:33:14.402255 (Thread-1): 15:33:14 | 3 of 26 START test not_null_github_daily_metrics_day................. [RUN]
2020-11-18 15:33:14.402644 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_daily_metrics_day".
2020-11-18 15:33:14.402782 (Thread-1): Compiling test.github_source.not_null_github_daily_metrics_day
2020-11-18 15:33:14.418229 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:14.458735 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:14.473434 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:14.489136 (Thread-1): Compiling model.github_source.stg_github_issue
2020-11-18 15:33:14.498752 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue"
2020-11-18 15:33:14.522901 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:14.531796 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.532345 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:14.533656 (Thread-1): 15:33:14 | 3 of 26 ERROR not_null_github_daily_metrics_day...................... [ERROR in 0.13s]
2020-11-18 15:33:14.533739 (Thread-1): Finished running node test.github_source.not_null_github_daily_metrics_day
2020-11-18 15:33:14.533869 (Thread-1): Began running node test.github_source.not_null_github_issues_issue_id
2020-11-18 15:33:14.533963 (Thread-1): 15:33:14 | 4 of 26 START test not_null_github_issues_issue_id................... [RUN]
2020-11-18 15:33:14.534203 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_issues_issue_id".
2020-11-18 15:33:14.534284 (Thread-1): Compiling test.github_source.not_null_github_issues_issue_id
2020-11-18 15:33:14.537276 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42118), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:14.537926 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59714), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:14.545740 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:14.561081 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:14.577952 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:14.585681 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.586180 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:14.586915 (Thread-1): 15:33:14 | 4 of 26 ERROR not_null_github_issues_issue_id........................ [ERROR in 0.05s]
2020-11-18 15:33:14.586996 (Thread-1): Finished running node test.github_source.not_null_github_issues_issue_id
2020-11-18 15:33:14.587123 (Thread-1): Began running node test.github_source.not_null_github_monthly_metrics_month
2020-11-18 15:33:14.587214 (Thread-1): 15:33:14 | 5 of 26 START test not_null_github_monthly_metrics_month............. [RUN]
2020-11-18 15:33:14.587527 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_monthly_metrics_month".
2020-11-18 15:33:14.587624 (Thread-1): Compiling test.github_source.not_null_github_monthly_metrics_month
2020-11-18 15:33:14.596610 (Thread-1): Compiling model.github_source.github_monthly_metrics
2020-11-18 15:33:14.608531 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:14.624106 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:14.647026 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:14.666574 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:14.677320 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.678198 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:14.679211 (Thread-1): 15:33:14 | 5 of 26 ERROR not_null_github_monthly_metrics_month.................. [ERROR in 0.09s]
2020-11-18 15:33:14.679343 (Thread-1): Finished running node test.github_source.not_null_github_monthly_metrics_month
2020-11-18 15:33:14.679551 (Thread-1): Began running node test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 15:33:14.679719 (Thread-1): 15:33:14 | 6 of 26 START test not_null_github_pull_requests_issue_id............ [RUN]
2020-11-18 15:33:14.680075 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_pull_requests_issue_id".
2020-11-18 15:33:14.680215 (Thread-1): Compiling test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 15:33:14.692020 (Thread-1): Compiling model.github_source.github_pull_requests
2020-11-18 15:33:14.709183 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:14.726215 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:14.735326 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.735879 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:14.736823 (Thread-1): 15:33:14 | 6 of 26 ERROR not_null_github_pull_requests_issue_id................. [ERROR in 0.06s]
2020-11-18 15:33:14.736913 (Thread-1): Finished running node test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 15:33:14.737040 (Thread-1): Began running node test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 15:33:14.737132 (Thread-1): 15:33:14 | 7 of 26 START test not_null_github_quarterly_metrics_quarter......... [RUN]
2020-11-18 15:33:14.737403 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_quarterly_metrics_quarter".
2020-11-18 15:33:14.737485 (Thread-1): Compiling test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 15:33:14.748778 (Thread-1): Compiling model.github_source.github_quarterly_metrics
2020-11-18 15:33:14.761750 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:14.777775 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:14.793198 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:14.805906 (Thread-58): handling poll request
2020-11-18 15:33:14.806425 (Thread-58): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc83c0e10>]}
2020-11-18 15:33:14.818341 (Thread-58): sending response (<Response 70644 bytes [200 OK]>) to 10.0.14.177
2020-11-18 15:33:14.810104 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:14.821108 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.821902 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:14.822700 (Thread-1): 15:33:14 | 7 of 26 ERROR not_null_github_quarterly_metrics_quarter.............. [ERROR in 0.09s]
2020-11-18 15:33:14.822784 (Thread-1): Finished running node test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 15:33:14.822912 (Thread-1): Began running node test.github_source.not_null_github_weekly_metrics_week
2020-11-18 15:33:14.823007 (Thread-1): 15:33:14 | 8 of 26 START test not_null_github_weekly_metrics_week............... [RUN]
2020-11-18 15:33:14.823232 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_weekly_metrics_week".
2020-11-18 15:33:14.823315 (Thread-1): Compiling test.github_source.not_null_github_weekly_metrics_week
2020-11-18 15:33:14.833436 (Thread-1): Compiling model.github_source.github_weekly_metrics
2020-11-18 15:33:14.846929 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:14.864814 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:14.882616 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:14.898772 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:14.906328 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.906807 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:14.907527 (Thread-1): 15:33:14 | 8 of 26 ERROR not_null_github_weekly_metrics_week.................... [ERROR in 0.08s]
2020-11-18 15:33:14.907609 (Thread-1): Finished running node test.github_source.not_null_github_weekly_metrics_week
2020-11-18 15:33:14.907746 (Thread-1): Began running node test.github_source.source_not_null_github_issue_comment_id
2020-11-18 15:33:14.907844 (Thread-1): 15:33:14 | 9 of 26 START test source_not_null_github_issue_comment_id........... [RUN]
2020-11-18 15:33:14.908063 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_issue_comment_id".
2020-11-18 15:33:14.908144 (Thread-1): Compiling test.github_source.source_not_null_github_issue_comment_id
2020-11-18 15:33:14.919696 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_issue_comment_id"
2020-11-18 15:33:14.941430 (Thread-1): finished collecting timing info
2020-11-18 15:33:14.941869 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:14.942392 (Thread-1): On test.github_source.source_not_null_github_issue_comment_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue_comment`
where id is null



2020-11-18 15:33:15.264706 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue_comment`
where id is null



2020-11-18 15:33:15.264945 (Thread-1): finished collecting timing info
2020-11-18 15:33:15.265555 (Thread-1): Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: f43269eb-b946-424c-af50-84953e75a9fb)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_comment was not found in location EU

(job ID: f43269eb-b946-424c-af50-84953e75a9fb)

                                                                       -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`issue_comment`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: f43269eb-b946-424c-af50-84953e75a9fb)
2020-11-18 15:33:15.266840 (Thread-1): 15:33:15 | 9 of 26 ERROR source_not_null_github_issue_comment_id................ [ERROR in 0.36s]
2020-11-18 15:33:15.266954 (Thread-1): Finished running node test.github_source.source_not_null_github_issue_comment_id
2020-11-18 15:33:15.267097 (Thread-1): Began running node test.github_source.source_not_null_github_issue_id
2020-11-18 15:33:15.267215 (Thread-1): 15:33:15 | 10 of 26 START test source_not_null_github_issue_id.................. [RUN]
2020-11-18 15:33:15.267476 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_issue_id".
2020-11-18 15:33:15.267563 (Thread-1): Compiling test.github_source.source_not_null_github_issue_id
2020-11-18 15:33:15.271741 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42168), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:15.271997 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59580), raddr=('172.217.13.234', 443)>
2020-11-18 15:33:15.284282 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_issue_id"
2020-11-18 15:33:15.304398 (Thread-1): finished collecting timing info
2020-11-18 15:33:15.304856 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:15.305393 (Thread-1): On test.github_source.source_not_null_github_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue`
where id is null



2020-11-18 15:33:15.642955 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue`
where id is null



2020-11-18 15:33:15.643201 (Thread-1): finished collecting timing info
2020-11-18 15:33:15.643776 (Thread-1): Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: d1a4ff10-152e-4388-aeed-f58f4bfb15de)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue was not found in location EU

(job ID: d1a4ff10-152e-4388-aeed-f58f4bfb15de)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`issue`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: d1a4ff10-152e-4388-aeed-f58f4bfb15de)
2020-11-18 15:33:15.644800 (Thread-1): 15:33:15 | 10 of 26 ERROR source_not_null_github_issue_id....................... [ERROR in 0.38s]
2020-11-18 15:33:15.644890 (Thread-1): Finished running node test.github_source.source_not_null_github_issue_id
2020-11-18 15:33:15.645022 (Thread-1): Began running node test.github_source.source_not_null_github_pull_request_id
2020-11-18 15:33:15.645137 (Thread-1): 15:33:15 | 11 of 26 START test source_not_null_github_pull_request_id........... [RUN]
2020-11-18 15:33:15.645466 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_pull_request_id".
2020-11-18 15:33:15.645560 (Thread-1): Compiling test.github_source.source_not_null_github_pull_request_id
2020-11-18 15:33:15.651205 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42212), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:15.651544 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59804), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:15.662534 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_pull_request_id"
2020-11-18 15:33:15.683769 (Thread-1): finished collecting timing info
2020-11-18 15:33:15.684251 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:15.684844 (Thread-1): On test.github_source.source_not_null_github_pull_request_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request`
where id is null



2020-11-18 15:33:15.973466 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request`
where id is null



2020-11-18 15:33:15.973707 (Thread-1): finished collecting timing info
2020-11-18 15:33:15.974267 (Thread-1): Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: 63096e60-4006-405c-be01-ade2ec06139f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request was not found in location EU

(job ID: 63096e60-4006-405c-be01-ade2ec06139f)

                                                                      -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`pull_request`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: 63096e60-4006-405c-be01-ade2ec06139f)
2020-11-18 15:33:15.975278 (Thread-1): 15:33:15 | 11 of 26 ERROR source_not_null_github_pull_request_id................ [ERROR in 0.33s]
2020-11-18 15:33:15.975399 (Thread-1): Finished running node test.github_source.source_not_null_github_pull_request_id
2020-11-18 15:33:15.975595 (Thread-1): Began running node test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 15:33:15.975753 (Thread-1): 15:33:15 | 12 of 26 START test source_not_null_github_pull_request_review_id.... [RUN]
2020-11-18 15:33:15.976130 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_pull_request_review_id".
2020-11-18 15:33:15.976234 (Thread-1): Compiling test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 15:33:15.987007 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_pull_request_review_id"
2020-11-18 15:33:16.004425 (Thread-1): finished collecting timing info
2020-11-18 15:33:16.005025 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:16.005607 (Thread-1): On test.github_source.source_not_null_github_pull_request_review_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request_review`
where id is null



2020-11-18 15:33:16.122899 (Thread-59): handling poll request
2020-11-18 15:33:16.123575 (Thread-59): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc34440b8>]}
2020-11-18 15:33:16.131660 (Thread-59): sending response (<Response 57234 bytes [200 OK]>) to 10.0.21.190
2020-11-18 15:33:16.311744 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request_review`
where id is null



2020-11-18 15:33:16.311982 (Thread-1): finished collecting timing info
2020-11-18 15:33:16.312532 (Thread-1): Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: 2d9c56fe-a716-4513-ae58-ed6ba6d2133f)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request_review was not found in location EU

(job ID: 2d9c56fe-a716-4513-ae58-ed6ba6d2133f)

                                                                          -----Query Job SQL Follows-----                                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`pull_request_review`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: 2d9c56fe-a716-4513-ae58-ed6ba6d2133f)
2020-11-18 15:33:16.313657 (Thread-1): 15:33:16 | 12 of 26 ERROR source_not_null_github_pull_request_review_id......... [ERROR in 0.34s]
2020-11-18 15:33:16.313746 (Thread-1): Finished running node test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 15:33:16.313875 (Thread-1): Began running node test.github_source.source_not_null_github_repository_id
2020-11-18 15:33:16.313977 (Thread-1): 15:33:16 | 13 of 26 START test source_not_null_github_repository_id............. [RUN]
2020-11-18 15:33:16.314252 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_repository_id".
2020-11-18 15:33:16.314341 (Thread-1): Compiling test.github_source.source_not_null_github_repository_id
2020-11-18 15:33:16.327585 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_repository_id"
2020-11-18 15:33:16.347141 (Thread-1): finished collecting timing info
2020-11-18 15:33:16.347608 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:16.348171 (Thread-1): On test.github_source.source_not_null_github_repository_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_repository_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`repository`
where id is null



2020-11-18 15:33:17.415865 (Thread-60): handling poll request
2020-11-18 15:33:17.416559 (Thread-60): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc80e2c18>]}
2020-11-18 15:33:17.419369 (Thread-60): Checking header 'user-agent' tracing in whitelist set(), 24 additional messages skipped
2020-11-18 15:33:17.446137 (Thread-60): writing 1 spans (enabled:True), 325 additional messages skipped
2020-11-18 15:33:17.446487 (Thread-60): 
      name requests.request
        id 1929568540207562894
  trace_id 12765685832940742380
 parent_id None
   service requests
  resource requests.request
      type http
     start 1605713597.418708
       end 1605713597.4459841
  duration 0.027276s
     error 0
      tags 
           http.method:POST
           http.status_code:200
           http.url:https://fishtownanalytics.sinter-collect.com/com.snowplowanalytics.snowplow/tp2
           runtime-id:fbe41a1a9fef4dc6b4d89ae108b31842, 357 additional messages skipped
2020-11-18 15:33:17.452189 (Thread-60): sending response (<Response 11375 bytes [200 OK]>) to 10.0.3.20
2020-11-18 15:33:17.939353 (Thread-1): finished collecting timing info
2020-11-18 15:33:17.940042 (Thread-1): 15:33:17 | 13 of 26 PASS source_not_null_github_repository_id................... [PASS in 1.63s]
2020-11-18 15:33:17.940143 (Thread-1): Finished running node test.github_source.source_not_null_github_repository_id
2020-11-18 15:33:17.940284 (Thread-1): Began running node test.github_source.source_not_null_github_user_id
2020-11-18 15:33:17.940398 (Thread-1): 15:33:17 | 14 of 26 START test source_not_null_github_user_id................... [RUN]
2020-11-18 15:33:17.940642 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_user_id".
2020-11-18 15:33:17.940728 (Thread-1): Compiling test.github_source.source_not_null_github_user_id
2020-11-18 15:33:17.952067 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_user_id"
2020-11-18 15:33:17.971992 (Thread-1): finished collecting timing info
2020-11-18 15:33:17.972456 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:17.972942 (Thread-1): On test.github_source.source_not_null_github_user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_user_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`user`
where id is null



2020-11-18 15:33:18.415731 (AgentWriter): reported 1 traces in 0.00510s, 4 additional messages skipped
2020-11-18 15:33:18.416033 (AgentWriter): initialized RateSampler, sample 100% of traces, 159 additional messages skipped
2020-11-18 15:33:18.759827 (Thread-61): handling poll request
2020-11-18 15:33:18.760355 (Thread-61): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc80ff4e0>]}
2020-11-18 15:33:18.762632 (Thread-61): sending response (<Response 5369 bytes [200 OK]>) to 10.0.37.56
2020-11-18 15:33:19.448301 (Thread-1): finished collecting timing info
2020-11-18 15:33:19.449018 (Thread-1): 15:33:19 | 14 of 26 PASS source_not_null_github_user_id......................... [PASS in 1.51s]
2020-11-18 15:33:19.449133 (Thread-1): Finished running node test.github_source.source_not_null_github_user_id
2020-11-18 15:33:19.449309 (Thread-1): Began running node test.github_source.source_unique_github_issue_comment_id
2020-11-18 15:33:19.449418 (Thread-1): 15:33:19 | 15 of 26 START test source_unique_github_issue_comment_id............ [RUN]
2020-11-18 15:33:19.449665 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_issue_comment_id".
2020-11-18 15:33:19.449760 (Thread-1): Compiling test.github_source.source_unique_github_issue_comment_id
2020-11-18 15:33:19.461274 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_issue_comment_id"
2020-11-18 15:33:19.480640 (Thread-1): finished collecting timing info
2020-11-18 15:33:19.481103 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:19.481675 (Thread-1): On test.github_source.source_unique_github_issue_comment_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue_comment`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:19.781463 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue_comment`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:19.781757 (Thread-1): finished collecting timing info
2020-11-18 15:33:19.782577 (Thread-1): Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: d34f8772-a0da-4526-88a6-5f9f82321f97)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_comment was not found in location EU

(job ID: d34f8772-a0da-4526-88a6-5f9f82321f97)

                                                                      -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`issue_comment`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: d34f8772-a0da-4526-88a6-5f9f82321f97)
2020-11-18 15:33:19.783762 (Thread-1): 15:33:19 | 15 of 26 ERROR source_unique_github_issue_comment_id................. [ERROR in 0.33s]
2020-11-18 15:33:19.783847 (Thread-1): Finished running node test.github_source.source_unique_github_issue_comment_id
2020-11-18 15:33:19.783975 (Thread-1): Began running node test.github_source.source_unique_github_issue_id
2020-11-18 15:33:19.784071 (Thread-1): 15:33:19 | 16 of 26 START test source_unique_github_issue_id.................... [RUN]
2020-11-18 15:33:19.784334 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_issue_id".
2020-11-18 15:33:19.784419 (Thread-1): Compiling test.github_source.source_unique_github_issue_id
2020-11-18 15:33:19.795727 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_issue_id"
2020-11-18 15:33:19.814001 (Thread-1): finished collecting timing info
2020-11-18 15:33:19.814439 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:19.814987 (Thread-1): On test.github_source.source_unique_github_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:19.836673 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59642), raddr=('172.217.13.234', 443)>
2020-11-18 15:33:19.837055 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42234), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:19.837377 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42240), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:19.837666 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59834), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:19.837904 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42292), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:19.838130 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59700), raddr=('172.217.13.234', 443)>
2020-11-18 15:33:19.838364 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42360), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:19.838557 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59956), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:19.838771 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42426), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:19.839036 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 60020), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:20.021858 (Thread-62): handling poll request
2020-11-18 15:33:20.022391 (Thread-62): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc80d47b8>]}
2020-11-18 15:33:20.026220 (Thread-62): sending response (<Response 16789 bytes [200 OK]>) to 10.0.30.126
2020-11-18 15:33:20.100777 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:20.101033 (Thread-1): finished collecting timing info
2020-11-18 15:33:20.101669 (Thread-1): Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: c320551b-a89b-4f91-a548-b56e34fb502a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue was not found in location EU

(job ID: c320551b-a89b-4f91-a548-b56e34fb502a)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`issue`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: c320551b-a89b-4f91-a548-b56e34fb502a)
2020-11-18 15:33:20.102898 (Thread-1): 15:33:20 | 16 of 26 ERROR source_unique_github_issue_id......................... [ERROR in 0.32s]
2020-11-18 15:33:20.102981 (Thread-1): Finished running node test.github_source.source_unique_github_issue_id
2020-11-18 15:33:20.103112 (Thread-1): Began running node test.github_source.source_unique_github_pull_request_id
2020-11-18 15:33:20.103209 (Thread-1): 15:33:20 | 17 of 26 START test source_unique_github_pull_request_id............. [RUN]
2020-11-18 15:33:20.103468 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_pull_request_id".
2020-11-18 15:33:20.103552 (Thread-1): Compiling test.github_source.source_unique_github_pull_request_id
2020-11-18 15:33:20.115884 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_pull_request_id"
2020-11-18 15:33:20.133491 (Thread-1): finished collecting timing info
2020-11-18 15:33:20.133949 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:20.134525 (Thread-1): On test.github_source.source_unique_github_pull_request_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:20.427985 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:20.428229 (Thread-1): finished collecting timing info
2020-11-18 15:33:20.428814 (Thread-1): Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: dd785a45-5a34-4c4a-9d74-c15734b1c963)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request was not found in location EU

(job ID: dd785a45-5a34-4c4a-9d74-c15734b1c963)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`pull_request`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: dd785a45-5a34-4c4a-9d74-c15734b1c963)
2020-11-18 15:33:20.430032 (Thread-1): 15:33:20 | 17 of 26 ERROR source_unique_github_pull_request_id.................. [ERROR in 0.33s]
2020-11-18 15:33:20.430116 (Thread-1): Finished running node test.github_source.source_unique_github_pull_request_id
2020-11-18 15:33:20.430248 (Thread-1): Began running node test.github_source.source_unique_github_pull_request_review_id
2020-11-18 15:33:20.430351 (Thread-1): 15:33:20 | 18 of 26 START test source_unique_github_pull_request_review_id...... [RUN]
2020-11-18 15:33:20.430622 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_pull_request_review_id".
2020-11-18 15:33:20.430710 (Thread-1): Compiling test.github_source.source_unique_github_pull_request_review_id
2020-11-18 15:33:20.431554 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42452), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:20.432106 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59866), raddr=('172.217.13.234', 443)>
2020-11-18 15:33:20.449836 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_pull_request_review_id"
2020-11-18 15:33:20.468791 (Thread-1): finished collecting timing info
2020-11-18 15:33:20.469317 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:20.469890 (Thread-1): On test.github_source.source_unique_github_pull_request_review_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request_review`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:20.736841 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request_review`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:20.737221 (Thread-1): finished collecting timing info
2020-11-18 15:33:20.738075 (Thread-1): Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: bd3d3bde-e145-4522-aa72-01dc3e23a00e)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request_review was not found in location EU

(job ID: bd3d3bde-e145-4522-aa72-01dc3e23a00e)

                                                                         -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`pull_request_review`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: bd3d3bde-e145-4522-aa72-01dc3e23a00e)
2020-11-18 15:33:20.739532 (Thread-1): 15:33:20 | 18 of 26 ERROR source_unique_github_pull_request_review_id........... [ERROR in 0.31s]
2020-11-18 15:33:20.739656 (Thread-1): Finished running node test.github_source.source_unique_github_pull_request_review_id
2020-11-18 15:33:20.739850 (Thread-1): Began running node test.github_source.source_unique_github_repository_id
2020-11-18 15:33:20.740007 (Thread-1): 15:33:20 | 19 of 26 START test source_unique_github_repository_id............... [RUN]
2020-11-18 15:33:20.740401 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_repository_id".
2020-11-18 15:33:20.740542 (Thread-1): Compiling test.github_source.source_unique_github_repository_id
2020-11-18 15:33:20.759814 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_repository_id"
2020-11-18 15:33:20.779589 (Thread-1): finished collecting timing info
2020-11-18 15:33:20.780197 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:20.780877 (Thread-1): On test.github_source.source_unique_github_repository_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_repository_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`repository`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:21.331075 (Thread-63): handling poll request
2020-11-18 15:33:21.331649 (Thread-63): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc80d4780>]}
2020-11-18 15:33:21.337142 (Thread-63): sending response (<Response 34297 bytes [200 OK]>) to 10.0.34.62
2020-11-18 15:33:22.308165 (Thread-1): finished collecting timing info
2020-11-18 15:33:22.308839 (Thread-1): 15:33:22 | 19 of 26 PASS source_unique_github_repository_id..................... [PASS in 1.57s]
2020-11-18 15:33:22.308947 (Thread-1): Finished running node test.github_source.source_unique_github_repository_id
2020-11-18 15:33:22.309073 (Thread-1): Began running node test.github_source.source_unique_github_user_id
2020-11-18 15:33:22.309201 (Thread-1): 15:33:22 | 20 of 26 START test source_unique_github_user_id..................... [RUN]
2020-11-18 15:33:22.309452 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_user_id".
2020-11-18 15:33:22.309575 (Thread-1): Compiling test.github_source.source_unique_github_user_id
2020-11-18 15:33:22.322572 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_user_id"
2020-11-18 15:33:22.342142 (Thread-1): finished collecting timing info
2020-11-18 15:33:22.342608 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:33:22.343180 (Thread-1): On test.github_source.source_unique_github_user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`user`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:33:22.608158 (Thread-64): handling poll request
2020-11-18 15:33:22.608699 (Thread-64): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc828ef98>]}
2020-11-18 15:33:22.610945 (Thread-64): sending response (<Response 5444 bytes [200 OK]>) to 10.0.14.186
2020-11-18 15:33:23.806210 (Thread-1): finished collecting timing info
2020-11-18 15:33:23.806936 (Thread-1): 15:33:23 | 20 of 26 PASS source_unique_github_user_id........................... [PASS in 1.50s]
2020-11-18 15:33:23.807047 (Thread-1): Finished running node test.github_source.source_unique_github_user_id
2020-11-18 15:33:23.807175 (Thread-1): Began running node test.github_source.unique_github_daily_metrics_day
2020-11-18 15:33:23.807280 (Thread-1): 15:33:23 | 21 of 26 START test unique_github_daily_metrics_day.................. [RUN]
2020-11-18 15:33:23.807507 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_daily_metrics_day".
2020-11-18 15:33:23.807591 (Thread-1): Compiling test.github_source.unique_github_daily_metrics_day
2020-11-18 15:33:23.816873 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:23.827695 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42482), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:23.828029 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59894), raddr=('172.217.13.234', 443)>
2020-11-18 15:33:23.828252 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42492), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:23.828464 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 60086), raddr=('172.217.8.10', 443)>
2020-11-18 15:33:23.828655 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42576), raddr=('172.217.13.74', 443)>
2020-11-18 15:33:23.828857 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 59988), raddr=('172.217.13.234', 443)>
2020-11-18 15:33:23.836964 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:23.852190 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:23.868486 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:23.876350 (Thread-1): finished collecting timing info
2020-11-18 15:33:23.876852 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:23.877524 (Thread-1): 15:33:23 | 21 of 26 ERROR unique_github_daily_metrics_day....................... [ERROR in 0.07s]
2020-11-18 15:33:23.877609 (Thread-1): Finished running node test.github_source.unique_github_daily_metrics_day
2020-11-18 15:33:23.877733 (Thread-1): Began running node test.github_source.unique_github_issues_issue_id
2020-11-18 15:33:23.877830 (Thread-1): 15:33:23 | 22 of 26 START test unique_github_issues_issue_id.................... [RUN]
2020-11-18 15:33:23.907387 (Thread-65): handling poll request
2020-11-18 15:33:23.908025 (Thread-65): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8186fd0>]}
2020-11-18 15:33:23.912898 (Thread-65): sending response (<Response 13316 bytes [200 OK]>) to 10.0.34.62
2020-11-18 15:33:23.878050 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_issues_issue_id".
2020-11-18 15:33:23.878132 (Thread-1): Compiling test.github_source.unique_github_issues_issue_id
2020-11-18 15:33:23.887232 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:23.902741 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:23.920364 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:23.929449 (Thread-1): finished collecting timing info
2020-11-18 15:33:23.929956 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:23.930662 (Thread-1): 15:33:23 | 22 of 26 ERROR unique_github_issues_issue_id......................... [ERROR in 0.05s]
2020-11-18 15:33:23.930754 (Thread-1): Finished running node test.github_source.unique_github_issues_issue_id
2020-11-18 15:33:23.930883 (Thread-1): Began running node test.github_source.unique_github_monthly_metrics_month
2020-11-18 15:33:23.930980 (Thread-1): 15:33:23 | 23 of 26 START test unique_github_monthly_metrics_month.............. [RUN]
2020-11-18 15:33:23.931208 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_monthly_metrics_month".
2020-11-18 15:33:23.931291 (Thread-1): Compiling test.github_source.unique_github_monthly_metrics_month
2020-11-18 15:33:23.940292 (Thread-1): Compiling model.github_source.github_monthly_metrics
2020-11-18 15:33:23.953048 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:23.968384 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:23.983822 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:24.001717 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:24.009583 (Thread-1): finished collecting timing info
2020-11-18 15:33:24.010087 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:24.010971 (Thread-1): 15:33:24 | 23 of 26 ERROR unique_github_monthly_metrics_month................... [ERROR in 0.08s]
2020-11-18 15:33:24.011054 (Thread-1): Finished running node test.github_source.unique_github_monthly_metrics_month
2020-11-18 15:33:24.011178 (Thread-1): Began running node test.github_source.unique_github_pull_requests_issue_id
2020-11-18 15:33:24.011270 (Thread-1): 15:33:24 | 24 of 26 START test unique_github_pull_requests_issue_id............. [RUN]
2020-11-18 15:33:24.011492 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_pull_requests_issue_id".
2020-11-18 15:33:24.011572 (Thread-1): Compiling test.github_source.unique_github_pull_requests_issue_id
2020-11-18 15:33:24.020935 (Thread-1): Compiling model.github_source.github_pull_requests
2020-11-18 15:33:24.037020 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:24.053109 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:24.061137 (Thread-1): finished collecting timing info
2020-11-18 15:33:24.061666 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:24.062391 (Thread-1): 15:33:24 | 24 of 26 ERROR unique_github_pull_requests_issue_id.................. [ERROR in 0.05s]
2020-11-18 15:33:24.062472 (Thread-1): Finished running node test.github_source.unique_github_pull_requests_issue_id
2020-11-18 15:33:24.062600 (Thread-1): Began running node test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 15:33:24.062697 (Thread-1): 15:33:24 | 25 of 26 START test unique_github_quarterly_metrics_quarter.......... [RUN]
2020-11-18 15:33:24.062920 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_quarterly_metrics_quarter".
2020-11-18 15:33:24.063003 (Thread-1): Compiling test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 15:33:24.072273 (Thread-1): Compiling model.github_source.github_quarterly_metrics
2020-11-18 15:33:24.084434 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:24.100383 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:24.120179 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:24.146456 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:24.154118 (Thread-1): finished collecting timing info
2020-11-18 15:33:24.154610 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:24.155264 (Thread-1): 15:33:24 | 25 of 26 ERROR unique_github_quarterly_metrics_quarter............... [ERROR in 0.09s]
2020-11-18 15:33:24.155346 (Thread-1): Finished running node test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 15:33:24.155469 (Thread-1): Began running node test.github_source.unique_github_weekly_metrics_week
2020-11-18 15:33:24.155560 (Thread-1): 15:33:24 | 26 of 26 START test unique_github_weekly_metrics_week................ [RUN]
2020-11-18 15:33:24.155770 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_weekly_metrics_week".
2020-11-18 15:33:24.155847 (Thread-1): Compiling test.github_source.unique_github_weekly_metrics_week
2020-11-18 15:33:24.164915 (Thread-1): Compiling model.github_source.github_weekly_metrics
2020-11-18 15:33:24.177424 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:33:24.192388 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:33:24.207240 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:33:24.224675 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:33:24.232911 (Thread-1): finished collecting timing info
2020-11-18 15:33:24.233699 (Thread-1): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 496, in catch_jinja
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 1090, in render
    self.environment.handle_exception()
  File "/usr/local/lib/python3.6/dist-packages/jinja2/environment.py", line 832, in handle_exception
    reraise(*rewrite_traceback_stack(source=source))
  File "/usr/local/lib/python3.6/dist-packages/jinja2/_compat.py", line 28, in reraise
    raise value.with_traceback(tb)
  File "<template>", line 10, in top-level template code
  File "/usr/local/lib/python3.6/dist-packages/jinja2/sandbox.py", line 407, in getattr
    value = getattr(obj, attribute)
jinja2.exceptions.UndefinedError: 'fivetran_utils' is undefined

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 270, in compile_and_execute
    ctx.node = self.compile(manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/compile.py", line 23, in compile
    return compiler.compile_node(self.node, manifest, {})
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 394, in _compile_node
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 356, in _insert_ctes
    compiled_node, manifest, extra_context
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 312, in _recursively_prepend_ctes
    extra_context,
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 193, in _get_compiled_model
    node = self.compile_node(cte_model, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 479, in compile_node
    node = self._compile_node(node, manifest, extra_context)
  File "/usr/local/lib/python3.6/dist-packages/dbt/compilation.py", line 388, in _compile_node
    node,
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 577, in get_rendered
    return render_template(template, ctx, node)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 528, in render_template
    return template.render(ctx)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/clients/jinja.py", line 501, in catch_jinja
    raise CompilationException(str(e), node) from e
dbt.exceptions.CompilationException: Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
  'fivetran_utils' is undefined
2020-11-18 15:33:24.234693 (Thread-1): 15:33:24 | 26 of 26 ERROR unique_github_weekly_metrics_week..................... [ERROR in 0.08s]
2020-11-18 15:33:24.234814 (Thread-1): Finished running node test.github_source.unique_github_weekly_metrics_week
2020-11-18 15:33:24.288645 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 15:33:24.289003 (MainThread): 15:33:24 | 
2020-11-18 15:33:24.289083 (MainThread): 15:33:24 | Finished running 26 tests in 11.01s.
2020-11-18 15:33:24.289174 (MainThread): Connection 'master' was properly closed.
2020-11-18 15:33:24.289229 (MainThread): Connection 'test.github_source.unique_github_weekly_metrics_week' was properly closed.
2020-11-18 15:33:24.464779 (MainThread): 
2020-11-18 15:33:24.465028 (MainThread): Completed with 22 errors and 0 warnings:
2020-11-18 15:33:24.465159 (MainThread): 
2020-11-18 15:33:24.465267 (MainThread): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.465348 (MainThread):   404 Not found: Table abij-playground:github.issue_assignee was not found in location EU
2020-11-18 15:33:24.465420 (MainThread):   
2020-11-18 15:33:24.465490 (MainThread):   (job ID: abe6a365-12f0-403a-8dd0-bf230893a8c5)
2020-11-18 15:33:24.465566 (MainThread): 
2020-11-18 15:33:24.465650 (MainThread): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
2020-11-18 15:33:24.465724 (MainThread):   404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU
2020-11-18 15:33:24.465793 (MainThread):   
2020-11-18 15:33:24.465858 (MainThread):   (job ID: 792427d7-264d-4b81-b9fa-e3523c9c434f)
2020-11-18 15:33:24.465929 (MainThread): 
2020-11-18 15:33:24.466008 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.466077 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.466147 (MainThread): 
2020-11-18 15:33:24.466225 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.466296 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.466370 (MainThread): 
2020-11-18 15:33:24.466449 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.466518 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.466591 (MainThread): 
2020-11-18 15:33:24.466673 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.466746 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.466817 (MainThread): 
2020-11-18 15:33:24.466898 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.466971 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.467043 (MainThread): 
2020-11-18 15:33:24.467122 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.467195 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.467267 (MainThread): 
2020-11-18 15:33:24.467346 (MainThread): Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.467418 (MainThread):   404 Not found: Table abij-playground:github.issue_comment was not found in location EU
2020-11-18 15:33:24.467486 (MainThread):   
2020-11-18 15:33:24.467555 (MainThread):   (job ID: f43269eb-b946-424c-af50-84953e75a9fb)
2020-11-18 15:33:24.467626 (MainThread): 
2020-11-18 15:33:24.467709 (MainThread): Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.467782 (MainThread):   404 Not found: Table abij-playground:github.issue was not found in location EU
2020-11-18 15:33:24.467848 (MainThread):   
2020-11-18 15:33:24.467912 (MainThread):   (job ID: d1a4ff10-152e-4388-aeed-f58f4bfb15de)
2020-11-18 15:33:24.467983 (MainThread): 
2020-11-18 15:33:24.468071 (MainThread): Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.468145 (MainThread):   404 Not found: Table abij-playground:github.pull_request was not found in location EU
2020-11-18 15:33:24.468209 (MainThread):   
2020-11-18 15:33:24.468271 (MainThread):   (job ID: 63096e60-4006-405c-be01-ade2ec06139f)
2020-11-18 15:33:24.468341 (MainThread): 
2020-11-18 15:33:24.468421 (MainThread): Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.468492 (MainThread):   404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
2020-11-18 15:33:24.468555 (MainThread):   
2020-11-18 15:33:24.468621 (MainThread):   (job ID: 2d9c56fe-a716-4513-ae58-ed6ba6d2133f)
2020-11-18 15:33:24.468694 (MainThread): 
2020-11-18 15:33:24.468774 (MainThread): Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.468844 (MainThread):   404 Not found: Table abij-playground:github.issue_comment was not found in location EU
2020-11-18 15:33:24.468907 (MainThread):   
2020-11-18 15:33:24.468970 (MainThread):   (job ID: d34f8772-a0da-4526-88a6-5f9f82321f97)
2020-11-18 15:33:24.469039 (MainThread): 
2020-11-18 15:33:24.469116 (MainThread): Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.469204 (MainThread):   404 Not found: Table abij-playground:github.issue was not found in location EU
2020-11-18 15:33:24.469271 (MainThread):   
2020-11-18 15:33:24.469334 (MainThread):   (job ID: c320551b-a89b-4f91-a548-b56e34fb502a)
2020-11-18 15:33:24.469403 (MainThread): 
2020-11-18 15:33:24.469483 (MainThread): Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.469553 (MainThread):   404 Not found: Table abij-playground:github.pull_request was not found in location EU
2020-11-18 15:33:24.469619 (MainThread):   
2020-11-18 15:33:24.469687 (MainThread):   (job ID: dd785a45-5a34-4c4a-9d74-c15734b1c963)
2020-11-18 15:33:24.469757 (MainThread): 
2020-11-18 15:33:24.469838 (MainThread): Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
2020-11-18 15:33:24.469909 (MainThread):   404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
2020-11-18 15:33:24.469973 (MainThread):   
2020-11-18 15:33:24.470040 (MainThread):   (job ID: bd3d3bde-e145-4522-aa72-01dc3e23a00e)
2020-11-18 15:33:24.470123 (MainThread): 
2020-11-18 15:33:24.470225 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.470316 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.470400 (MainThread): 
2020-11-18 15:33:24.470495 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.470597 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.470688 (MainThread): 
2020-11-18 15:33:24.470788 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.470876 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.470970 (MainThread): 
2020-11-18 15:33:24.471071 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.471159 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.471247 (MainThread): 
2020-11-18 15:33:24.471349 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.471438 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.471526 (MainThread): 
2020-11-18 15:33:24.471621 (MainThread): Compilation Error in model github_issue_labels (models/github/github_issue_labels.sql)
2020-11-18 15:33:24.471711 (MainThread):   'fivetran_utils' is undefined
2020-11-18 15:33:24.471833 (MainThread): 
Done. PASS=4 WARN=0 ERROR=22 SKIP=0 TOTAL=26
2020-11-18 15:33:25.183465 (Thread-66): handling poll request
2020-11-18 15:33:25.183998 (Thread-66): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc817eeb8>]}
2020-11-18 15:33:25.277786 (Thread-66): sending response (<Response 148537 bytes [200 OK]>) to 10.0.30.126
2020-11-18 15:33:25.621286 (Thread-67): handling status request
2020-11-18 15:33:25.621787 (Thread-67): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8443c88>]}
2020-11-18 15:33:25.624440 (Thread-67): sending response (<Response 4846 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:35:31.826852 (MainThread): writing 1 spans (enabled:True)
2020-11-18 15:35:31.828467 (MainThread): 
      name jinja2.compile
        id 18187475930927494924
  trace_id 6938816461464460698
 parent_id None
   service None
  resource <memory>
      type template
     start 1605713731.825929
       end 1605713731.826683
  duration 0.000754s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:fbe41a1a9fef4dc6b4d89ae108b31842
2020-11-18 15:35:32.186217 (Thread-68): Got an acceptable cached parse result
2020-11-18 15:35:32.392080 (Thread-69): handling status request
2020-11-18 15:35:32.400779 (Thread-69): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc323a860>]}
2020-11-18 15:35:32.401821 (Thread-69): sending response (<Response 184 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:35:32.568029 (AgentWriter): reported 41 traces in 0.01278s
2020-11-18 15:35:32.568262 (AgentWriter): initialized RateSampler, sample 100% of traces, 31 additional messages skipped
2020-11-18 15:35:33.079511 (Thread-68): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github
- models.github.intermediate

2020-11-18 15:35:33.697365 (Thread-70): handling status request
2020-11-18 15:35:33.697902 (Thread-70): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8261940>]}
2020-11-18 15:35:33.698980 (Thread-70): sending response (<Response 890 bytes [200 OK]>) to 10.0.14.29
2020-11-18 15:35:37.069371 (Thread-71): handling status request
2020-11-18 15:35:37.069908 (Thread-71): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82619b0>]}
2020-11-18 15:35:37.071000 (Thread-71): sending response (<Response 890 bytes [200 OK]>) to 10.0.14.29
2020-11-18 15:35:37.173840 (Thread-72): handling status request
2020-11-18 15:35:37.174374 (Thread-72): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8267b70>]}
2020-11-18 15:35:37.175402 (Thread-72): sending response (<Response 890 bytes [200 OK]>) to 10.0.41.79
2020-11-18 15:35:37.412516 (Thread-73): handling deps request
2020-11-18 15:35:37.413035 (Thread-73): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8267ac8>]}
2020-11-18 15:35:37.472722 (Thread-73): sending response (<Response 137 bytes [200 OK]>) to 10.0.44.246
2020-11-18 15:35:37.785467 (Thread-74): handling poll request
2020-11-18 15:35:37.786036 (Thread-74): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82679e8>]}
2020-11-18 15:35:37.787629 (Thread-74): sending response (<Response 288 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:35:39.111046 (Thread-75): handling poll request
2020-11-18 15:35:39.111547 (Thread-75): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc35330f0>]}
2020-11-18 15:35:39.112568 (Thread-75): sending response (<Response 288 bytes [200 OK]>) to 10.0.34.241
2020-11-18 15:35:39.764538 (MainThread): Set downloads directory='/tmp/dbt-downloads-xyzb6w56'
2020-11-18 15:35:39.769379 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/index.json
2020-11-18 15:35:39.882461 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/index.json 200
2020-11-18 15:35:39.882958 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2020-11-18 15:35:39.931095 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2020-11-18 15:35:39.946269 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json
2020-11-18 15:35:39.995094 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json 200
2020-11-18 15:35:40.000360 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2020-11-18 15:35:40.303750 (MainThread): STDOUT: "b''"
2020-11-18 15:35:40.304044 (MainThread): STDERR: "b"Cloning into '2570ae56bf9cb34e49fe01aa3bc99195'...\n""
2020-11-18 15:35:40.304438 (MainThread): Pulling new dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2020-11-18 15:35:40.304545 (MainThread): Executing "git rev-parse HEAD"
2020-11-18 15:35:40.309913 (MainThread): STDOUT: "b'653365efe12aa3555bb18095af6d20bb3fc68c6f\n'"
2020-11-18 15:35:40.310210 (MainThread): STDERR: "b''"
2020-11-18 15:35:40.310320 (MainThread):   Checking out branch master.
2020-11-18 15:35:40.310384 (MainThread): Executing "git remote set-branches origin master"
2020-11-18 15:35:40.317276 (MainThread): STDOUT: "b''"
2020-11-18 15:35:40.317534 (MainThread): STDERR: "b''"
2020-11-18 15:35:40.317610 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2020-11-18 15:35:40.379433 (Thread-76): handling poll request
2020-11-18 15:35:40.380013 (Thread-76): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc332c908>]}
2020-11-18 15:35:40.383320 (Thread-76): sending response (<Response 5863 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:35:40.582172 (MainThread): STDOUT: "b''"
2020-11-18 15:35:40.582468 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2020-11-18 15:35:40.582554 (MainThread): Executing "git tag --list"
2020-11-18 15:35:40.587815 (MainThread): STDOUT: "b''"
2020-11-18 15:35:40.588072 (MainThread): STDERR: "b''"
2020-11-18 15:35:40.588165 (MainThread): Executing "git reset --hard origin/master"
2020-11-18 15:35:40.595573 (MainThread): STDOUT: "b'HEAD is now at 653365e Update columns_setup.sh\n'"
2020-11-18 15:35:40.595828 (MainThread): STDERR: "b''"
2020-11-18 15:35:40.595919 (MainThread): Executing "git rev-parse HEAD"
2020-11-18 15:35:40.600175 (MainThread): STDOUT: "b'653365efe12aa3555bb18095af6d20bb3fc68c6f\n'"
2020-11-18 15:35:40.600429 (MainThread): STDERR: "b''"
2020-11-18 15:35:40.600514 (MainThread):   Checked out at 653365e.
2020-11-18 15:35:40.629507 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json
2020-11-18 15:35:40.682902 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils.json 200
2020-11-18 15:35:40.697882 (MainThread): Making package registry request: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json
2020-11-18 15:35:40.748602 (MainThread): Response from registry: GET https://hub.getdbt.com/api/v1/fishtown-analytics/dbt_utils/0.6.2.json 200
2020-11-18 15:35:40.749615 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2020-11-18 15:35:40.754558 (MainThread): STDOUT: "b''"
2020-11-18 15:35:40.754752 (MainThread): STDERR: "b"fatal: destination path '2570ae56bf9cb34e49fe01aa3bc99195' already exists and is not an empty directory.\n""
2020-11-18 15:35:40.754806 (MainThread): command return code=128
2020-11-18 15:35:40.755219 (MainThread): Updating existing dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2020-11-18 15:35:40.755311 (MainThread): Executing "git rev-parse HEAD"
2020-11-18 15:35:40.759782 (MainThread): STDOUT: "b'653365efe12aa3555bb18095af6d20bb3fc68c6f\n'"
2020-11-18 15:35:40.760022 (MainThread): STDERR: "b''"
2020-11-18 15:35:40.760110 (MainThread):   Checking out branch master.
2020-11-18 15:35:40.760164 (MainThread): Executing "git remote set-branches origin master"
2020-11-18 15:35:40.765608 (MainThread): STDOUT: "b''"
2020-11-18 15:35:40.765842 (MainThread): STDERR: "b''"
2020-11-18 15:35:40.765914 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2020-11-18 15:35:41.045096 (MainThread): STDOUT: "b''"
2020-11-18 15:35:41.045360 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2020-11-18 15:35:41.045445 (MainThread): Executing "git tag --list"
2020-11-18 15:35:41.050458 (MainThread): STDOUT: "b''"
2020-11-18 15:35:41.050720 (MainThread): STDERR: "b''"
2020-11-18 15:35:41.050811 (MainThread): Executing "git reset --hard origin/master"
2020-11-18 15:35:41.057944 (MainThread): STDOUT: "b'HEAD is now at 653365e Update columns_setup.sh\n'"
2020-11-18 15:35:41.058198 (MainThread): STDERR: "b''"
2020-11-18 15:35:41.058290 (MainThread): Executing "git rev-parse HEAD"
2020-11-18 15:35:41.062525 (MainThread): STDOUT: "b'653365efe12aa3555bb18095af6d20bb3fc68c6f\n'"
2020-11-18 15:35:41.062768 (MainThread): STDERR: "b''"
2020-11-18 15:35:41.062854 (MainThread):   Already at 653365e, nothing to do.
2020-11-18 15:35:41.074786 (MainThread): Installing fishtown-analytics/dbt_utils@0.6.2
2020-11-18 15:35:41.647977 (Thread-77): handling poll request
2020-11-18 15:35:41.648474 (Thread-77): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82a8630>]}
2020-11-18 15:35:41.653689 (Thread-77): sending response (<Response 12067 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:35:42.932754 (Thread-78): handling poll request
2020-11-18 15:35:42.933308 (Thread-78): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc83ab128>]}
2020-11-18 15:35:42.934327 (Thread-78): sending response (<Response 288 bytes [200 OK]>) to 10.0.30.126
2020-11-18 15:35:44.250448 (Thread-79): handling poll request
2020-11-18 15:35:44.250995 (Thread-79): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc83ab0f0>]}
2020-11-18 15:35:44.252086 (Thread-79): sending response (<Response 288 bytes [200 OK]>) to 10.0.41.79
2020-11-18 15:35:45.563413 (Thread-80): handling poll request
2020-11-18 15:35:45.563909 (Thread-80): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc819bba8>]}
2020-11-18 15:35:45.564933 (Thread-80): sending response (<Response 288 bytes [200 OK]>) to 10.0.3.20
2020-11-18 15:35:46.830333 (Thread-81): handling poll request
2020-11-18 15:35:46.830862 (Thread-81): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc83abc88>]}
2020-11-18 15:35:46.831871 (Thread-81): sending response (<Response 288 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:35:47.561773 (MainThread):   Installed from version 0.6.2

2020-11-18 15:35:47.562096 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'e63168e7-5ed7-4cbf-92fb-1dd7a4154ace', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd249612a58>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd249612240>]}
2020-11-18 15:35:47.562439 (MainThread): Installing https://github.com/fivetran/dbt_fivetran_utils.git@master
2020-11-18 15:35:47.564064 (MainThread): Executing "git clone --depth 1 https://github.com/fivetran/dbt_fivetran_utils.git 2570ae56bf9cb34e49fe01aa3bc99195"
2020-11-18 15:35:47.570299 (MainThread): STDOUT: "b''"
2020-11-18 15:35:47.570629 (MainThread): STDERR: "b"fatal: destination path '2570ae56bf9cb34e49fe01aa3bc99195' already exists and is not an empty directory.\n""
2020-11-18 15:35:47.570706 (MainThread): command return code=128
2020-11-18 15:35:47.570897 (MainThread): Updating existing dependency 2570ae56bf9cb34e49fe01aa3bc99195.
2020-11-18 15:35:47.570987 (MainThread): Executing "git rev-parse HEAD"
2020-11-18 15:35:47.576163 (MainThread): STDOUT: "b'653365efe12aa3555bb18095af6d20bb3fc68c6f\n'"
2020-11-18 15:35:47.576357 (MainThread): STDERR: "b''"
2020-11-18 15:35:47.576439 (MainThread):   Checking out branch master.
2020-11-18 15:35:47.576493 (MainThread): Executing "git remote set-branches origin master"
2020-11-18 15:35:47.581364 (MainThread): STDOUT: "b''"
2020-11-18 15:35:47.581561 (MainThread): STDERR: "b''"
2020-11-18 15:35:47.581638 (MainThread): Executing "git fetch --tags --depth 1 origin master"
2020-11-18 15:35:47.914127 (MainThread): STDOUT: "b''"
2020-11-18 15:35:47.914417 (MainThread): STDERR: "b'From https://github.com/fivetran/dbt_fivetran_utils\n * branch            master     -> FETCH_HEAD\n'"
2020-11-18 15:35:47.914505 (MainThread): Executing "git tag --list"
2020-11-18 15:35:47.919755 (MainThread): STDOUT: "b''"
2020-11-18 15:35:47.920009 (MainThread): STDERR: "b''"
2020-11-18 15:35:47.920098 (MainThread): Executing "git reset --hard origin/master"
2020-11-18 15:35:47.926426 (MainThread): STDOUT: "b'HEAD is now at 653365e Update columns_setup.sh\n'"
2020-11-18 15:35:47.926677 (MainThread): STDERR: "b''"
2020-11-18 15:35:47.926765 (MainThread): Executing "git rev-parse HEAD"
2020-11-18 15:35:47.931037 (MainThread): STDOUT: "b'653365efe12aa3555bb18095af6d20bb3fc68c6f\n'"
2020-11-18 15:35:47.931289 (MainThread): STDERR: "b''"
2020-11-18 15:35:47.931376 (MainThread):   Already at 653365e, nothing to do.
2020-11-18 15:35:48.132882 (Thread-82): handling poll request
2020-11-18 15:35:48.133423 (Thread-82): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc83ab860>]}
2020-11-18 15:35:48.137430 (Thread-82): sending response (<Response 8311 bytes [200 OK]>) to 10.0.44.246
2020-11-18 15:35:49.473103 (Thread-83): handling poll request
2020-11-18 15:35:49.473649 (Thread-83): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc323a898>]}
2020-11-18 15:35:49.474670 (Thread-83): sending response (<Response 289 bytes [200 OK]>) to 10.0.37.56
2020-11-18 15:35:50.608408 (MainThread):   Installed from revision master

2020-11-18 15:35:50.608740 (MainThread): Sending event: {'category': 'dbt', 'action': 'package', 'label': 'e63168e7-5ed7-4cbf-92fb-1dd7a4154ace', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd249612a58>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd249612da0>]}
2020-11-18 15:35:50.757588 (Thread-84): handling poll request
2020-11-18 15:35:50.758093 (Thread-84): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc332c400>]}
2020-11-18 15:35:50.759328 (Thread-84): sending response (<Response 1099 bytes [200 OK]>) to 10.0.21.190
2020-11-18 15:35:50.902698 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): project hash mismatch: values missing, cache invalidated: {'fivetran_utils'}
2020-11-18 15:35:50.903885 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/adapters.sql
2020-11-18 15:35:50.924263 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/etc.sql
2020-11-18 15:35:50.925710 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/catalog.sql
2020-11-18 15:35:50.931766 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/table.sql
2020-11-18 15:35:50.942177 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/view.sql
2020-11-18 15:35:50.945229 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/copy.sql
2020-11-18 15:35:50.949885 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/seed.sql
2020-11-18 15:35:50.952808 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/incremental.sql
2020-11-18 15:35:50.968498 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/snapshot.sql
2020-11-18 15:35:50.971700 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/core.sql
2020-11-18 15:35:50.975807 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/adapters/common.sql
2020-11-18 15:35:51.035601 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/helpers.sql
2020-11-18 15:35:51.051724 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/table/table.sql
2020-11-18 15:35:51.063116 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/seed/seed.sql
2020-11-18 15:35:51.099889 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/view/view.sql
2020-11-18 15:35:51.109556 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 15:35:51.117712 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 15:35:51.120165 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 15:35:51.126872 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/common/merge.sql
2020-11-18 15:35:51.141822 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 15:35:51.159891 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 15:35:51.161952 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 15:35:51.191801 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/relationships.sql
2020-11-18 15:35:51.194062 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/not_null.sql
2020-11-18 15:35:51.195788 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/unique.sql
2020-11-18 15:35:51.197680 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 15:35:51.200580 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/etc/get_custom_database.sql
2020-11-18 15:35:51.202404 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/etc/query.sql
2020-11-18 15:35:51.203541 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/etc/datetime.sql
2020-11-18 15:35:51.212968 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/etc/get_custom_alias.sql
2020-11-18 15:35:51.214119 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/etc/is_incremental.sql
2020-11-18 15:35:51.215857 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/etc/get_custom_schema.sql
2020-11-18 15:35:51.270882 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/logger/pretty_time.sql
2020-11-18 15:35:51.277021 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/logger/log_info.sql
2020-11-18 15:35:51.283547 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/logger/pretty_log_format.sql
2020-11-18 15:35:51.289411 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/pivot.sql
2020-11-18 15:35:51.297475 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/star.sql
2020-11-18 15:35:51.306163 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/surrogate_key.sql
2020-11-18 15:35:51.314632 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/get_query_results_as_dict.sql
2020-11-18 15:35:51.322130 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/get_column_values.sql
2020-11-18 15:35:51.332045 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/groupby.sql
2020-11-18 15:35:51.338187 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/get_tables_by_pattern_sql.sql
2020-11-18 15:35:51.349731 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/nullcheck_table.sql
2020-11-18 15:35:51.355841 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/get_tables_by_prefix_sql.sql
2020-11-18 15:35:51.361879 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/get_relations_by_pattern.sql
2020-11-18 15:35:51.369718 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/get_relations_by_prefix.sql
2020-11-18 15:35:51.377545 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/safe_add.sql
2020-11-18 15:35:51.383794 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/unpivot.sql
2020-11-18 15:35:51.396040 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/generate_series.sql
2020-11-18 15:35:51.404666 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/nullcheck.sql
2020-11-18 15:35:51.411678 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/sql/union.sql
2020-11-18 15:35:51.426808 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/materializations/insert_by_period_materialization.sql
2020-11-18 15:35:51.456395 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/web/get_url_parameter.sql
2020-11-18 15:35:51.462874 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/web/get_url_path.sql
2020-11-18 15:35:51.470409 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/web/get_url_host.sql
2020-11-18 15:35:51.477288 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/datetime/date_spine.sql
2020-11-18 15:35:51.486708 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/expression_is_true.sql
2020-11-18 15:35:51.492806 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/not_constant.sql
2020-11-18 15:35:51.499135 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/at_least_one.sql
2020-11-18 15:35:51.504930 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/equality.sql
2020-11-18 15:35:51.514415 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/test_not_null_where.sql
2020-11-18 15:35:51.522337 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/equal_rowcount.sql
2020-11-18 15:35:51.528541 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/test_unique_where.sql
2020-11-18 15:35:51.535589 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2020-11-18 15:35:51.546710 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/relationships_where.sql
2020-11-18 15:35:51.554078 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/unique_combination_of_columns.sql
2020-11-18 15:35:51.561869 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/recency.sql
2020-11-18 15:35:51.568701 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/schema_tests/cardinality_equality.sql
2020-11-18 15:35:51.575434 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/geo/haversine_distance.sql
2020-11-18 15:35:51.581800 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/split_part.sql
2020-11-18 15:35:51.590056 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/length.sql
2020-11-18 15:35:51.596900 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/current_timestamp.sql
2020-11-18 15:35:51.605723 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/_get_utils_namespaces.sql
2020-11-18 15:35:51.611666 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/right.sql
2020-11-18 15:35:51.619899 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/hash.sql
2020-11-18 15:35:51.626718 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/replace.sql
2020-11-18 15:35:51.633166 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/concat.sql
2020-11-18 15:35:51.640764 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/_is_relation.sql
2020-11-18 15:35:51.647272 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/identifier.sql
2020-11-18 15:35:51.654341 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/datediff.sql
2020-11-18 15:35:51.669571 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/dateadd.sql
2020-11-18 15:35:51.677547 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/datatypes.sql
2020-11-18 15:35:51.689725 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/position.sql
2020-11-18 15:35:51.697287 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/literal.sql
2020-11-18 15:35:51.703471 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/_is_ephemeral.sql
2020-11-18 15:35:51.710818 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/width_bucket.sql
2020-11-18 15:35:51.722079 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/date_trunc.sql
2020-11-18 15:35:51.729078 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/except.sql
2020-11-18 15:35:51.735515 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/safe_cast.sql
2020-11-18 15:35:51.742731 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/last_day.sql
2020-11-18 15:35:51.751861 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/cross_db_utils/intersect.sql
2020-11-18 15:35:51.764574 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/dummy_coalesce_value.sql
2020-11-18 15:35:51.773257 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/enabled_vars.sql
2020-11-18 15:35:51.780024 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/_get_utils_namespaces.sql
2020-11-18 15:35:51.786242 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/remove_prefix_from_columns.sql
2020-11-18 15:35:51.793658 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/generate_columns_macro.sql
2020-11-18 15:35:51.802736 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/timestamp_add.sql
2020-11-18 15:35:51.810431 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/fill_staging_columns.sql
2020-11-18 15:35:51.818068 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/get_columns_for_macro.sql
2020-11-18 15:35:51.827721 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/string_agg.sql
2020-11-18 15:35:51.835066 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/array_agg.sql
2020-11-18 15:35:51.841950 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Parsing macros/union_relations.sql
2020-11-18 15:35:51.877585 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): project hash mismatch: values missing, cache invalidated: {'fivetran_utils'}
2020-11-18 15:35:51.928518 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 15:35:51.954041 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 15:35:51.972607 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 15:35:51.992617 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 15:35:52.012282 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 15:35:52.030214 (Thread-85): handling poll request
2020-11-18 15:35:52.030693 (Thread-85): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc34e3780>]}
2020-11-18 15:35:52.031685 (Thread-85): sending response (<Response 289 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:35:52.037852 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 15:35:52.056598 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 15:35:52.076109 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 15:35:52.104255 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 15:35:52.126566 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 15:35:52.147403 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 15:35:52.169789 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 15:35:52.189268 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 15:35:52.209261 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 15:35:52.235315 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 15:35:52.260536 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 15:35:52.290224 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 15:35:52.315655 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 15:35:52.336641 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 15:35:52.356018 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 15:35:52.375484 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 15:35:52.395582 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 15:35:52.415729 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 15:35:52.437524 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 15:35:53.333450 (Thread-86): handling poll request
2020-11-18 15:35:53.333982 (Thread-86): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc82dc2e8>]}
2020-11-18 15:35:53.335020 (Thread-86): sending response (<Response 289 bytes [200 OK]>) to 10.0.30.126
2020-11-18 15:35:53.785269 (30a9ca29-b2df-4d8a-8651-adffd45c7413-handler-deps): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github
- models.github.intermediate

2020-11-18 15:35:54.614178 (Thread-87): handling poll request
2020-11-18 15:35:54.614753 (Thread-87): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc35ae470>]}
2020-11-18 15:35:54.615848 (Thread-87): sending response (<Response 314 bytes [200 OK]>) to 10.0.3.20
2020-11-18 15:35:54.900214 (Thread-88): handling status request
2020-11-18 15:35:54.900753 (Thread-88): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc359a160>]}
2020-11-18 15:35:54.910728 (Thread-88): sending response (<Response 26373 bytes [200 OK]>) to 10.0.21.190
2020-11-18 15:37:25.927891 (Thread-89): handling status request
2020-11-18 15:37:25.930375 (Thread-89): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc358cdd8>]}
2020-11-18 15:37:25.945733 (Thread-89): sending response (<Response 26373 bytes [200 OK]>) to 10.0.21.190
2020-11-18 15:37:25.951525 (Thread-90): handling status request
2020-11-18 15:37:25.951935 (Thread-90): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc35099b0>]}
2020-11-18 15:37:25.961775 (Thread-90): sending response (<Response 26373 bytes [200 OK]>) to 10.0.23.22
2020-11-18 15:37:26.278070 (Thread-91): handling cli_args request
2020-11-18 15:37:26.278584 (Thread-91): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3494eb8>]}
2020-11-18 15:37:26.280060 (Thread-91): Checking header 'user-agent' tracing in whitelist set(), 24 additional messages skipped
2020-11-18 15:37:26.301094 (Thread-91): writing 1 spans (enabled:True), 421 additional messages skipped
2020-11-18 15:37:26.301347 (Thread-91): 
      name requests.request
        id 12724901405504232982
  trace_id 5829068973654019718
 parent_id None
   service requests
  resource requests.request
      type http
     start 1605713846.2797492
       end 1605713846.3009892
  duration 0.021240s
     error 0
      tags 
           http.method:POST
           http.status_code:200
           http.url:https://fishtownanalytics.sinter-collect.com/com.snowplowanalytics.snowplow/tp2
           runtime-id:fbe41a1a9fef4dc6b4d89ae108b31842, 446 additional messages skipped
2020-11-18 15:37:26.311624 (Thread-91): Connection 'model.github_source.stg_github_pull_request_review' was properly closed.
2020-11-18 15:37:26.714935 (AgentWriter): reported 1 traces in 0.00451s, 6 additional messages skipped
2020-11-18 15:37:26.715371 (AgentWriter): initialized RateSampler, sample 100% of traces, 223 additional messages skipped
2020-11-18 15:37:27.409598 (Thread-91): sending response (<Response 137 bytes [200 OK]>) to 10.0.3.20
2020-11-18 15:37:27.683865 (Thread-92): handling poll request
2020-11-18 15:37:27.684421 (Thread-92): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc359ada0>]}
2020-11-18 15:37:27.686021 (Thread-92): sending response (<Response 288 bytes [200 OK]>) to 10.0.5.154
2020-11-18 15:37:27.812681 (MainThread): Partial parsing not enabled
2020-11-18 15:37:27.814299 (MainThread): Parsing macros/adapters.sql
2020-11-18 15:37:27.835736 (MainThread): Parsing macros/etc.sql
2020-11-18 15:37:27.837331 (MainThread): Parsing macros/catalog.sql
2020-11-18 15:37:27.843621 (MainThread): Parsing macros/materializations/table.sql
2020-11-18 15:37:27.854401 (MainThread): Parsing macros/materializations/view.sql
2020-11-18 15:37:27.857654 (MainThread): Parsing macros/materializations/copy.sql
2020-11-18 15:37:27.862457 (MainThread): Parsing macros/materializations/seed.sql
2020-11-18 15:37:27.865489 (MainThread): Parsing macros/materializations/incremental.sql
2020-11-18 15:37:27.879344 (MainThread): Parsing macros/materializations/snapshot.sql
2020-11-18 15:37:27.882399 (MainThread): Parsing macros/core.sql
2020-11-18 15:37:27.886512 (MainThread): Parsing macros/adapters/common.sql
2020-11-18 15:37:27.932314 (MainThread): Parsing macros/materializations/helpers.sql
2020-11-18 15:37:27.942203 (MainThread): Parsing macros/materializations/table/table.sql
2020-11-18 15:37:27.949798 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-11-18 15:37:27.972521 (MainThread): Parsing macros/materializations/view/view.sql
2020-11-18 15:37:27.979408 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 15:37:27.985009 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 15:37:27.987119 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 15:37:27.993910 (MainThread): Parsing macros/materializations/common/merge.sql
2020-11-18 15:37:28.009010 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 15:37:28.026797 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 15:37:28.028906 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 15:37:28.058982 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-11-18 15:37:28.061283 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-11-18 15:37:28.063017 (MainThread): Parsing macros/schema_tests/unique.sql
2020-11-18 15:37:28.064963 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 15:37:28.067909 (MainThread): Parsing macros/etc/get_custom_database.sql
2020-11-18 15:37:28.069793 (MainThread): Parsing macros/etc/query.sql
2020-11-18 15:37:28.071019 (MainThread): Parsing macros/etc/datetime.sql
2020-11-18 15:37:28.081016 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-11-18 15:37:28.082181 (MainThread): Parsing macros/etc/is_incremental.sql
2020-11-18 15:37:28.083971 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-11-18 15:37:28.252790 (MainThread): Parsing macros/logger/pretty_time.sql
2020-11-18 15:37:28.263728 (MainThread): Parsing macros/logger/log_info.sql
2020-11-18 15:37:28.273098 (MainThread): Parsing macros/logger/pretty_log_format.sql
2020-11-18 15:37:28.279864 (MainThread): Parsing macros/sql/pivot.sql
2020-11-18 15:37:28.291661 (MainThread): Parsing macros/sql/star.sql
2020-11-18 15:37:28.301421 (MainThread): Parsing macros/sql/surrogate_key.sql
2020-11-18 15:37:28.309610 (MainThread): Parsing macros/sql/get_query_results_as_dict.sql
2020-11-18 15:37:28.343628 (MainThread): Parsing macros/sql/get_column_values.sql
2020-11-18 15:37:28.363719 (MainThread): Parsing macros/sql/groupby.sql
2020-11-18 15:37:28.370220 (MainThread): Parsing macros/sql/get_tables_by_pattern_sql.sql
2020-11-18 15:37:28.380986 (MainThread): Parsing macros/sql/nullcheck_table.sql
2020-11-18 15:37:28.386064 (MainThread): Parsing macros/sql/get_tables_by_prefix_sql.sql
2020-11-18 15:37:28.391524 (MainThread): Parsing macros/sql/get_relations_by_pattern.sql
2020-11-18 15:37:28.397718 (MainThread): Parsing macros/sql/get_relations_by_prefix.sql
2020-11-18 15:37:28.404177 (MainThread): Parsing macros/sql/safe_add.sql
2020-11-18 15:37:28.408865 (MainThread): Parsing macros/sql/unpivot.sql
2020-11-18 15:37:28.419295 (MainThread): Parsing macros/sql/generate_series.sql
2020-11-18 15:37:28.441845 (MainThread): Parsing macros/sql/nullcheck.sql
2020-11-18 15:37:28.448358 (MainThread): Parsing macros/sql/union.sql
2020-11-18 15:37:28.465448 (MainThread): Parsing macros/materializations/insert_by_period_materialization.sql
2020-11-18 15:37:28.493571 (MainThread): Parsing macros/web/get_url_parameter.sql
2020-11-18 15:37:28.498363 (MainThread): Parsing macros/web/get_url_path.sql
2020-11-18 15:37:28.504554 (MainThread): Parsing macros/web/get_url_host.sql
2020-11-18 15:37:28.510371 (MainThread): Parsing macros/datetime/date_spine.sql
2020-11-18 15:37:28.518198 (MainThread): Parsing macros/schema_tests/expression_is_true.sql
2020-11-18 15:37:28.523001 (MainThread): Parsing macros/schema_tests/not_constant.sql
2020-11-18 15:37:28.528010 (MainThread): Parsing macros/schema_tests/at_least_one.sql
2020-11-18 15:37:28.532792 (MainThread): Parsing macros/schema_tests/equality.sql
2020-11-18 15:37:28.540538 (MainThread): Parsing macros/schema_tests/test_not_null_where.sql
2020-11-18 15:37:28.545834 (MainThread): Parsing macros/schema_tests/equal_rowcount.sql
2020-11-18 15:37:28.551352 (MainThread): Parsing macros/schema_tests/test_unique_where.sql
2020-11-18 15:37:28.556564 (MainThread): Parsing macros/schema_tests/mutually_exclusive_ranges.sql
2020-11-18 15:37:28.566271 (MainThread): Parsing macros/schema_tests/relationships_where.sql
2020-11-18 15:37:28.572219 (MainThread): Parsing macros/schema_tests/unique_combination_of_columns.sql
2020-11-18 15:37:28.578359 (MainThread): Parsing macros/schema_tests/recency.sql
2020-11-18 15:37:28.583417 (MainThread): Parsing macros/schema_tests/cardinality_equality.sql
2020-11-18 15:37:28.589235 (MainThread): Parsing macros/geo/haversine_distance.sql
2020-11-18 15:37:28.594155 (MainThread): Parsing macros/cross_db_utils/split_part.sql
2020-11-18 15:37:28.600222 (MainThread): Parsing macros/cross_db_utils/length.sql
2020-11-18 15:37:28.605305 (MainThread): Parsing macros/cross_db_utils/current_timestamp.sql
2020-11-18 15:37:28.612184 (MainThread): Parsing macros/cross_db_utils/_get_utils_namespaces.sql
2020-11-18 15:37:28.616949 (MainThread): Parsing macros/cross_db_utils/right.sql
2020-11-18 15:37:28.622866 (MainThread): Parsing macros/cross_db_utils/hash.sql
2020-11-18 15:37:28.628010 (MainThread): Parsing macros/cross_db_utils/replace.sql
2020-11-18 15:37:28.632746 (MainThread): Parsing macros/cross_db_utils/concat.sql
2020-11-18 15:37:28.638633 (MainThread): Parsing macros/cross_db_utils/_is_relation.sql
2020-11-18 15:37:28.644028 (MainThread): Parsing macros/cross_db_utils/identifier.sql
2020-11-18 15:37:28.650820 (MainThread): Parsing macros/cross_db_utils/datediff.sql
2020-11-18 15:37:28.672816 (MainThread): Parsing macros/cross_db_utils/dateadd.sql
2020-11-18 15:37:28.680904 (MainThread): Parsing macros/cross_db_utils/datatypes.sql
2020-11-18 15:37:28.692700 (MainThread): Parsing macros/cross_db_utils/position.sql
2020-11-18 15:37:28.698054 (MainThread): Parsing macros/cross_db_utils/literal.sql
2020-11-18 15:37:28.702747 (MainThread): Parsing macros/cross_db_utils/_is_ephemeral.sql
2020-11-18 15:37:28.708463 (MainThread): Parsing macros/cross_db_utils/width_bucket.sql
2020-11-18 15:37:28.718673 (MainThread): Parsing macros/cross_db_utils/date_trunc.sql
2020-11-18 15:37:28.723928 (MainThread): Parsing macros/cross_db_utils/except.sql
2020-11-18 15:37:28.728885 (MainThread): Parsing macros/cross_db_utils/safe_cast.sql
2020-11-18 15:37:28.734830 (MainThread): Parsing macros/cross_db_utils/last_day.sql
2020-11-18 15:37:28.741688 (MainThread): Parsing macros/cross_db_utils/intersect.sql
2020-11-18 15:37:28.748098 (MainThread): Parsing macros/dummy_coalesce_value.sql
2020-11-18 15:37:28.755368 (MainThread): Parsing macros/enabled_vars.sql
2020-11-18 15:37:28.760299 (MainThread): Parsing macros/_get_utils_namespaces.sql
2020-11-18 15:37:28.764855 (MainThread): Parsing macros/remove_prefix_from_columns.sql
2020-11-18 15:37:28.770160 (MainThread): Parsing macros/generate_columns_macro.sql
2020-11-18 15:37:28.777362 (MainThread): Parsing macros/timestamp_add.sql
2020-11-18 15:37:28.784136 (MainThread): Parsing macros/fill_staging_columns.sql
2020-11-18 15:37:28.790195 (MainThread): Parsing macros/get_columns_for_macro.sql
2020-11-18 15:37:28.798356 (MainThread): Parsing macros/string_agg.sql
2020-11-18 15:37:28.804505 (MainThread): Parsing macros/array_agg.sql
2020-11-18 15:37:28.809858 (MainThread): Parsing macros/union_relations.sql
2020-11-18 15:37:28.838739 (MainThread): Partial parsing not enabled
2020-11-18 15:37:28.903838 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 15:37:28.938605 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_requests".
2020-11-18 15:37:28.964770 (Thread-93): handling poll request
2020-11-18 15:37:28.965294 (Thread-93): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc34c5a20>]}
2020-11-18 15:37:28.956275 (MainThread): Acquiring new bigquery connection "model.github_source.github_issues".
2020-11-18 15:37:28.977458 (Thread-93): sending response (<Response 29447 bytes [200 OK]>) to 10.0.3.20
2020-11-18 15:37:28.976428 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_assignees".
2020-11-18 15:37:29.001634 (MainThread): Acquiring new bigquery connection "model.github_source.github_pull_request_times".
2020-11-18 15:37:29.034416 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_comments".
2020-11-18 15:37:29.052138 (MainThread): Acquiring new bigquery connection "model.github_source.github_monthly_metrics".
2020-11-18 15:37:29.073683 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_joined".
2020-11-18 15:37:29.104530 (MainThread): Acquiring new bigquery connection "model.github_source.github_daily_metrics".
2020-11-18 15:37:29.126697 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_open_length".
2020-11-18 15:37:29.147225 (MainThread): Acquiring new bigquery connection "model.github_source.github_issue_labels".
2020-11-18 15:37:29.166664 (MainThread): Acquiring new bigquery connection "model.github_source.github_weekly_metrics".
2020-11-18 15:37:29.185249 (MainThread): Acquiring new bigquery connection "model.github_source.github_quarterly_metrics".
2020-11-18 15:37:29.203801 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_closed_history".
2020-11-18 15:37:29.222570 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_requested_reviewer_history".
2020-11-18 15:37:29.240889 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_comment".
2020-11-18 15:37:29.259945 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_assignee".
2020-11-18 15:37:29.278615 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_user".
2020-11-18 15:37:29.297910 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request".
2020-11-18 15:37:29.366952 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue".
2020-11-18 15:37:29.386919 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_merged".
2020-11-18 15:37:29.405253 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_issue_label".
2020-11-18 15:37:29.423367 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_repository".
2020-11-18 15:37:29.441781 (MainThread): Acquiring new bigquery connection "model.github_source.stg_github_pull_request_review".
2020-11-18 15:37:30.252146 (Thread-94): handling poll request
2020-11-18 15:37:30.252680 (Thread-94): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2effba8>]}
2020-11-18 15:37:30.255972 (Thread-94): sending response (<Response 7207 bytes [200 OK]>) to 10.0.18.40
2020-11-18 15:37:30.820050 (MainThread): [WARNING]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 2 unused configuration paths:
- models.github
- models.github.intermediate

2020-11-18 15:37:31.057991 (MainThread): Found 24 models, 26 tests, 0 snapshots, 0 analyses, 310 macros, 0 operations, 0 seed files, 11 sources
2020-11-18 15:37:31.064536 (MainThread): 
2020-11-18 15:37:31.064907 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 15:37:31.101649 (ThreadPoolExecutor-1_0): Acquiring new bigquery connection "list_abij-playground_dbt_abij".
2020-11-18 15:37:31.101810 (ThreadPoolExecutor-1_0): Opening a new connection, currently in state init
2020-11-18 15:37:31.102527 (ThreadPoolExecutor-1_0): Client.dataset is deprecated and will be removed in a future version. Use a string like 'my_project.my_dataset' or a cloud.google.bigquery.DatasetReference object, instead.
2020-11-18 15:37:31.335315 (MainThread): 15:37:31 | Concurrency: 1 threads (target='default')
2020-11-18 15:37:31.335457 (MainThread): 15:37:31 | 
2020-11-18 15:37:31.337869 (Thread-1): Began running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 15:37:31.338065 (Thread-1): 15:37:31 | 1 of 26 START test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id [RUN]
2020-11-18 15:37:31.338343 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id".
2020-11-18 15:37:31.338443 (Thread-1): Compiling test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 15:37:31.360897 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"
2020-11-18 15:37:31.386069 (Thread-1): finished collecting timing info
2020-11-18 15:37:31.386529 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:31.387017 (Thread-1): On test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"} */






with validation_errors as (

    select
        issue_id, user_id
    from `abij-playground`.`github`.`issue_assignee`

    group by issue_id, user_id
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:37:31.562012 (Thread-95): handling poll request
2020-11-18 15:37:31.562529 (Thread-95): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37cee80>]}
2020-11-18 15:37:31.565266 (Thread-95): sending response (<Response 7572 bytes [200 OK]>) to 10.0.30.126
2020-11-18 15:37:31.762799 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"} */






with validation_errors as (

    select
        issue_id, user_id
    from `abij-playground`.`github`.`issue_assignee`

    group by issue_id, user_id
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:37:31.763170 (Thread-1): finished collecting timing info
2020-11-18 15:37:31.763836 (Thread-1): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_assignee was not found in location EU
  
  (job ID: 8cf0ea84-50e5-4931-9d91-1fae952db70b)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_assignee was not found in location EU

(job ID: 8cf0ea84-50e5-4931-9d91-1fae952db70b)

                                                                                              -----Query Job SQL Follows-----                                                                                               

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id"} */
   2:
   3:
   4:
   5:
   6:
   7:
   8:with validation_errors as (
   9:
  10:    select
  11:        issue_id, user_id
  12:    from `abij-playground`.`github`.`issue_assignee`
  13:
  14:    group by issue_id, user_id
  15:    having count(*) > 1
  16:
  17:)
  18:
  19:select count(*)
  20:from validation_errors
  21:
  22:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_assignee was not found in location EU
  
  (job ID: 8cf0ea84-50e5-4931-9d91-1fae952db70b)
2020-11-18 15:37:31.767318 (Thread-1): 15:37:31 | 1 of 26 ERROR dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id [ERROR in 0.43s]
2020-11-18 15:37:31.767457 (Thread-1): Finished running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id
2020-11-18 15:37:31.767662 (Thread-1): Began running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 15:37:31.767832 (Thread-1): 15:37:31 | 2 of 26 START test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at [RUN]
2020-11-18 15:37:31.768263 (Thread-1): Acquiring new bigquery connection "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at".
2020-11-18 15:37:31.768405 (Thread-1): Compiling test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 15:37:31.773895 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42536), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:31.774372 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 43830), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:31.774631 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42560), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:31.774861 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55008), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:31.789606 (Thread-1): Writing injected SQL for node "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"
2020-11-18 15:37:31.807836 (Thread-1): finished collecting timing info
2020-11-18 15:37:31.808427 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:31.808954 (Thread-1): On test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"} */






with validation_errors as (

    select
        issue_id, updated_at
    from `abij-playground`.`github`.`issue_closed_history`

    group by issue_id, updated_at
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:37:32.155295 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"} */






with validation_errors as (

    select
        issue_id, updated_at
    from `abij-playground`.`github`.`issue_closed_history`

    group by issue_id, updated_at
    having count(*) > 1

)

select count(*)
from validation_errors



2020-11-18 15:37:32.155532 (Thread-1): finished collecting timing info
2020-11-18 15:37:32.156083 (Thread-1): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU
  
  (job ID: 5a8626c9-8936-49c8-b590-7a7a55af5eca)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU

(job ID: 5a8626c9-8936-49c8-b590-7a7a55af5eca)

                                                                                                   -----Query Job SQL Follows-----                                                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at"} */
   2:
   3:
   4:
   5:
   6:
   7:
   8:with validation_errors as (
   9:
  10:    select
  11:        issue_id, updated_at
  12:    from `abij-playground`.`github`.`issue_closed_history`
  13:
  14:    group by issue_id, updated_at
  15:    having count(*) > 1
  16:
  17:)
  18:
  19:select count(*)
  20:from validation_errors
  21:
  22:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU
  
  (job ID: 5a8626c9-8936-49c8-b590-7a7a55af5eca)
2020-11-18 15:37:32.157185 (Thread-1): 15:37:32 | 2 of 26 ERROR dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at [ERROR in 0.39s]
2020-11-18 15:37:32.157282 (Thread-1): Finished running node test.github_source.dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at
2020-11-18 15:37:32.157415 (Thread-1): Began running node test.github_source.not_null_github_daily_metrics_day
2020-11-18 15:37:32.157535 (Thread-1): 15:37:32 | 3 of 26 START test not_null_github_daily_metrics_day................. [RUN]
2020-11-18 15:37:32.157808 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_daily_metrics_day".
2020-11-18 15:37:32.157893 (Thread-1): Compiling test.github_source.not_null_github_daily_metrics_day
2020-11-18 15:37:32.167148 (Thread-1): Compiling model.github_source.github_daily_metrics
2020-11-18 15:37:32.193874 (Thread-1): Compiling model.github_source.github_issues
2020-11-18 15:37:32.208732 (Thread-1): Compiling model.github_source.github_issue_joined
2020-11-18 15:37:32.224589 (Thread-1): Compiling model.github_source.stg_github_issue
2020-11-18 15:37:32.233981 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue"
2020-11-18 15:37:32.261840 (Thread-1): Compiling model.github_source.github_issue_labels
2020-11-18 15:37:32.265717 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42596), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:32.265951 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55046), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:32.271557 (Thread-1): Compiling model.github_source.stg_github_issue_label
2020-11-18 15:37:32.280700 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_label"
2020-11-18 15:37:32.303043 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_labels"
2020-11-18 15:37:32.314988 (Thread-1): Compiling model.github_source.stg_github_repository
2020-11-18 15:37:32.324926 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_repository"
2020-11-18 15:37:32.343514 (Thread-1): Compiling model.github_source.github_issue_assignees
2020-11-18 15:37:32.352570 (Thread-1): Compiling model.github_source.stg_github_issue_assignee
2020-11-18 15:37:32.362185 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_assignee"
2020-11-18 15:37:32.380287 (Thread-1): Compiling model.github_source.stg_github_user
2020-11-18 15:37:32.389906 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_user"
2020-11-18 15:37:32.412381 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_assignees"
2020-11-18 15:37:32.425267 (Thread-1): Compiling model.github_source.github_issue_open_length
2020-11-18 15:37:32.435322 (Thread-1): Compiling model.github_source.stg_github_issue_closed_history
2020-11-18 15:37:32.444853 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_closed_history"
2020-11-18 15:37:32.475561 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_open_length"
2020-11-18 15:37:32.495829 (Thread-1): Compiling model.github_source.github_issue_comments
2020-11-18 15:37:32.506868 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_comments"
2020-11-18 15:37:32.526474 (Thread-1): Compiling model.github_source.github_pull_request_times
2020-11-18 15:37:32.541111 (Thread-1): Compiling model.github_source.stg_github_pull_request_review
2020-11-18 15:37:32.550620 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_pull_request_review"
2020-11-18 15:37:32.569261 (Thread-1): Compiling model.github_source.stg_github_pull_request
2020-11-18 15:37:32.579475 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_pull_request"
2020-11-18 15:37:32.596861 (Thread-1): Compiling model.github_source.stg_github_requested_reviewer_history
2020-11-18 15:37:32.606616 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_requested_reviewer_history"
2020-11-18 15:37:32.639565 (Thread-1): Compiling model.github_source.stg_github_issue_merged
2020-11-18 15:37:32.649592 (Thread-1): Writing injected SQL for node "model.github_source.stg_github_issue_merged"
2020-11-18 15:37:32.692183 (Thread-1): Writing injected SQL for node "model.github_source.github_pull_request_times"
2020-11-18 15:37:32.752648 (Thread-1): Compiling model.github_source.github_pull_request_reviewers
2020-11-18 15:37:32.769810 (Thread-1): Writing injected SQL for node "model.github_source.github_pull_request_reviewers"
2020-11-18 15:37:32.799932 (Thread-1): Writing injected SQL for node "model.github_source.github_issue_joined"
2020-11-18 15:37:32.850087 (Thread-1): Writing injected SQL for node "model.github_source.github_issues"
2020-11-18 15:37:32.894030 (Thread-96): handling poll request
2020-11-18 15:37:32.894723 (Thread-96): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc37a4e48>]}
2020-11-18 15:37:32.902028 (Thread-96): sending response (<Response 37046 bytes [200 OK]>) to 10.0.34.62
2020-11-18 15:37:32.958459 (Thread-1): Compiling model.github_source.github_pull_requests
2020-11-18 15:37:32.979621 (Thread-1): Writing injected SQL for node "model.github_source.github_pull_requests"
2020-11-18 15:37:33.134467 (Thread-1): Writing injected SQL for node "model.github_source.github_daily_metrics"
2020-11-18 15:37:33.228823 (Thread-1): Writing injected SQL for node "test.github_source.not_null_github_daily_metrics_day"
2020-11-18 15:37:33.335725 (Thread-1): finished collecting timing info
2020-11-18 15:37:33.336195 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:33.336708 (Thread-1): On test.github_source.not_null_github_daily_metrics_day: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_daily_metrics_day"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
)select count(*) as validation_errors
from __dbt__CTE__github_daily_metrics
where day is null



2020-11-18 15:37:33.700372 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_daily_metrics_day"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
)select count(*) as validation_errors
from __dbt__CTE__github_daily_metrics
where day is null



2020-11-18 15:37:33.700650 (Thread-1): finished collecting timing info
2020-11-18 15:37:33.701246 (Thread-1): Runtime Error in test not_null_github_daily_metrics_day (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 1a2862cc-0350-42d3-9632-621c6b2a54a5)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 1a2862cc-0350-42d3-9632-621c6b2a54a5)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_daily_metrics_day"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:)select count(*) as validation_errors
 686:from __dbt__CTE__github_daily_metrics
 687:where day is null
 688:
 689:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_github_daily_metrics_day (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 1a2862cc-0350-42d3-9632-621c6b2a54a5)
2020-11-18 15:37:33.702418 (Thread-1): 15:37:33 | 3 of 26 ERROR not_null_github_daily_metrics_day...................... [ERROR in 1.54s]
2020-11-18 15:37:33.702513 (Thread-1): Finished running node test.github_source.not_null_github_daily_metrics_day
2020-11-18 15:37:33.702653 (Thread-1): Began running node test.github_source.not_null_github_issues_issue_id
2020-11-18 15:37:33.702758 (Thread-1): 15:37:33 | 4 of 26 START test not_null_github_issues_issue_id................... [RUN]
2020-11-18 15:37:33.703010 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_issues_issue_id".
2020-11-18 15:37:33.703100 (Thread-1): Compiling test.github_source.not_null_github_issues_issue_id
2020-11-18 15:37:33.719330 (Thread-1): Writing injected SQL for node "test.github_source.not_null_github_issues_issue_id"
2020-11-18 15:37:33.785276 (Thread-1): finished collecting timing info
2020-11-18 15:37:33.785777 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:33.786334 (Thread-1): On test.github_source.not_null_github_issues_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_issues_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
)select count(*) as validation_errors
from __dbt__CTE__github_issues
where issue_id is null



2020-11-18 15:37:34.137189 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_issues_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
)select count(*) as validation_errors
from __dbt__CTE__github_issues
where issue_id is null



2020-11-18 15:37:34.137450 (Thread-1): finished collecting timing info
2020-11-18 15:37:34.138018 (Thread-1): Runtime Error in test not_null_github_issues_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 3d4915ac-b8f6-43ee-a2e7-87b6fe20ef47)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 3d4915ac-b8f6-43ee-a2e7-87b6fe20ef47)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_issues_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:)select count(*) as validation_errors
 539:from __dbt__CTE__github_issues
 540:where issue_id is null
 541:
 542:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_github_issues_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 3d4915ac-b8f6-43ee-a2e7-87b6fe20ef47)
2020-11-18 15:37:34.139143 (Thread-1): 15:37:34 | 4 of 26 ERROR not_null_github_issues_issue_id........................ [ERROR in 0.44s]
2020-11-18 15:37:34.139230 (Thread-1): Finished running node test.github_source.not_null_github_issues_issue_id
2020-11-18 15:37:34.139360 (Thread-1): Began running node test.github_source.not_null_github_monthly_metrics_month
2020-11-18 15:37:34.139458 (Thread-1): 15:37:34 | 5 of 26 START test not_null_github_monthly_metrics_month............. [RUN]
2020-11-18 15:37:34.139703 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_monthly_metrics_month".
2020-11-18 15:37:34.139786 (Thread-1): Compiling test.github_source.not_null_github_monthly_metrics_month
2020-11-18 15:37:34.149304 (Thread-1): Compiling model.github_source.github_monthly_metrics
2020-11-18 15:37:34.170921 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42832), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:34.171239 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 43934), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:34.171548 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42682), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:34.171754 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 43962), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:34.175550 (Thread-1): Writing injected SQL for node "model.github_source.github_monthly_metrics"
2020-11-18 15:37:34.186173 (Thread-97): handling poll request
2020-11-18 15:37:34.186642 (Thread-97): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3561e48>]}
2020-11-18 15:37:34.191355 (Thread-97): sending response (<Response 107208 bytes [200 OK]>) to 10.0.14.186
2020-11-18 15:37:34.251963 (Thread-1): Writing injected SQL for node "test.github_source.not_null_github_monthly_metrics_month"
2020-11-18 15:37:34.339647 (Thread-1): finished collecting timing info
2020-11-18 15:37:34.340257 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:34.340853 (Thread-1): On test.github_source.not_null_github_monthly_metrics_month: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_monthly_metrics_month"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_monthly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
    timestamp_trunc(
        cast(day as timestamp),
        month
    )

 as month, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from __dbt__CTE__github_monthly_metrics
where month is null



2020-11-18 15:37:34.680890 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_monthly_metrics_month"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_monthly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
    timestamp_trunc(
        cast(day as timestamp),
        month
    )

 as month, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from __dbt__CTE__github_monthly_metrics
where month is null



2020-11-18 15:37:34.681138 (Thread-1): finished collecting timing info
2020-11-18 15:37:34.681729 (Thread-1): Runtime Error in test not_null_github_monthly_metrics_month (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 9574fa17-6747-45c9-861d-73be1c42a348)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 9574fa17-6747-45c9-861d-73be1c42a348)

                                                                      -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_monthly_metrics_month"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:),  __dbt__CTE__github_monthly_metrics as (
 686:with daily_metrics as (
 687:
 688:    select *
 689:    from __dbt__CTE__github_daily_metrics
 690:
 691:)
 692:
 693:select 
 694:  
 695:    timestamp_trunc(
 696:        cast(day as timestamp),
 697:        month
 698:    )
 699:
 700: as month, 
 701:  sum(number_issues_opened) as number_issues_opened,
 702:  sum(number_issues_closed) as number_issues_closed,
 703:  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
 704:  max(longest_days_issue_open) as longest_days_issue_open,
 705:  sum(number_prs_opened) as number_prs_opened,
 706:  sum(number_prs_merged) as number_prs_merged,
 707:  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
 708:  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
 709:  max(longest_days_pr_open) as longest_days_pr_open
 710:
 711:from daily_metrics 
 712:group by 1
 713:order by 1 desc
 714:)select count(*) as validation_errors
 715:from __dbt__CTE__github_monthly_metrics
 716:where month is null
 717:
 718:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_github_monthly_metrics_month (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 9574fa17-6747-45c9-861d-73be1c42a348)
2020-11-18 15:37:34.682979 (Thread-1): 15:37:34 | 5 of 26 ERROR not_null_github_monthly_metrics_month.................. [ERROR in 0.54s]
2020-11-18 15:37:34.683065 (Thread-1): Finished running node test.github_source.not_null_github_monthly_metrics_month
2020-11-18 15:37:34.683196 (Thread-1): Began running node test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 15:37:34.683293 (Thread-1): 15:37:34 | 6 of 26 START test not_null_github_pull_requests_issue_id............ [RUN]
2020-11-18 15:37:34.683530 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_pull_requests_issue_id".
2020-11-18 15:37:34.683615 (Thread-1): Compiling test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 15:37:34.687198 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42694), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:34.687916 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55146), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:34.698183 (Thread-1): Writing injected SQL for node "test.github_source.not_null_github_pull_requests_issue_id"
2020-11-18 15:37:34.740405 (Thread-1): finished collecting timing info
2020-11-18 15:37:34.740868 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:34.741373 (Thread-1): On test.github_source.not_null_github_pull_requests_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_pull_requests_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
)select count(*) as validation_errors
from __dbt__CTE__github_pull_requests
where issue_id is null



2020-11-18 15:37:35.053445 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_pull_requests_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
)select count(*) as validation_errors
from __dbt__CTE__github_pull_requests
where issue_id is null



2020-11-18 15:37:35.053695 (Thread-1): finished collecting timing info
2020-11-18 15:37:35.054253 (Thread-1): Runtime Error in test not_null_github_pull_requests_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 018a30b8-71f1-4f0c-b680-ab8103c1f783)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 018a30b8-71f1-4f0c-b680-ab8103c1f783)

                                                                      -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_pull_requests_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_pull_requests as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  *
 514:from issue_joined
 515:where is_pull_request
 516:)select count(*) as validation_errors
 517:from __dbt__CTE__github_pull_requests
 518:where issue_id is null
 519:
 520:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_github_pull_requests_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 018a30b8-71f1-4f0c-b680-ab8103c1f783)
2020-11-18 15:37:35.055263 (Thread-1): 15:37:35 | 6 of 26 ERROR not_null_github_pull_requests_issue_id................. [ERROR in 0.37s]
2020-11-18 15:37:35.055349 (Thread-1): Finished running node test.github_source.not_null_github_pull_requests_issue_id
2020-11-18 15:37:35.055479 (Thread-1): Began running node test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 15:37:35.055576 (Thread-1): 15:37:35 | 7 of 26 START test not_null_github_quarterly_metrics_quarter......... [RUN]
2020-11-18 15:37:35.055796 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_quarterly_metrics_quarter".
2020-11-18 15:37:35.055878 (Thread-1): Compiling test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 15:37:35.065213 (Thread-1): Compiling model.github_source.github_quarterly_metrics
2020-11-18 15:37:35.088941 (Thread-1): Writing injected SQL for node "model.github_source.github_quarterly_metrics"
2020-11-18 15:37:35.154270 (Thread-1): Writing injected SQL for node "test.github_source.not_null_github_quarterly_metrics_quarter"
2020-11-18 15:37:35.244366 (Thread-1): finished collecting timing info
2020-11-18 15:37:35.244987 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:35.245604 (Thread-1): On test.github_source.not_null_github_quarterly_metrics_quarter: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_quarterly_metrics_quarter"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_quarterly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
  
    timestamp_trunc(
        cast(day as timestamp),
        quarter
    )

 as quarter, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from __dbt__CTE__github_quarterly_metrics
where quarter is null



2020-11-18 15:37:35.510176 (Thread-98): handling poll request
2020-11-18 15:37:35.510879 (Thread-98): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc81b74e0>]}
2020-11-18 15:37:35.518545 (Thread-98): sending response (<Response 125372 bytes [200 OK]>) to 10.0.34.62
2020-11-18 15:37:35.783932 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_quarterly_metrics_quarter"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_quarterly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
  
    timestamp_trunc(
        cast(day as timestamp),
        quarter
    )

 as quarter, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from __dbt__CTE__github_quarterly_metrics
where quarter is null



2020-11-18 15:37:35.784183 (Thread-1): finished collecting timing info
2020-11-18 15:37:35.784747 (Thread-1): Runtime Error in test not_null_github_quarterly_metrics_quarter (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: a9b500c9-7033-4bda-b817-66107701d0a7)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: a9b500c9-7033-4bda-b817-66107701d0a7)

                                                                        -----Query Job SQL Follows-----                                                                        

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_quarterly_metrics_quarter"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:),  __dbt__CTE__github_quarterly_metrics as (
 686:with daily_metrics as (
 687:
 688:    select *
 689:    from __dbt__CTE__github_daily_metrics
 690:
 691:)
 692:
 693:select 
 694:  
 695:  
 696:    timestamp_trunc(
 697:        cast(day as timestamp),
 698:        quarter
 699:    )
 700:
 701: as quarter, 
 702:  sum(number_issues_opened) as number_issues_opened,
 703:  sum(number_issues_closed) as number_issues_closed,
 704:  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
 705:  max(longest_days_issue_open) as longest_days_issue_open,
 706:  sum(number_prs_opened) as number_prs_opened,
 707:  sum(number_prs_merged) as number_prs_merged,
 708:  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
 709:  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
 710:  max(longest_days_pr_open) as longest_days_pr_open
 711:
 712:from daily_metrics 
 713:group by 1
 714:order by 1 desc
 715:)select count(*) as validation_errors
 716:from __dbt__CTE__github_quarterly_metrics
 717:where quarter is null
 718:
 719:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_github_quarterly_metrics_quarter (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: a9b500c9-7033-4bda-b817-66107701d0a7)
2020-11-18 15:37:35.785773 (Thread-1): 15:37:35 | 7 of 26 ERROR not_null_github_quarterly_metrics_quarter.............. [ERROR in 0.73s]
2020-11-18 15:37:35.785859 (Thread-1): Finished running node test.github_source.not_null_github_quarterly_metrics_quarter
2020-11-18 15:37:35.785989 (Thread-1): Began running node test.github_source.not_null_github_weekly_metrics_week
2020-11-18 15:37:35.786089 (Thread-1): 15:37:35 | 8 of 26 START test not_null_github_weekly_metrics_week............... [RUN]
2020-11-18 15:37:35.786315 (Thread-1): Acquiring new bigquery connection "test.github_source.not_null_github_weekly_metrics_week".
2020-11-18 15:37:35.786397 (Thread-1): Compiling test.github_source.not_null_github_weekly_metrics_week
2020-11-18 15:37:35.789803 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42924), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:35.790063 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44026), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:35.796427 (Thread-1): Compiling model.github_source.github_weekly_metrics
2020-11-18 15:37:35.819650 (Thread-1): Writing injected SQL for node "model.github_source.github_weekly_metrics"
2020-11-18 15:37:35.875094 (Thread-1): Writing injected SQL for node "test.github_source.not_null_github_weekly_metrics_week"
2020-11-18 15:37:35.928557 (Thread-1): finished collecting timing info
2020-11-18 15:37:35.929010 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:35.929479 (Thread-1): On test.github_source.not_null_github_weekly_metrics_week: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_weekly_metrics_week"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_weekly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 

  
    timestamp_trunc(
        cast(day as timestamp),
        week
    )

 as week, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from __dbt__CTE__github_weekly_metrics
where week is null



2020-11-18 15:37:35.935100 (Thread-1): unclosed <socket.socket fd=6, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42728), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:35.935362 (Thread-1): unclosed <socket.socket fd=7, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55176), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:36.337306 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_weekly_metrics_week"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_weekly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 

  
    timestamp_trunc(
        cast(day as timestamp),
        week
    )

 as week, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from __dbt__CTE__github_weekly_metrics
where week is null



2020-11-18 15:37:36.337565 (Thread-1): finished collecting timing info
2020-11-18 15:37:36.338136 (Thread-1): Runtime Error in test not_null_github_weekly_metrics_week (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: fbd4c369-78eb-4b78-a0d5-efa577de82ac)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: fbd4c369-78eb-4b78-a0d5-efa577de82ac)

                                                                     -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.not_null_github_weekly_metrics_week"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:),  __dbt__CTE__github_weekly_metrics as (
 686:with daily_metrics as (
 687:
 688:    select *
 689:    from __dbt__CTE__github_daily_metrics
 690:
 691:)
 692:
 693:select 
 694:
 695:  
 696:    timestamp_trunc(
 697:        cast(day as timestamp),
 698:        week
 699:    )
 700:
 701: as week, 
 702:  sum(number_issues_opened) as number_issues_opened,
 703:  sum(number_issues_closed) as number_issues_closed,
 704:  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
 705:  max(longest_days_issue_open) as longest_days_issue_open,
 706:  sum(number_prs_opened) as number_prs_opened,
 707:  sum(number_prs_merged) as number_prs_merged,
 708:  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
 709:  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
 710:  max(longest_days_pr_open) as longest_days_pr_open
 711:
 712:from daily_metrics 
 713:group by 1
 714:order by 1 desc
 715:)select count(*) as validation_errors
 716:from __dbt__CTE__github_weekly_metrics
 717:where week is null
 718:
 719:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test not_null_github_weekly_metrics_week (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: fbd4c369-78eb-4b78-a0d5-efa577de82ac)
2020-11-18 15:37:36.339129 (Thread-1): 15:37:36 | 8 of 26 ERROR not_null_github_weekly_metrics_week.................... [ERROR in 0.55s]
2020-11-18 15:37:36.339214 (Thread-1): Finished running node test.github_source.not_null_github_weekly_metrics_week
2020-11-18 15:37:36.339348 (Thread-1): Began running node test.github_source.source_not_null_github_issue_comment_id
2020-11-18 15:37:36.339447 (Thread-1): 15:37:36 | 9 of 26 START test source_not_null_github_issue_comment_id........... [RUN]
2020-11-18 15:37:36.339672 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_issue_comment_id".
2020-11-18 15:37:36.339753 (Thread-1): Compiling test.github_source.source_not_null_github_issue_comment_id
2020-11-18 15:37:36.350916 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_issue_comment_id"
2020-11-18 15:37:36.370961 (Thread-1): finished collecting timing info
2020-11-18 15:37:36.371405 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:36.371810 (Thread-1): On test.github_source.source_not_null_github_issue_comment_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue_comment`
where id is null



2020-11-18 15:37:36.642910 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue_comment`
where id is null



2020-11-18 15:37:36.643150 (Thread-1): finished collecting timing info
2020-11-18 15:37:36.643729 (Thread-1): Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: d3ef5b9e-3b59-4992-a70f-962a032c4c51)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_comment was not found in location EU

(job ID: d3ef5b9e-3b59-4992-a70f-962a032c4c51)

                                                                       -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_comment_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`issue_comment`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: d3ef5b9e-3b59-4992-a70f-962a032c4c51)
2020-11-18 15:37:36.644729 (Thread-1): 15:37:36 | 9 of 26 ERROR source_not_null_github_issue_comment_id................ [ERROR in 0.31s]
2020-11-18 15:37:36.644813 (Thread-1): Finished running node test.github_source.source_not_null_github_issue_comment_id
2020-11-18 15:37:36.644945 (Thread-1): Began running node test.github_source.source_not_null_github_issue_id
2020-11-18 15:37:36.645044 (Thread-1): 15:37:36 | 10 of 26 START test source_not_null_github_issue_id.................. [RUN]
2020-11-18 15:37:36.645302 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_issue_id".
2020-11-18 15:37:36.645391 (Thread-1): Compiling test.github_source.source_not_null_github_issue_id
2020-11-18 15:37:36.648998 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42780), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:36.649330 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44058), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:36.658418 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_issue_id"
2020-11-18 15:37:36.675869 (Thread-1): finished collecting timing info
2020-11-18 15:37:36.676282 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:36.676799 (Thread-1): On test.github_source.source_not_null_github_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue`
where id is null



2020-11-18 15:37:36.836361 (Thread-99): handling poll request
2020-11-18 15:37:36.836853 (Thread-99): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8220240>]}
2020-11-18 15:37:36.842857 (Thread-99): sending response (<Response 118354 bytes [200 OK]>) to 10.0.14.29
2020-11-18 15:37:36.946897 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`issue`
where id is null



2020-11-18 15:37:36.947139 (Thread-1): finished collecting timing info
2020-11-18 15:37:36.947709 (Thread-1): Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: 4766ea95-a2fb-4243-92e9-18554d956325)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue was not found in location EU

(job ID: 4766ea95-a2fb-4243-92e9-18554d956325)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`issue`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: 4766ea95-a2fb-4243-92e9-18554d956325)
2020-11-18 15:37:36.948848 (Thread-1): 15:37:36 | 10 of 26 ERROR source_not_null_github_issue_id....................... [ERROR in 0.30s]
2020-11-18 15:37:36.948966 (Thread-1): Finished running node test.github_source.source_not_null_github_issue_id
2020-11-18 15:37:36.949135 (Thread-1): Began running node test.github_source.source_not_null_github_pull_request_id
2020-11-18 15:37:36.949315 (Thread-1): 15:37:36 | 11 of 26 START test source_not_null_github_pull_request_id........... [RUN]
2020-11-18 15:37:36.949659 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_pull_request_id".
2020-11-18 15:37:36.949753 (Thread-1): Compiling test.github_source.source_not_null_github_pull_request_id
2020-11-18 15:37:36.960703 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_pull_request_id"
2020-11-18 15:37:36.979731 (Thread-1): finished collecting timing info
2020-11-18 15:37:36.980177 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:36.980678 (Thread-1): On test.github_source.source_not_null_github_pull_request_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request`
where id is null



2020-11-18 15:37:37.267522 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request`
where id is null



2020-11-18 15:37:37.267766 (Thread-1): finished collecting timing info
2020-11-18 15:37:37.268345 (Thread-1): Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: 9236135f-6831-4fc4-863a-6b6787a155b9)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request was not found in location EU

(job ID: 9236135f-6831-4fc4-863a-6b6787a155b9)

                                                                      -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`pull_request`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: 9236135f-6831-4fc4-863a-6b6787a155b9)
2020-11-18 15:37:37.269378 (Thread-1): 15:37:37 | 11 of 26 ERROR source_not_null_github_pull_request_id................ [ERROR in 0.32s]
2020-11-18 15:37:37.269464 (Thread-1): Finished running node test.github_source.source_not_null_github_pull_request_id
2020-11-18 15:37:37.269592 (Thread-1): Began running node test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 15:37:37.269689 (Thread-1): 15:37:37 | 12 of 26 START test source_not_null_github_pull_request_review_id.... [RUN]
2020-11-18 15:37:37.269929 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_pull_request_review_id".
2020-11-18 15:37:37.270014 (Thread-1): Compiling test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 15:37:37.281199 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_pull_request_review_id"
2020-11-18 15:37:37.298371 (Thread-1): finished collecting timing info
2020-11-18 15:37:37.298788 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:37.299234 (Thread-1): On test.github_source.source_not_null_github_pull_request_review_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request_review`
where id is null



2020-11-18 15:37:37.594200 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`pull_request_review`
where id is null



2020-11-18 15:37:37.594443 (Thread-1): finished collecting timing info
2020-11-18 15:37:37.595017 (Thread-1): Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: a6ba08ff-dae1-4237-9eb0-7f3b0c069f58)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request_review was not found in location EU

(job ID: a6ba08ff-dae1-4237-9eb0-7f3b0c069f58)

                                                                          -----Query Job SQL Follows-----                                                                          

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_pull_request_review_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from `abij-playground`.`github`.`pull_request_review`
  10:where id is null
  11:
  12:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: a6ba08ff-dae1-4237-9eb0-7f3b0c069f58)
2020-11-18 15:37:37.596069 (Thread-1): 15:37:37 | 12 of 26 ERROR source_not_null_github_pull_request_review_id......... [ERROR in 0.33s]
2020-11-18 15:37:37.596161 (Thread-1): Finished running node test.github_source.source_not_null_github_pull_request_review_id
2020-11-18 15:37:37.596297 (Thread-1): Began running node test.github_source.source_not_null_github_repository_id
2020-11-18 15:37:37.596396 (Thread-1): 15:37:37 | 13 of 26 START test source_not_null_github_repository_id............. [RUN]
2020-11-18 15:37:37.596662 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_repository_id".
2020-11-18 15:37:37.596751 (Thread-1): Compiling test.github_source.source_not_null_github_repository_id
2020-11-18 15:37:37.608141 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_repository_id"
2020-11-18 15:37:37.626883 (Thread-1): finished collecting timing info
2020-11-18 15:37:37.627351 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:37.627833 (Thread-1): On test.github_source.source_not_null_github_repository_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_repository_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`repository`
where id is null



2020-11-18 15:37:38.129036 (Thread-100): handling poll request
2020-11-18 15:37:38.129584 (Thread-100): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3590f98>]}
2020-11-18 15:37:38.134852 (Thread-100): sending response (<Response 33334 bytes [200 OK]>) to 10.0.30.126
2020-11-18 15:37:39.104031 (Thread-1): finished collecting timing info
2020-11-18 15:37:39.104741 (Thread-1): 15:37:39 | 13 of 26 PASS source_not_null_github_repository_id................... [PASS in 1.51s]
2020-11-18 15:37:39.104848 (Thread-1): Finished running node test.github_source.source_not_null_github_repository_id
2020-11-18 15:37:39.104975 (Thread-1): Began running node test.github_source.source_not_null_github_user_id
2020-11-18 15:37:39.105074 (Thread-1): 15:37:39 | 14 of 26 START test source_not_null_github_user_id................... [RUN]
2020-11-18 15:37:39.105355 (Thread-1): Acquiring new bigquery connection "test.github_source.source_not_null_github_user_id".
2020-11-18 15:37:39.105445 (Thread-1): Compiling test.github_source.source_not_null_github_user_id
2020-11-18 15:37:39.111579 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42974), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:39.111838 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55246), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:39.112050 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42804), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:39.112225 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55252), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:39.112404 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 42994), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:39.112560 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44096), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:39.112732 (Thread-1): unclosed <socket.socket fd=15, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43008), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:39.112880 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55284), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:39.121271 (Thread-1): Writing injected SQL for node "test.github_source.source_not_null_github_user_id"
2020-11-18 15:37:39.180859 (Thread-1): finished collecting timing info
2020-11-18 15:37:39.181360 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:39.181833 (Thread-1): On test.github_source.source_not_null_github_user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_not_null_github_user_id"} */

    
    



select count(*) as validation_errors
from `abij-playground`.`github`.`user`
where id is null



2020-11-18 15:37:39.426464 (Thread-101): handling poll request
2020-11-18 15:37:39.426979 (Thread-101): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc342edd8>]}
2020-11-18 15:37:39.429244 (Thread-101): sending response (<Response 5371 bytes [200 OK]>) to 10.0.37.56
2020-11-18 15:37:40.646938 (Thread-1): finished collecting timing info
2020-11-18 15:37:40.647608 (Thread-1): 15:37:40 | 14 of 26 PASS source_not_null_github_user_id......................... [PASS in 1.54s]
2020-11-18 15:37:40.647709 (Thread-1): Finished running node test.github_source.source_not_null_github_user_id
2020-11-18 15:37:40.647835 (Thread-1): Began running node test.github_source.source_unique_github_issue_comment_id
2020-11-18 15:37:40.647937 (Thread-1): 15:37:40 | 15 of 26 START test source_unique_github_issue_comment_id............ [RUN]
2020-11-18 15:37:40.648153 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_issue_comment_id".
2020-11-18 15:37:40.648234 (Thread-1): Compiling test.github_source.source_unique_github_issue_comment_id
2020-11-18 15:37:40.651839 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43068), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:40.652472 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44170), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:40.661250 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_issue_comment_id"
2020-11-18 15:37:40.679118 (Thread-1): finished collecting timing info
2020-11-18 15:37:40.679564 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:40.680003 (Thread-1): On test.github_source.source_unique_github_issue_comment_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue_comment`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:40.700586 (Thread-102): handling poll request
2020-11-18 15:37:40.701215 (Thread-102): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc830c6d8>]}
2020-11-18 15:37:40.703411 (Thread-102): sending response (<Response 5590 bytes [200 OK]>) to 10.0.21.190
2020-11-18 15:37:40.958023 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue_comment`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:40.958269 (Thread-1): finished collecting timing info
2020-11-18 15:37:40.958834 (Thread-1): Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: c0b15e2b-3893-4a15-94a4-23919e8654c7)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue_comment was not found in location EU

(job ID: c0b15e2b-3893-4a15-94a4-23919e8654c7)

                                                                      -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_comment_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`issue_comment`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue_comment was not found in location EU
  
  (job ID: c0b15e2b-3893-4a15-94a4-23919e8654c7)
2020-11-18 15:37:40.960017 (Thread-1): 15:37:40 | 15 of 26 ERROR source_unique_github_issue_comment_id................. [ERROR in 0.31s]
2020-11-18 15:37:40.960112 (Thread-1): Finished running node test.github_source.source_unique_github_issue_comment_id
2020-11-18 15:37:40.960246 (Thread-1): Began running node test.github_source.source_unique_github_issue_id
2020-11-18 15:37:40.960347 (Thread-1): 15:37:40 | 16 of 26 START test source_unique_github_issue_id.................... [RUN]
2020-11-18 15:37:40.960624 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_issue_id".
2020-11-18 15:37:40.960711 (Thread-1): Compiling test.github_source.source_unique_github_issue_id
2020-11-18 15:37:40.961570 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43114), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:40.961817 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55388), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:40.973440 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_issue_id"
2020-11-18 15:37:41.012705 (Thread-1): finished collecting timing info
2020-11-18 15:37:41.013177 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:41.013677 (Thread-1): On test.github_source.source_unique_github_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:41.287576 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`issue`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:41.287819 (Thread-1): finished collecting timing info
2020-11-18 15:37:41.288395 (Thread-1): Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: df44453a-c91f-4718-aa8f-f7922f4b6cb7)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.issue was not found in location EU

(job ID: df44453a-c91f-4718-aa8f-f7922f4b6cb7)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`issue`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.issue was not found in location EU
  
  (job ID: df44453a-c91f-4718-aa8f-f7922f4b6cb7)
2020-11-18 15:37:41.289546 (Thread-1): 15:37:41 | 16 of 26 ERROR source_unique_github_issue_id......................... [ERROR in 0.33s]
2020-11-18 15:37:41.289642 (Thread-1): Finished running node test.github_source.source_unique_github_issue_id
2020-11-18 15:37:41.289785 (Thread-1): Began running node test.github_source.source_unique_github_pull_request_id
2020-11-18 15:37:41.289893 (Thread-1): 15:37:41 | 17 of 26 START test source_unique_github_pull_request_id............. [RUN]
2020-11-18 15:37:41.290179 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_pull_request_id".
2020-11-18 15:37:41.290267 (Thread-1): Compiling test.github_source.source_unique_github_pull_request_id
2020-11-18 15:37:41.303242 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_pull_request_id"
2020-11-18 15:37:41.323851 (Thread-1): finished collecting timing info
2020-11-18 15:37:41.324286 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:41.324757 (Thread-1): On test.github_source.source_unique_github_pull_request_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:41.613736 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:41.613979 (Thread-1): finished collecting timing info
2020-11-18 15:37:41.614556 (Thread-1): Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: c1b94923-4436-4010-8b5c-528ea3389867)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request was not found in location EU

(job ID: c1b94923-4436-4010-8b5c-528ea3389867)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`pull_request`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request was not found in location EU
  
  (job ID: c1b94923-4436-4010-8b5c-528ea3389867)
2020-11-18 15:37:41.615543 (Thread-1): 15:37:41 | 17 of 26 ERROR source_unique_github_pull_request_id.................. [ERROR in 0.33s]
2020-11-18 15:37:41.615632 (Thread-1): Finished running node test.github_source.source_unique_github_pull_request_id
2020-11-18 15:37:41.615764 (Thread-1): Began running node test.github_source.source_unique_github_pull_request_review_id
2020-11-18 15:37:41.615903 (Thread-1): 15:37:41 | 18 of 26 START test source_unique_github_pull_request_review_id...... [RUN]
2020-11-18 15:37:41.616288 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_pull_request_review_id".
2020-11-18 15:37:41.616425 (Thread-1): Compiling test.github_source.source_unique_github_pull_request_review_id
2020-11-18 15:37:41.629015 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_pull_request_review_id"
2020-11-18 15:37:41.646260 (Thread-1): finished collecting timing info
2020-11-18 15:37:41.646782 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:41.647306 (Thread-1): On test.github_source.source_unique_github_pull_request_review_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request_review`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:41.952931 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`pull_request_review`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:41.953212 (Thread-1): finished collecting timing info
2020-11-18 15:37:41.953793 (Thread-1): Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: f5fdee4a-8dc5-4749-9d36-10ed88019742)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.pull_request_review was not found in location EU

(job ID: f5fdee4a-8dc5-4749-9d36-10ed88019742)

                                                                         -----Query Job SQL Follows-----                                                                         

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_pull_request_review_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:select count(*) as validation_errors
   9:from (
  10:
  11:    select
  12:        id
  13:
  14:    from `abij-playground`.`github`.`pull_request_review`
  15:    where id is not null
  16:    group by id
  17:    having count(*) > 1
  18:
  19:) validation_errors
  20:
  21:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
  404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
  
  (job ID: f5fdee4a-8dc5-4749-9d36-10ed88019742)
2020-11-18 15:37:41.954818 (Thread-1): 15:37:41 | 18 of 26 ERROR source_unique_github_pull_request_review_id........... [ERROR in 0.34s]
2020-11-18 15:37:41.954903 (Thread-1): Finished running node test.github_source.source_unique_github_pull_request_review_id
2020-11-18 15:37:41.955039 (Thread-1): Began running node test.github_source.source_unique_github_repository_id
2020-11-18 15:37:41.955149 (Thread-1): 15:37:41 | 19 of 26 START test source_unique_github_repository_id............... [RUN]
2020-11-18 15:37:41.955396 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_repository_id".
2020-11-18 15:37:41.955480 (Thread-1): Compiling test.github_source.source_unique_github_repository_id
2020-11-18 15:37:41.966571 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_repository_id"
2020-11-18 15:37:41.983847 (Thread-1): finished collecting timing info
2020-11-18 15:37:41.984371 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:41.984834 (Thread-1): On test.github_source.source_unique_github_repository_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_repository_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`repository`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:41.997405 (Thread-1): unclosed <socket.socket fd=9, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43124), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:41.997756 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55398), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:41.997945 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43166), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:41.998104 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44268), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:41.998255 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43178), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:41.998420 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44280), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:42.125926 (Thread-103): handling poll request
2020-11-18 15:37:42.126450 (Thread-103): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2e2ef98>]}
2020-11-18 15:37:42.133393 (Thread-103): sending response (<Response 45497 bytes [200 OK]>) to 10.0.34.241
2020-11-18 15:37:43.328963 (Thread-1): finished collecting timing info
2020-11-18 15:37:43.329675 (Thread-1): 15:37:43 | 19 of 26 PASS source_unique_github_repository_id..................... [PASS in 1.37s]
2020-11-18 15:37:43.329779 (Thread-1): Finished running node test.github_source.source_unique_github_repository_id
2020-11-18 15:37:43.329906 (Thread-1): Began running node test.github_source.source_unique_github_user_id
2020-11-18 15:37:43.330003 (Thread-1): 15:37:43 | 20 of 26 START test source_unique_github_user_id..................... [RUN]
2020-11-18 15:37:43.330211 (Thread-1): Acquiring new bigquery connection "test.github_source.source_unique_github_user_id".
2020-11-18 15:37:43.330294 (Thread-1): Compiling test.github_source.source_unique_github_user_id
2020-11-18 15:37:43.342449 (Thread-1): Writing injected SQL for node "test.github_source.source_unique_github_user_id"
2020-11-18 15:37:43.380458 (Thread-1): finished collecting timing info
2020-11-18 15:37:43.380938 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:43.381451 (Thread-1): On test.github_source.source_unique_github_user_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.source_unique_github_user_id"} */

    
    



select count(*) as validation_errors
from (

    select
        id

    from `abij-playground`.`github`.`user`
    where id is not null
    group by id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:43.407197 (Thread-104): handling poll request
2020-11-18 15:37:43.407792 (Thread-104): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc342ed68>]}
2020-11-18 15:37:43.410097 (Thread-104): sending response (<Response 5444 bytes [200 OK]>) to 10.0.14.186
2020-11-18 15:37:44.703071 (Thread-105): handling poll request
2020-11-18 15:37:44.703569 (Thread-105): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2e2efd0>]}
2020-11-18 15:37:44.704567 (Thread-105): sending response (<Response 289 bytes [200 OK]>) to 10.0.5.154
2020-11-18 15:37:45.245460 (Thread-1): finished collecting timing info
2020-11-18 15:37:45.246403 (Thread-1): 15:37:45 | 20 of 26 PASS source_unique_github_user_id........................... [PASS in 1.92s]
2020-11-18 15:37:45.246557 (Thread-1): Finished running node test.github_source.source_unique_github_user_id
2020-11-18 15:37:45.246741 (Thread-1): Began running node test.github_source.unique_github_daily_metrics_day
2020-11-18 15:37:45.246891 (Thread-1): 15:37:45 | 21 of 26 START test unique_github_daily_metrics_day.................. [RUN]
2020-11-18 15:37:45.247235 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_daily_metrics_day".
2020-11-18 15:37:45.247364 (Thread-1): Compiling test.github_source.unique_github_daily_metrics_day
2020-11-18 15:37:45.248755 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43272), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:45.249056 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55546), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:45.272730 (Thread-1): Writing injected SQL for node "test.github_source.unique_github_daily_metrics_day"
2020-11-18 15:37:45.470756 (Thread-1): finished collecting timing info
2020-11-18 15:37:45.471218 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:45.471743 (Thread-1): On test.github_source.unique_github_daily_metrics_day: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_daily_metrics_day"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
)select count(*) as validation_errors
from (

    select
        day

    from __dbt__CTE__github_daily_metrics
    where day is not null
    group by day
    having count(*) > 1

) validation_errors



2020-11-18 15:37:45.922420 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_daily_metrics_day"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
)select count(*) as validation_errors
from (

    select
        day

    from __dbt__CTE__github_daily_metrics
    where day is not null
    group by day
    having count(*) > 1

) validation_errors



2020-11-18 15:37:45.922761 (Thread-1): finished collecting timing info
2020-11-18 15:37:45.923533 (Thread-1): Runtime Error in test unique_github_daily_metrics_day (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 3b1a7505-8b74-45a7-acab-b0b74439d53a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 3b1a7505-8b74-45a7-acab-b0b74439d53a)

                                                                   -----Query Job SQL Follows-----                                                                   

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_daily_metrics_day"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:)select count(*) as validation_errors
 686:from (
 687:
 688:    select
 689:        day
 690:
 691:    from __dbt__CTE__github_daily_metrics
 692:    where day is not null
 693:    group by day
 694:    having count(*) > 1
 695:
 696:) validation_errors
 697:
 698:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_github_daily_metrics_day (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 3b1a7505-8b74-45a7-acab-b0b74439d53a)
2020-11-18 15:37:45.924728 (Thread-1): 15:37:45 | 21 of 26 ERROR unique_github_daily_metrics_day....................... [ERROR in 0.68s]
2020-11-18 15:37:45.924846 (Thread-1): Finished running node test.github_source.unique_github_daily_metrics_day
2020-11-18 15:37:45.925022 (Thread-1): Began running node test.github_source.unique_github_issues_issue_id
2020-11-18 15:37:45.925180 (Thread-1): 15:37:45 | 22 of 26 START test unique_github_issues_issue_id.................... [RUN]
2020-11-18 15:37:45.925529 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_issues_issue_id".
2020-11-18 15:37:45.925648 (Thread-1): Compiling test.github_source.unique_github_issues_issue_id
2020-11-18 15:37:45.947619 (Thread-1): Writing injected SQL for node "test.github_source.unique_github_issues_issue_id"
2020-11-18 15:37:45.973684 (Thread-106): handling poll request
2020-11-18 15:37:45.974168 (Thread-106): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2e32d68>]}
2020-11-18 15:37:45.977694 (Thread-106): sending response (<Response 62327 bytes [200 OK]>) to 10.0.18.40
2020-11-18 15:37:46.066328 (Thread-1): finished collecting timing info
2020-11-18 15:37:46.066777 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:46.067246 (Thread-1): On test.github_source.unique_github_issues_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_issues_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
)select count(*) as validation_errors
from (

    select
        issue_id

    from __dbt__CTE__github_issues
    where issue_id is not null
    group by issue_id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:46.375200 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_issues_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
)select count(*) as validation_errors
from (

    select
        issue_id

    from __dbt__CTE__github_issues
    where issue_id is not null
    group by issue_id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:46.375474 (Thread-1): finished collecting timing info
2020-11-18 15:37:46.376056 (Thread-1): Runtime Error in test unique_github_issues_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 3f8131ee-756a-4309-b3bb-a171587c3d2a)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 3f8131ee-756a-4309-b3bb-a171587c3d2a)

                                                                  -----Query Job SQL Follows-----                                                                  

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_issues_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:)select count(*) as validation_errors
 539:from (
 540:
 541:    select
 542:        issue_id
 543:
 544:    from __dbt__CTE__github_issues
 545:    where issue_id is not null
 546:    group by issue_id
 547:    having count(*) > 1
 548:
 549:) validation_errors
 550:
 551:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_github_issues_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 3f8131ee-756a-4309-b3bb-a171587c3d2a)
2020-11-18 15:37:46.377182 (Thread-1): 15:37:46 | 22 of 26 ERROR unique_github_issues_issue_id......................... [ERROR in 0.45s]
2020-11-18 15:37:46.377279 (Thread-1): Finished running node test.github_source.unique_github_issues_issue_id
2020-11-18 15:37:46.377412 (Thread-1): Began running node test.github_source.unique_github_monthly_metrics_month
2020-11-18 15:37:46.377521 (Thread-1): 15:37:46 | 23 of 26 START test unique_github_monthly_metrics_month.............. [RUN]
2020-11-18 15:37:46.377780 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_monthly_metrics_month".
2020-11-18 15:37:46.377865 (Thread-1): Compiling test.github_source.unique_github_monthly_metrics_month
2020-11-18 15:37:46.393113 (Thread-1): Writing injected SQL for node "test.github_source.unique_github_monthly_metrics_month"
2020-11-18 15:37:46.545826 (Thread-1): finished collecting timing info
2020-11-18 15:37:46.546278 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:46.546797 (Thread-1): On test.github_source.unique_github_monthly_metrics_month: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_monthly_metrics_month"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_monthly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
    timestamp_trunc(
        cast(day as timestamp),
        month
    )

 as month, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from (

    select
        month

    from __dbt__CTE__github_monthly_metrics
    where month is not null
    group by month
    having count(*) > 1

) validation_errors



2020-11-18 15:37:46.894950 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_monthly_metrics_month"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_monthly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
    timestamp_trunc(
        cast(day as timestamp),
        month
    )

 as month, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from (

    select
        month

    from __dbt__CTE__github_monthly_metrics
    where month is not null
    group by month
    having count(*) > 1

) validation_errors



2020-11-18 15:37:46.895218 (Thread-1): finished collecting timing info
2020-11-18 15:37:46.895809 (Thread-1): Runtime Error in test unique_github_monthly_metrics_month (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 62f1d341-adc1-4882-be23-e5bdf27e94f5)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 62f1d341-adc1-4882-be23-e5bdf27e94f5)

                                                                     -----Query Job SQL Follows-----                                                                     

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_monthly_metrics_month"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:),  __dbt__CTE__github_monthly_metrics as (
 686:with daily_metrics as (
 687:
 688:    select *
 689:    from __dbt__CTE__github_daily_metrics
 690:
 691:)
 692:
 693:select 
 694:  
 695:    timestamp_trunc(
 696:        cast(day as timestamp),
 697:        month
 698:    )
 699:
 700: as month, 
 701:  sum(number_issues_opened) as number_issues_opened,
 702:  sum(number_issues_closed) as number_issues_closed,
 703:  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
 704:  max(longest_days_issue_open) as longest_days_issue_open,
 705:  sum(number_prs_opened) as number_prs_opened,
 706:  sum(number_prs_merged) as number_prs_merged,
 707:  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
 708:  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
 709:  max(longest_days_pr_open) as longest_days_pr_open
 710:
 711:from daily_metrics 
 712:group by 1
 713:order by 1 desc
 714:)select count(*) as validation_errors
 715:from (
 716:
 717:    select
 718:        month
 719:
 720:    from __dbt__CTE__github_monthly_metrics
 721:    where month is not null
 722:    group by month
 723:    having count(*) > 1
 724:
 725:) validation_errors
 726:
 727:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_github_monthly_metrics_month (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 62f1d341-adc1-4882-be23-e5bdf27e94f5)
2020-11-18 15:37:46.896971 (Thread-1): 15:37:46 | 23 of 26 ERROR unique_github_monthly_metrics_month................... [ERROR in 0.52s]
2020-11-18 15:37:46.897063 (Thread-1): Finished running node test.github_source.unique_github_monthly_metrics_month
2020-11-18 15:37:46.897227 (Thread-1): Began running node test.github_source.unique_github_pull_requests_issue_id
2020-11-18 15:37:46.897333 (Thread-1): 15:37:46 | 24 of 26 START test unique_github_pull_requests_issue_id............. [RUN]
2020-11-18 15:37:46.897582 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_pull_requests_issue_id".
2020-11-18 15:37:46.897668 (Thread-1): Compiling test.github_source.unique_github_pull_requests_issue_id
2020-11-18 15:37:46.901438 (Thread-1): unclosed <socket.socket fd=14, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43216), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:46.901697 (Thread-1): unclosed <socket.socket fd=16, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44496), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:46.914600 (Thread-1): Writing injected SQL for node "test.github_source.unique_github_pull_requests_issue_id"
2020-11-18 15:37:47.010257 (Thread-1): finished collecting timing info
2020-11-18 15:37:47.010731 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:47.011269 (Thread-1): On test.github_source.unique_github_pull_requests_issue_id: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_pull_requests_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
)select count(*) as validation_errors
from (

    select
        issue_id

    from __dbt__CTE__github_pull_requests
    where issue_id is not null
    group by issue_id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:47.031582 (Thread-1): unclosed <socket.socket fd=10, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43354), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:47.031943 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44458), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:47.032226 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43200), raddr=('172.217.7.138', 443)>
2020-11-18 15:37:47.032450 (Thread-1): unclosed <socket.socket fd=13, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 55648), raddr=('142.250.73.234', 443)>
2020-11-18 15:37:47.274979 (Thread-107): handling poll request
2020-11-18 15:37:47.275500 (Thread-107): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc34b8da0>]}
2020-11-18 15:37:47.280062 (Thread-107): sending response (<Response 121336 bytes [200 OK]>) to 10.0.41.79
2020-11-18 15:37:47.324426 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_pull_requests_issue_id"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
)select count(*) as validation_errors
from (

    select
        issue_id

    from __dbt__CTE__github_pull_requests
    where issue_id is not null
    group by issue_id
    having count(*) > 1

) validation_errors



2020-11-18 15:37:47.324679 (Thread-1): finished collecting timing info
2020-11-18 15:37:47.325316 (Thread-1): Runtime Error in test unique_github_pull_requests_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 01e35d92-ba90-4882-a382-79b22d3d4174)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 01e35d92-ba90-4882-a382-79b22d3d4174)

                                                                     -----Query Job SQL Follows-----                                                                      

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_pull_requests_issue_id"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_pull_requests as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  *
 514:from issue_joined
 515:where is_pull_request
 516:)select count(*) as validation_errors
 517:from (
 518:
 519:    select
 520:        issue_id
 521:
 522:    from __dbt__CTE__github_pull_requests
 523:    where issue_id is not null
 524:    group by issue_id
 525:    having count(*) > 1
 526:
 527:) validation_errors
 528:
 529:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_github_pull_requests_issue_id (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 01e35d92-ba90-4882-a382-79b22d3d4174)
2020-11-18 15:37:47.326499 (Thread-1): 15:37:47 | 24 of 26 ERROR unique_github_pull_requests_issue_id.................. [ERROR in 0.43s]
2020-11-18 15:37:47.326588 (Thread-1): Finished running node test.github_source.unique_github_pull_requests_issue_id
2020-11-18 15:37:47.326715 (Thread-1): Began running node test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 15:37:47.326812 (Thread-1): 15:37:47 | 25 of 26 START test unique_github_quarterly_metrics_quarter.......... [RUN]
2020-11-18 15:37:47.327057 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_quarterly_metrics_quarter".
2020-11-18 15:37:47.327143 (Thread-1): Compiling test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 15:37:47.341937 (Thread-1): Writing injected SQL for node "test.github_source.unique_github_quarterly_metrics_quarter"
2020-11-18 15:37:47.431498 (Thread-1): finished collecting timing info
2020-11-18 15:37:47.431968 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:47.432445 (Thread-1): On test.github_source.unique_github_quarterly_metrics_quarter: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_quarterly_metrics_quarter"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_quarterly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
  
    timestamp_trunc(
        cast(day as timestamp),
        quarter
    )

 as quarter, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from (

    select
        quarter

    from __dbt__CTE__github_quarterly_metrics
    where quarter is not null
    group by quarter
    having count(*) > 1

) validation_errors



2020-11-18 15:37:48.153667 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_quarterly_metrics_quarter"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_quarterly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 
  
  
    timestamp_trunc(
        cast(day as timestamp),
        quarter
    )

 as quarter, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from (

    select
        quarter

    from __dbt__CTE__github_quarterly_metrics
    where quarter is not null
    group by quarter
    having count(*) > 1

) validation_errors



2020-11-18 15:37:48.154008 (Thread-1): finished collecting timing info
2020-11-18 15:37:48.154819 (Thread-1): Runtime Error in test unique_github_quarterly_metrics_quarter (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 85ac383f-9fc6-4876-9b54-d91f51fadc01)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 85ac383f-9fc6-4876-9b54-d91f51fadc01)

                                                                       -----Query Job SQL Follows-----                                                                       

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_quarterly_metrics_quarter"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:),  __dbt__CTE__github_quarterly_metrics as (
 686:with daily_metrics as (
 687:
 688:    select *
 689:    from __dbt__CTE__github_daily_metrics
 690:
 691:)
 692:
 693:select 
 694:  
 695:  
 696:    timestamp_trunc(
 697:        cast(day as timestamp),
 698:        quarter
 699:    )
 700:
 701: as quarter, 
 702:  sum(number_issues_opened) as number_issues_opened,
 703:  sum(number_issues_closed) as number_issues_closed,
 704:  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
 705:  max(longest_days_issue_open) as longest_days_issue_open,
 706:  sum(number_prs_opened) as number_prs_opened,
 707:  sum(number_prs_merged) as number_prs_merged,
 708:  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
 709:  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
 710:  max(longest_days_pr_open) as longest_days_pr_open
 711:
 712:from daily_metrics 
 713:group by 1
 714:order by 1 desc
 715:)select count(*) as validation_errors
 716:from (
 717:
 718:    select
 719:        quarter
 720:
 721:    from __dbt__CTE__github_quarterly_metrics
 722:    where quarter is not null
 723:    group by quarter
 724:    having count(*) > 1
 725:
 726:) validation_errors
 727:
 728:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_github_quarterly_metrics_quarter (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 85ac383f-9fc6-4876-9b54-d91f51fadc01)
2020-11-18 15:37:48.156294 (Thread-1): 15:37:48 | 25 of 26 ERROR unique_github_quarterly_metrics_quarter............... [ERROR in 0.83s]
2020-11-18 15:37:48.156425 (Thread-1): Finished running node test.github_source.unique_github_quarterly_metrics_quarter
2020-11-18 15:37:48.156613 (Thread-1): Began running node test.github_source.unique_github_weekly_metrics_week
2020-11-18 15:37:48.156769 (Thread-1): 15:37:48 | 26 of 26 START test unique_github_weekly_metrics_week................ [RUN]
2020-11-18 15:37:48.157189 (Thread-1): Acquiring new bigquery connection "test.github_source.unique_github_weekly_metrics_week".
2020-11-18 15:37:48.158305 (Thread-1): unclosed <socket.socket fd=11, family=AddressFamily.AF_INET, type=2049, proto=6, laddr=('10.0.25.107', 43428), raddr=('172.217.13.234', 443)>
2020-11-18 15:37:48.158603 (Thread-1): unclosed <socket.socket fd=12, family=AddressFamily.AF_INET, type=SocketKind.SOCK_STREAM, proto=6, laddr=('10.0.25.107', 44532), raddr=('172.217.2.106', 443)>
2020-11-18 15:37:48.158920 (Thread-1): Compiling test.github_source.unique_github_weekly_metrics_week
2020-11-18 15:37:48.177545 (Thread-1): Writing injected SQL for node "test.github_source.unique_github_weekly_metrics_week"
2020-11-18 15:37:48.233837 (Thread-1): finished collecting timing info
2020-11-18 15:37:48.234315 (Thread-1): Opening a new connection, currently in state closed
2020-11-18 15:37:48.234808 (Thread-1): On test.github_source.unique_github_weekly_metrics_week: /* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_weekly_metrics_week"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_weekly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 

  
    timestamp_trunc(
        cast(day as timestamp),
        week
    )

 as week, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from (

    select
        week

    from __dbt__CTE__github_weekly_metrics
    where week is not null
    group by week
    having count(*) > 1

) validation_errors



2020-11-18 15:37:48.578069 (Thread-108): handling poll request
2020-11-18 15:37:48.578581 (Thread-108): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc34b8160>]}
2020-11-18 15:37:48.583426 (Thread-108): sending response (<Response 112658 bytes [200 OK]>) to 10.0.14.177
2020-11-18 15:37:48.591024 (Thread-1): Unhandled error while running:
/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_weekly_metrics_week"} */

    
    



with __dbt__CTE__stg_github_issue as (
with issue as (

    select *
    from `abij-playground`.`github`.`issue`

), fields as (

    select 
      id as issue_id,
      body,
      closed_at,
      created_at,
      locked as is_locked,
      milestone_id,
      number as issue_number,
      pull_request as is_pull_request,
      repository_id,
      state,
      title,
      updated_at,
      user_id
    from issue
)

select *
from fields
),  __dbt__CTE__stg_github_issue_label as (
with issue_label as (

    select *
    from `abij-playground`.`github`.`issue_label`

), fields as (

    select 
      issue_id,
      label
    from issue_label
)

select *
from fields
),  __dbt__CTE__github_issue_labels as (
with issue_label as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  
    string_agg(label, ', ')

 as labels
from issue_label
group by issue_id
),  __dbt__CTE__stg_github_repository as (
with repository as (

    select *
    from `abij-playground`.`github`.`repository`

), fields as (

    select 
      id as repository_id,
      full_name,
      private as is_private
    from repository
)

select *
from fields
),  __dbt__CTE__stg_github_issue_assignee as (
with issue_assignee as (

    select *
    from `abij-playground`.`github`.`issue_assignee`

), fields as (

    select 
      issue_id,
      user_id
    from issue_assignee
)

select *
from fields
),  __dbt__CTE__stg_github_user as (
with github_user as (

    select *
    from `abij-playground`.`github`.`user`

), fields as (

    select
      id as user_id,
      login as login_name,
      name,
      bio,
      company
    from github_user
)

select *
from fields
),  __dbt__CTE__github_issue_assignees as (
with issue_assignee as (

    select *
    from __dbt__CTE__stg_github_issue_assignee
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  issue_assignee.issue_id,
  
    string_agg(github_user.login_name, ', ')

 as assignees
from issue_assignee
join github_user on issue_assignee.user_id = github_user.user_id
group by 1
),  __dbt__CTE__stg_github_issue_closed_history as (
with issue_closed_history as (

    select *
    from `abij-playground`.`github`.`issue_closed_history`

), fields as (

    select 
      issue_id,
      updated_at,
      closed as is_closed
    from issue_closed_history
)

select *
from fields
),  __dbt__CTE__github_issue_open_length as (
with issue as (
    
    select *
    from __dbt__CTE__stg_github_issue
  
), issue_closed_history as (

    select *
    from __dbt__CTE__stg_github_issue_closed_history
  
), close_events_stacked as (
    select  
      issue_id,
      created_at as updated_at,
      false as is_closed
    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
    union all
    select
      issue_id,
      updated_at,
      is_closed
    from issue_closed_history

), close_events_with_timestamps as (

  select
    issue_id,
    updated_at as valid_starting,
    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
    current_timestamp
) as valid_until,
    is_closed
  from close_events_stacked

)

select
  issue_id,
  sum(
  

    datetime_diff(
        cast(valid_until as datetime),
        cast(valid_starting as datetime),
        second
    )


) /60/60/24 as days_issue_open,
  count(*) - 1 as number_of_times_reopened
from close_events_with_timestamps
  where not is_closed
group by issue_id
),  __dbt__CTE__github_issue_comments as (
with issue_comment as (

    select *
    from __dbt__CTE__stg_github_issue_label
  
)

select
  issue_id,
  count(*) as number_of_comments
from issue_comment
group by issue_id
),  __dbt__CTE__stg_github_pull_request_review as (
with pull_request_review as (

    select *
    from `abij-playground`.`github`.`pull_request_review`

), fields as (

    select 
      pull_request_id,
      submitted_at,
      state,
      user_id
    from pull_request_review
)

select *
from fields
),  __dbt__CTE__stg_github_pull_request as (
with pull_request as (

    select *
    from `abij-playground`.`github`.`pull_request`

), fields as (

    select 
      id as pull_request_id,
      issue_id,
      head_repo_id,
      head_user_id
    from pull_request
)

select *
from fields
),  __dbt__CTE__stg_github_requested_reviewer_history as (
with requested_reviewer_history as (

    select *
    from `abij-playground`.`github`.`requested_reviewer_history`

), fields as (

    select 
      pull_request_id,
      created_at,
      requested_id,
      removed
    from requested_reviewer_history
)

select *
from fields
),  __dbt__CTE__stg_github_issue_merged as (
with issue_merged as (

    select *
    from `abij-playground`.`github`.`issue_merged`

), fields as (

    select 
      issue_id,
      merged_at
    from issue_merged
)

select *
from fields
),  __dbt__CTE__github_pull_request_times as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

), requested_reviewer_history as (

    select *
    from __dbt__CTE__stg_github_requested_reviewer_history
    where not removed

), issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_merged as (

    select
      issue_id,
      min(merged_at) as merged_at
      from __dbt__CTE__stg_github_issue_merged
    group by 1

), first_request_time as (

    select
      pull_request.issue_id,
      pull_request.pull_request_id,
      -- Finds the first review that is by the requested reviewer and is not a dismissal
      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
                then pull_request_review.submitted_at end 
      else null end) as time_of_first_requested_reviewer_review,
      min(requested_reviewer_history.created_at) as time_of_first_request,
      min(pull_request_review.submitted_at) as time_of_first_review_post_request
    from pull_request
    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
      and pull_request_review.submitted_at > requested_reviewer_history.created_at
    group by 1, 2

)

select
  first_request_time.issue_id,
  issue_merged.merged_at,
  
  

    datetime_diff(
        cast(coalesce(time_of_first_review_post_request, 
    current_timestamp
) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_first_review,
  
  

    datetime_diff(
        cast(least(
                            coalesce(time_of_first_requested_reviewer_review, 
    current_timestamp
),
                            coalesce(issue.closed_at, 
    current_timestamp
)) as datetime),
        cast(time_of_first_request as datetime),
        second
    )


 / 60/60 as hours_request_review_to_first_action,
  
  

    datetime_diff(
        cast(merged_at as datetime),
        cast(time_of_first_request as datetime),
        second
    )


/ 60/60 as hours_request_review_to_merge
from first_request_time
join issue on first_request_time.issue_id = issue.issue_id
left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
),  __dbt__CTE__github_pull_request_reviewers as (
with pull_request_review as (

    select *
    from __dbt__CTE__stg_github_pull_request_review
  
), github_user as (

    select *
    from __dbt__CTE__stg_github_user

)

select
  pull_request_review.pull_request_id,
  
    string_agg(github_user.login_name, ', ')

 as reviewers,
  count(*) as number_of_reviews
from pull_request_review
left join github_user on pull_request_review.user_id = github_user.user_id
group by 1
),  __dbt__CTE__github_issue_joined as (
with issue as (

    select *
    from __dbt__CTE__stg_github_issue
  
), issue_labels as (

    select *
    from __dbt__CTE__github_issue_labels

), repository as (

    select *
    from __dbt__CTE__stg_github_repository

), issue_assignees as (

    select *
    from __dbt__CTE__github_issue_assignees

), issue_open_length as (

    select *
    from __dbt__CTE__github_issue_open_length

), issue_comments as (

    select *
    from __dbt__CTE__github_issue_comments

), creator as (

    select *
    from __dbt__CTE__stg_github_user

), pull_request_times as (

    select *
    from __dbt__CTE__github_pull_request_times

), pull_request_reviewers as (

    select *
    from __dbt__CTE__github_pull_request_reviewers

), pull_request as (

    select *
    from __dbt__CTE__stg_github_pull_request

)

select
  issue.*,
  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
  issue_open_length.days_issue_open,
  issue_open_length.number_of_times_reopened,
  labels.labels,
  issue_comments.number_of_comments,
  repository.full_name as repository,
  issue_assignees.assignees,
  creator.login_name as creator_login_name,
  creator.name as creator_name,
  creator.company as creator_company,
  hours_request_review_to_first_review,
  hours_request_review_to_first_action,
  hours_request_review_to_merge,
  merged_at,
  reviewers,
  number_of_reviews
from issue
left join issue_labels as labels
  on issue.issue_id = labels.issue_id
join repository
  on issue.repository_id = repository.repository_id
left join issue_assignees
  on issue.issue_id = issue_assignees.issue_id
left join issue_open_length
  on issue.issue_id = issue_open_length.issue_id
left join issue_comments 
  on issue.issue_id = issue_comments.issue_id
left join creator 
  on issue.user_id = creator.user_id
left join pull_request
  on issue.issue_id = pull_request.issue_id
left join pull_request_times
  on issue.issue_id = pull_request_times.issue_id
left join pull_request_reviewers
  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
),  __dbt__CTE__github_issues as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  issue_id,
  body,
  closed_at,
  created_at,
  is_locked,
  milestone_id,
  issue_number,
  is_pull_request,
  repository_id,
  state,
  title,
  updated_at,
  user_id,
  url_link,
  days_issue_open,
  number_of_times_reopened,
  labels,
  number_of_comments,
  repository,
  assignees,
  creator_login_name,
  creator_name,
  creator_company
from issue_joined
where not is_pull_request
),  __dbt__CTE__github_pull_requests as (
with issue_joined as (

    select *
    from __dbt__CTE__github_issue_joined  
)

select
  *
from issue_joined
where is_pull_request
),  __dbt__CTE__github_daily_metrics as (
with github_issues as (

    select *
    from __dbt__CTE__github_issues

), pull_requests as (

    select *
    from __dbt__CTE__github_pull_requests

), issues_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_opened,
      sum(days_issue_open) as sum_days_issue_open,
      max(days_issue_open) as longest_days_issue_open
    from github_issues
    group by 1

), issues_closed_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_issues_closed
    from github_issues
    where closed_at is not null
    group by 1

), prs_opened_per_day as (

   select 
      
    timestamp_trunc(
        cast(created_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_opened,
      sum(days_issue_open) as sum_days_pr_open,
      max(days_issue_open) as longest_days_pr_open
    from pull_requests
    group by 1

), prs_merged_per_day as (

   select 
      
    timestamp_trunc(
        cast(merged_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_merged
    from pull_requests
    where merged_at is not null
    group by 1

), prs_closed_without_merge_per_day as (

   select 
      
    timestamp_trunc(
        cast(closed_at as timestamp),
        day
    )

 as day, 
      count(*) as number_prs_closed_without_merge
    from pull_requests
    where closed_at is not null
      and merged_at is null
    group by 1

), issues_per_day as (

    select 
      coalesce(issues_opened_per_day.day, 
        issues_closed_per_day.day
      ) as day,
      number_issues_opened,
      number_issues_closed,      
      sum_days_issue_open,
      longest_days_issue_open
    from issues_opened_per_day
    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day

), prs_per_day as (

    select 
      coalesce(prs_opened_per_day.day, 
        prs_merged_per_day.day,
        prs_closed_without_merge_per_day.day
      ) as day,
      number_prs_opened,
      number_prs_merged,
      number_prs_closed_without_merge,
      sum_days_pr_open,
      longest_days_pr_open
    from prs_opened_per_day
    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day

)

select 
  coalesce(issues_per_day.day, 
    prs_per_day.day
  ) as day,
  coalesce(number_issues_opened, 0) as number_issues_opened,
  coalesce(number_issues_closed, 0) as number_issues_closed,
  sum_days_issue_open,
  longest_days_issue_open,
  coalesce(number_prs_opened, 0) as number_prs_opened,
  coalesce(number_prs_merged, 0) as number_prs_merged,
  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
  sum_days_pr_open,
  longest_days_pr_open
from issues_per_day 
full outer join prs_per_day on issues_per_day.day = prs_per_day.day
order by day desc
),  __dbt__CTE__github_weekly_metrics as (
with daily_metrics as (

    select *
    from __dbt__CTE__github_daily_metrics

)

select 

  
    timestamp_trunc(
        cast(day as timestamp),
        week
    )

 as week, 
  sum(number_issues_opened) as number_issues_opened,
  sum(number_issues_closed) as number_issues_closed,
  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
  max(longest_days_issue_open) as longest_days_issue_open,
  sum(number_prs_opened) as number_prs_opened,
  sum(number_prs_merged) as number_prs_merged,
  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
  max(longest_days_pr_open) as longest_days_pr_open

from daily_metrics 
group by 1
order by 1 desc
)select count(*) as validation_errors
from (

    select
        week

    from __dbt__CTE__github_weekly_metrics
    where week is not null
    group by week
    having count(*) > 1

) validation_errors



2020-11-18 15:37:48.591324 (Thread-1): finished collecting timing info
2020-11-18 15:37:48.591900 (Thread-1): Runtime Error in test unique_github_weekly_metrics_week (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 578d3840-c327-4230-9f62-971400d98a44)
Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 103, in exception_handler
    yield
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/retry.py", line 184, in retry_target
    return target()
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 266, in fn
    return self._query_and_results(client, sql, conn, job_params)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 428, in _query_and_results
    iterator = query_job.result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 3196, in result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/cloud/bigquery/job.py", line 818, in result
    return super(_AsyncJob, self).result(timeout=timeout)
  File "/usr/local/lib/python3.6/dist-packages/google/api_core/future/polling.py", line 130, in result
    raise self._exception
google.api_core.exceptions.NotFound: 404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU

(job ID: 578d3840-c327-4230-9f62-971400d98a44)

                                                                    -----Query Job SQL Follows-----                                                                    

    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |
   1:/* {"app": "dbt", "dbt_version": "0.18.1", "profile_name": "user", "target_name": "default", "node_id": "test.github_source.unique_github_weekly_metrics_week"} */
   2:
   3:    
   4:    
   5:
   6:
   7:
   8:with __dbt__CTE__stg_github_issue as (
   9:with issue as (
  10:
  11:    select *
  12:    from `abij-playground`.`github`.`issue`
  13:
  14:), fields as (
  15:
  16:    select 
  17:      id as issue_id,
  18:      body,
  19:      closed_at,
  20:      created_at,
  21:      locked as is_locked,
  22:      milestone_id,
  23:      number as issue_number,
  24:      pull_request as is_pull_request,
  25:      repository_id,
  26:      state,
  27:      title,
  28:      updated_at,
  29:      user_id
  30:    from issue
  31:)
  32:
  33:select *
  34:from fields
  35:),  __dbt__CTE__stg_github_issue_label as (
  36:with issue_label as (
  37:
  38:    select *
  39:    from `abij-playground`.`github`.`issue_label`
  40:
  41:), fields as (
  42:
  43:    select 
  44:      issue_id,
  45:      label
  46:    from issue_label
  47:)
  48:
  49:select *
  50:from fields
  51:),  __dbt__CTE__github_issue_labels as (
  52:with issue_label as (
  53:
  54:    select *
  55:    from __dbt__CTE__stg_github_issue_label
  56:  
  57:)
  58:
  59:select
  60:  issue_id,
  61:  
  62:    string_agg(label, ', ')
  63:
  64: as labels
  65:from issue_label
  66:group by issue_id
  67:),  __dbt__CTE__stg_github_repository as (
  68:with repository as (
  69:
  70:    select *
  71:    from `abij-playground`.`github`.`repository`
  72:
  73:), fields as (
  74:
  75:    select 
  76:      id as repository_id,
  77:      full_name,
  78:      private as is_private
  79:    from repository
  80:)
  81:
  82:select *
  83:from fields
  84:),  __dbt__CTE__stg_github_issue_assignee as (
  85:with issue_assignee as (
  86:
  87:    select *
  88:    from `abij-playground`.`github`.`issue_assignee`
  89:
  90:), fields as (
  91:
  92:    select 
  93:      issue_id,
  94:      user_id
  95:    from issue_assignee
  96:)
  97:
  98:select *
  99:from fields
 100:),  __dbt__CTE__stg_github_user as (
 101:with github_user as (
 102:
 103:    select *
 104:    from `abij-playground`.`github`.`user`
 105:
 106:), fields as (
 107:
 108:    select
 109:      id as user_id,
 110:      login as login_name,
 111:      name,
 112:      bio,
 113:      company
 114:    from github_user
 115:)
 116:
 117:select *
 118:from fields
 119:),  __dbt__CTE__github_issue_assignees as (
 120:with issue_assignee as (
 121:
 122:    select *
 123:    from __dbt__CTE__stg_github_issue_assignee
 124:  
 125:), github_user as (
 126:
 127:    select *
 128:    from __dbt__CTE__stg_github_user
 129:
 130:)
 131:
 132:select
 133:  issue_assignee.issue_id,
 134:  
 135:    string_agg(github_user.login_name, ', ')
 136:
 137: as assignees
 138:from issue_assignee
 139:join github_user on issue_assignee.user_id = github_user.user_id
 140:group by 1
 141:),  __dbt__CTE__stg_github_issue_closed_history as (
 142:with issue_closed_history as (
 143:
 144:    select *
 145:    from `abij-playground`.`github`.`issue_closed_history`
 146:
 147:), fields as (
 148:
 149:    select 
 150:      issue_id,
 151:      updated_at,
 152:      closed as is_closed
 153:    from issue_closed_history
 154:)
 155:
 156:select *
 157:from fields
 158:),  __dbt__CTE__github_issue_open_length as (
 159:with issue as (
 160:    
 161:    select *
 162:    from __dbt__CTE__stg_github_issue
 163:  
 164:), issue_closed_history as (
 165:
 166:    select *
 167:    from __dbt__CTE__stg_github_issue_closed_history
 168:  
 169:), close_events_stacked as (
 170:    select  
 171:      issue_id,
 172:      created_at as updated_at,
 173:      false as is_closed
 174:    from issue -- required because issue_closed_history table does not have a line item for when the issue was opened
 175:    union all
 176:    select
 177:      issue_id,
 178:      updated_at,
 179:      is_closed
 180:    from issue_closed_history
 181:
 182:), close_events_with_timestamps as (
 183:
 184:  select
 185:    issue_id,
 186:    updated_at as valid_starting,
 187:    coalesce(lead(updated_at) over (partition by issue_id order by updated_at), 
 188:    current_timestamp
 189:) as valid_until,
 190:    is_closed
 191:  from close_events_stacked
 192:
 193:)
 194:
 195:select
 196:  issue_id,
 197:  sum(
 198:  
 199:
 200:    datetime_diff(
 201:        cast(valid_until as datetime),
 202:        cast(valid_starting as datetime),
 203:        second
 204:    )
 205:
 206:
 207:) /60/60/24 as days_issue_open,
 208:  count(*) - 1 as number_of_times_reopened
 209:from close_events_with_timestamps
 210:  where not is_closed
 211:group by issue_id
 212:),  __dbt__CTE__github_issue_comments as (
 213:with issue_comment as (
 214:
 215:    select *
 216:    from __dbt__CTE__stg_github_issue_label
 217:  
 218:)
 219:
 220:select
 221:  issue_id,
 222:  count(*) as number_of_comments
 223:from issue_comment
 224:group by issue_id
 225:),  __dbt__CTE__stg_github_pull_request_review as (
 226:with pull_request_review as (
 227:
 228:    select *
 229:    from `abij-playground`.`github`.`pull_request_review`
 230:
 231:), fields as (
 232:
 233:    select 
 234:      pull_request_id,
 235:      submitted_at,
 236:      state,
 237:      user_id
 238:    from pull_request_review
 239:)
 240:
 241:select *
 242:from fields
 243:),  __dbt__CTE__stg_github_pull_request as (
 244:with pull_request as (
 245:
 246:    select *
 247:    from `abij-playground`.`github`.`pull_request`
 248:
 249:), fields as (
 250:
 251:    select 
 252:      id as pull_request_id,
 253:      issue_id,
 254:      head_repo_id,
 255:      head_user_id
 256:    from pull_request
 257:)
 258:
 259:select *
 260:from fields
 261:),  __dbt__CTE__stg_github_requested_reviewer_history as (
 262:with requested_reviewer_history as (
 263:
 264:    select *
 265:    from `abij-playground`.`github`.`requested_reviewer_history`
 266:
 267:), fields as (
 268:
 269:    select 
 270:      pull_request_id,
 271:      created_at,
 272:      requested_id,
 273:      removed
 274:    from requested_reviewer_history
 275:)
 276:
 277:select *
 278:from fields
 279:),  __dbt__CTE__stg_github_issue_merged as (
 280:with issue_merged as (
 281:
 282:    select *
 283:    from `abij-playground`.`github`.`issue_merged`
 284:
 285:), fields as (
 286:
 287:    select 
 288:      issue_id,
 289:      merged_at
 290:    from issue_merged
 291:)
 292:
 293:select *
 294:from fields
 295:),  __dbt__CTE__github_pull_request_times as (
 296:with pull_request_review as (
 297:
 298:    select *
 299:    from __dbt__CTE__stg_github_pull_request_review
 300:  
 301:), pull_request as (
 302:
 303:    select *
 304:    from __dbt__CTE__stg_github_pull_request
 305:
 306:), requested_reviewer_history as (
 307:
 308:    select *
 309:    from __dbt__CTE__stg_github_requested_reviewer_history
 310:    where not removed
 311:
 312:), issue as (
 313:
 314:    select *
 315:    from __dbt__CTE__stg_github_issue
 316:  
 317:), issue_merged as (
 318:
 319:    select
 320:      issue_id,
 321:      min(merged_at) as merged_at
 322:      from __dbt__CTE__stg_github_issue_merged
 323:    group by 1
 324:
 325:), first_request_time as (
 326:
 327:    select
 328:      pull_request.issue_id,
 329:      pull_request.pull_request_id,
 330:      -- Finds the first review that is by the requested reviewer and is not a dismissal
 331:      min(case when requested_reviewer_history.requested_id = pull_request_review.user_id then
 332:          case when lower(pull_request_review.state) in ('commented', 'approved', 'changes_requested') 
 333:                then pull_request_review.submitted_at end 
 334:      else null end) as time_of_first_requested_reviewer_review,
 335:      min(requested_reviewer_history.created_at) as time_of_first_request,
 336:      min(pull_request_review.submitted_at) as time_of_first_review_post_request
 337:    from pull_request
 338:    join requested_reviewer_history on requested_reviewer_history.pull_request_id = pull_request.pull_request_id
 339:    left join pull_request_review on pull_request_review.pull_request_id = pull_request.pull_request_id
 340:      and pull_request_review.submitted_at > requested_reviewer_history.created_at
 341:    group by 1, 2
 342:
 343:)
 344:
 345:select
 346:  first_request_time.issue_id,
 347:  issue_merged.merged_at,
 348:  
 349:  
 350:
 351:    datetime_diff(
 352:        cast(coalesce(time_of_first_review_post_request, 
 353:    current_timestamp
 354:) as datetime),
 355:        cast(time_of_first_request as datetime),
 356:        second
 357:    )
 358:
 359:
 360:/ 60/60 as hours_request_review_to_first_review,
 361:  
 362:  
 363:
 364:    datetime_diff(
 365:        cast(least(
 366:                            coalesce(time_of_first_requested_reviewer_review, 
 367:    current_timestamp
 368:),
 369:                            coalesce(issue.closed_at, 
 370:    current_timestamp
 371:)) as datetime),
 372:        cast(time_of_first_request as datetime),
 373:        second
 374:    )
 375:
 376:
 377: / 60/60 as hours_request_review_to_first_action,
 378:  
 379:  
 380:
 381:    datetime_diff(
 382:        cast(merged_at as datetime),
 383:        cast(time_of_first_request as datetime),
 384:        second
 385:    )
 386:
 387:
 388:/ 60/60 as hours_request_review_to_merge
 389:from first_request_time
 390:join issue on first_request_time.issue_id = issue.issue_id
 391:left join issue_merged on first_request_time.issue_id = issue_merged.issue_id
 392:),  __dbt__CTE__github_pull_request_reviewers as (
 393:with pull_request_review as (
 394:
 395:    select *
 396:    from __dbt__CTE__stg_github_pull_request_review
 397:  
 398:), github_user as (
 399:
 400:    select *
 401:    from __dbt__CTE__stg_github_user
 402:
 403:)
 404:
 405:select
 406:  pull_request_review.pull_request_id,
 407:  
 408:    string_agg(github_user.login_name, ', ')
 409:
 410: as reviewers,
 411:  count(*) as number_of_reviews
 412:from pull_request_review
 413:left join github_user on pull_request_review.user_id = github_user.user_id
 414:group by 1
 415:),  __dbt__CTE__github_issue_joined as (
 416:with issue as (
 417:
 418:    select *
 419:    from __dbt__CTE__stg_github_issue
 420:  
 421:), issue_labels as (
 422:
 423:    select *
 424:    from __dbt__CTE__github_issue_labels
 425:
 426:), repository as (
 427:
 428:    select *
 429:    from __dbt__CTE__stg_github_repository
 430:
 431:), issue_assignees as (
 432:
 433:    select *
 434:    from __dbt__CTE__github_issue_assignees
 435:
 436:), issue_open_length as (
 437:
 438:    select *
 439:    from __dbt__CTE__github_issue_open_length
 440:
 441:), issue_comments as (
 442:
 443:    select *
 444:    from __dbt__CTE__github_issue_comments
 445:
 446:), creator as (
 447:
 448:    select *
 449:    from __dbt__CTE__stg_github_user
 450:
 451:), pull_request_times as (
 452:
 453:    select *
 454:    from __dbt__CTE__github_pull_request_times
 455:
 456:), pull_request_reviewers as (
 457:
 458:    select *
 459:    from __dbt__CTE__github_pull_request_reviewers
 460:
 461:), pull_request as (
 462:
 463:    select *
 464:    from __dbt__CTE__stg_github_pull_request
 465:
 466:)
 467:
 468:select
 469:  issue.*,
 470:  concat('https://github.com/', repository.full_name, '/pull/', issue.issue_number) as url_link,
 471:  issue_open_length.days_issue_open,
 472:  issue_open_length.number_of_times_reopened,
 473:  labels.labels,
 474:  issue_comments.number_of_comments,
 475:  repository.full_name as repository,
 476:  issue_assignees.assignees,
 477:  creator.login_name as creator_login_name,
 478:  creator.name as creator_name,
 479:  creator.company as creator_company,
 480:  hours_request_review_to_first_review,
 481:  hours_request_review_to_first_action,
 482:  hours_request_review_to_merge,
 483:  merged_at,
 484:  reviewers,
 485:  number_of_reviews
 486:from issue
 487:left join issue_labels as labels
 488:  on issue.issue_id = labels.issue_id
 489:join repository
 490:  on issue.repository_id = repository.repository_id
 491:left join issue_assignees
 492:  on issue.issue_id = issue_assignees.issue_id
 493:left join issue_open_length
 494:  on issue.issue_id = issue_open_length.issue_id
 495:left join issue_comments 
 496:  on issue.issue_id = issue_comments.issue_id
 497:left join creator 
 498:  on issue.user_id = creator.user_id
 499:left join pull_request
 500:  on issue.issue_id = pull_request.issue_id
 501:left join pull_request_times
 502:  on issue.issue_id = pull_request_times.issue_id
 503:left join pull_request_reviewers
 504:  on pull_request.pull_request_id = pull_request_reviewers.pull_request_id
 505:),  __dbt__CTE__github_issues as (
 506:with issue_joined as (
 507:
 508:    select *
 509:    from __dbt__CTE__github_issue_joined  
 510:)
 511:
 512:select
 513:  issue_id,
 514:  body,
 515:  closed_at,
 516:  created_at,
 517:  is_locked,
 518:  milestone_id,
 519:  issue_number,
 520:  is_pull_request,
 521:  repository_id,
 522:  state,
 523:  title,
 524:  updated_at,
 525:  user_id,
 526:  url_link,
 527:  days_issue_open,
 528:  number_of_times_reopened,
 529:  labels,
 530:  number_of_comments,
 531:  repository,
 532:  assignees,
 533:  creator_login_name,
 534:  creator_name,
 535:  creator_company
 536:from issue_joined
 537:where not is_pull_request
 538:),  __dbt__CTE__github_pull_requests as (
 539:with issue_joined as (
 540:
 541:    select *
 542:    from __dbt__CTE__github_issue_joined  
 543:)
 544:
 545:select
 546:  *
 547:from issue_joined
 548:where is_pull_request
 549:),  __dbt__CTE__github_daily_metrics as (
 550:with github_issues as (
 551:
 552:    select *
 553:    from __dbt__CTE__github_issues
 554:
 555:), pull_requests as (
 556:
 557:    select *
 558:    from __dbt__CTE__github_pull_requests
 559:
 560:), issues_opened_per_day as (
 561:
 562:   select 
 563:      
 564:    timestamp_trunc(
 565:        cast(created_at as timestamp),
 566:        day
 567:    )
 568:
 569: as day, 
 570:      count(*) as number_issues_opened,
 571:      sum(days_issue_open) as sum_days_issue_open,
 572:      max(days_issue_open) as longest_days_issue_open
 573:    from github_issues
 574:    group by 1
 575:
 576:), issues_closed_per_day as (
 577:
 578:   select 
 579:      
 580:    timestamp_trunc(
 581:        cast(closed_at as timestamp),
 582:        day
 583:    )
 584:
 585: as day, 
 586:      count(*) as number_issues_closed
 587:    from github_issues
 588:    where closed_at is not null
 589:    group by 1
 590:
 591:), prs_opened_per_day as (
 592:
 593:   select 
 594:      
 595:    timestamp_trunc(
 596:        cast(created_at as timestamp),
 597:        day
 598:    )
 599:
 600: as day, 
 601:      count(*) as number_prs_opened,
 602:      sum(days_issue_open) as sum_days_pr_open,
 603:      max(days_issue_open) as longest_days_pr_open
 604:    from pull_requests
 605:    group by 1
 606:
 607:), prs_merged_per_day as (
 608:
 609:   select 
 610:      
 611:    timestamp_trunc(
 612:        cast(merged_at as timestamp),
 613:        day
 614:    )
 615:
 616: as day, 
 617:      count(*) as number_prs_merged
 618:    from pull_requests
 619:    where merged_at is not null
 620:    group by 1
 621:
 622:), prs_closed_without_merge_per_day as (
 623:
 624:   select 
 625:      
 626:    timestamp_trunc(
 627:        cast(closed_at as timestamp),
 628:        day
 629:    )
 630:
 631: as day, 
 632:      count(*) as number_prs_closed_without_merge
 633:    from pull_requests
 634:    where closed_at is not null
 635:      and merged_at is null
 636:    group by 1
 637:
 638:), issues_per_day as (
 639:
 640:    select 
 641:      coalesce(issues_opened_per_day.day, 
 642:        issues_closed_per_day.day
 643:      ) as day,
 644:      number_issues_opened,
 645:      number_issues_closed,      
 646:      sum_days_issue_open,
 647:      longest_days_issue_open
 648:    from issues_opened_per_day
 649:    full outer join issues_closed_per_day on issues_opened_per_day.day = issues_closed_per_day.day
 650:
 651:), prs_per_day as (
 652:
 653:    select 
 654:      coalesce(prs_opened_per_day.day, 
 655:        prs_merged_per_day.day,
 656:        prs_closed_without_merge_per_day.day
 657:      ) as day,
 658:      number_prs_opened,
 659:      number_prs_merged,
 660:      number_prs_closed_without_merge,
 661:      sum_days_pr_open,
 662:      longest_days_pr_open
 663:    from prs_opened_per_day
 664:    full outer join prs_merged_per_day on prs_opened_per_day.day = prs_merged_per_day.day
 665:    full outer join prs_closed_without_merge_per_day on coalesce(prs_opened_per_day.day, prs_merged_per_day.day) = prs_closed_without_merge_per_day.day
 666:
 667:)
 668:
 669:select 
 670:  coalesce(issues_per_day.day, 
 671:    prs_per_day.day
 672:  ) as day,
 673:  coalesce(number_issues_opened, 0) as number_issues_opened,
 674:  coalesce(number_issues_closed, 0) as number_issues_closed,
 675:  sum_days_issue_open,
 676:  longest_days_issue_open,
 677:  coalesce(number_prs_opened, 0) as number_prs_opened,
 678:  coalesce(number_prs_merged, 0) as number_prs_merged,
 679:  coalesce(number_prs_closed_without_merge, 0) as number_prs_closed_without_merge,
 680:  sum_days_pr_open,
 681:  longest_days_pr_open
 682:from issues_per_day 
 683:full outer join prs_per_day on issues_per_day.day = prs_per_day.day
 684:order by day desc
 685:),  __dbt__CTE__github_weekly_metrics as (
 686:with daily_metrics as (
 687:
 688:    select *
 689:    from __dbt__CTE__github_daily_metrics
 690:
 691:)
 692:
 693:select 
 694:
 695:  
 696:    timestamp_trunc(
 697:        cast(day as timestamp),
 698:        week
 699:    )
 700:
 701: as week, 
 702:  sum(number_issues_opened) as number_issues_opened,
 703:  sum(number_issues_closed) as number_issues_closed,
 704:  sum(sum_days_issue_open) / sum(number_issues_opened) as avg_days_issue_open,
 705:  max(longest_days_issue_open) as longest_days_issue_open,
 706:  sum(number_prs_opened) as number_prs_opened,
 707:  sum(number_prs_merged) as number_prs_merged,
 708:  sum(number_prs_closed_without_merge) as number_prs_closed_without_merge,
 709:  sum(sum_days_pr_open) / sum(number_prs_opened) as avg_days_pr_open,
 710:  max(longest_days_pr_open) as longest_days_pr_open
 711:
 712:from daily_metrics 
 713:group by 1
 714:order by 1 desc
 715:)select count(*) as validation_errors
 716:from (
 717:
 718:    select
 719:        week
 720:
 721:    from __dbt__CTE__github_weekly_metrics
 722:    where week is not null
 723:    group by week
 724:    having count(*) > 1
 725:
 726:) validation_errors
 727:
 728:
    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |    .    |

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 333, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 276, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/base.py", line 378, in run
    return self.execute(compiled_node, manifest)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 84, in execute
    failed_rows = self.execute_schema_test(test)
  File "/usr/local/lib/python3.6/dist-packages/dbt/task/test.py", line 64, in execute_schema_test
    fetch=True,
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/base/impl.py", line 227, in execute
    fetch=fetch
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 275, in execute
    query_job, iterator = self.raw_execute(sql, fetch=fetch)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 268, in raw_execute
    query_job, iterator = self._retry_and_handle(msg=sql, conn=conn, fn=fn)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 447, in _retry_and_handle
    on_error=reopen_conn_on_error)
  File "/usr/lib/python3.6/contextlib.py", line 99, in __exit__
    self.gen.throw(type, value, traceback)
  File "/usr/local/lib/python3.6/dist-packages/dbt/adapters/bigquery/connections.py", line 134, in exception_handler
    raise RuntimeException(exc_message)
dbt.exceptions.RuntimeException: Runtime Error in test unique_github_weekly_metrics_week (models/github/github.yml)
  404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
  
  (job ID: 578d3840-c327-4230-9f62-971400d98a44)
2020-11-18 15:37:48.592965 (Thread-1): 15:37:48 | 26 of 26 ERROR unique_github_weekly_metrics_week..................... [ERROR in 0.44s]
2020-11-18 15:37:48.593084 (Thread-1): Finished running node test.github_source.unique_github_weekly_metrics_week
2020-11-18 15:37:48.690768 (MainThread): Acquiring new bigquery connection "master".
2020-11-18 15:37:48.691133 (MainThread): 15:37:48 | 
2020-11-18 15:37:48.691217 (MainThread): 15:37:48 | Finished running 26 tests in 17.63s.
2020-11-18 15:37:48.691284 (MainThread): Connection 'master' was properly closed.
2020-11-18 15:37:48.691334 (MainThread): Connection 'test.github_source.unique_github_weekly_metrics_week' was properly closed.
2020-11-18 15:37:49.103492 (MainThread): 
2020-11-18 15:37:49.103663 (MainThread): Completed with 22 errors and 0 warnings:
2020-11-18 15:37:49.103734 (MainThread): 
2020-11-18 15:37:49.103802 (MainThread): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_assignee_issue_id__user_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.103855 (MainThread):   404 Not found: Table abij-playground:github.issue_assignee was not found in location EU
2020-11-18 15:37:49.103902 (MainThread):   
2020-11-18 15:37:49.103947 (MainThread):   (job ID: 8cf0ea84-50e5-4931-9d91-1fae952db70b)
2020-11-18 15:37:49.103994 (MainThread): 
2020-11-18 15:37:49.104049 (MainThread): Runtime Error in test dbt_utils_source_unique_combination_of_columns_github_issue_closed_history_issue_id__updated_at (models/github_source/src_github.yml)
2020-11-18 15:37:49.104095 (MainThread):   404 Not found: Table abij-playground:github.issue_closed_history was not found in location EU
2020-11-18 15:37:49.104142 (MainThread):   
2020-11-18 15:37:49.104189 (MainThread):   (job ID: 5a8626c9-8936-49c8-b590-7a7a55af5eca)
2020-11-18 15:37:49.104238 (MainThread): 
2020-11-18 15:37:49.104291 (MainThread): Runtime Error in test not_null_github_daily_metrics_day (models/github/github.yml)
2020-11-18 15:37:49.104338 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.104381 (MainThread):   
2020-11-18 15:37:49.104425 (MainThread):   (job ID: 1a2862cc-0350-42d3-9632-621c6b2a54a5)
2020-11-18 15:37:49.104471 (MainThread): 
2020-11-18 15:37:49.104525 (MainThread): Runtime Error in test not_null_github_issues_issue_id (models/github/github.yml)
2020-11-18 15:37:49.104573 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.104617 (MainThread):   
2020-11-18 15:37:49.104659 (MainThread):   (job ID: 3d4915ac-b8f6-43ee-a2e7-87b6fe20ef47)
2020-11-18 15:37:49.104706 (MainThread): 
2020-11-18 15:37:49.104756 (MainThread): Runtime Error in test not_null_github_monthly_metrics_month (models/github/github.yml)
2020-11-18 15:37:49.104802 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.104845 (MainThread):   
2020-11-18 15:37:49.104891 (MainThread):   (job ID: 9574fa17-6747-45c9-861d-73be1c42a348)
2020-11-18 15:37:49.104941 (MainThread): 
2020-11-18 15:37:49.104992 (MainThread): Runtime Error in test not_null_github_pull_requests_issue_id (models/github/github.yml)
2020-11-18 15:37:49.105039 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.105083 (MainThread):   
2020-11-18 15:37:49.105126 (MainThread):   (job ID: 018a30b8-71f1-4f0c-b680-ab8103c1f783)
2020-11-18 15:37:49.105199 (MainThread): 
2020-11-18 15:37:49.105267 (MainThread): Runtime Error in test not_null_github_quarterly_metrics_quarter (models/github/github.yml)
2020-11-18 15:37:49.105314 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.105358 (MainThread):   
2020-11-18 15:37:49.105404 (MainThread):   (job ID: a9b500c9-7033-4bda-b817-66107701d0a7)
2020-11-18 15:37:49.105453 (MainThread): 
2020-11-18 15:37:49.105505 (MainThread): Runtime Error in test not_null_github_weekly_metrics_week (models/github/github.yml)
2020-11-18 15:37:49.105552 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.105595 (MainThread):   
2020-11-18 15:37:49.105638 (MainThread):   (job ID: fbd4c369-78eb-4b78-a0d5-efa577de82ac)
2020-11-18 15:37:49.105688 (MainThread): 
2020-11-18 15:37:49.105741 (MainThread): Runtime Error in test source_not_null_github_issue_comment_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.105790 (MainThread):   404 Not found: Table abij-playground:github.issue_comment was not found in location EU
2020-11-18 15:37:49.105835 (MainThread):   
2020-11-18 15:37:49.105879 (MainThread):   (job ID: d3ef5b9e-3b59-4992-a70f-962a032c4c51)
2020-11-18 15:37:49.105925 (MainThread): 
2020-11-18 15:37:49.105976 (MainThread): Runtime Error in test source_not_null_github_issue_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.106023 (MainThread):   404 Not found: Table abij-playground:github.issue was not found in location EU
2020-11-18 15:37:49.106066 (MainThread):   
2020-11-18 15:37:49.106108 (MainThread):   (job ID: 4766ea95-a2fb-4243-92e9-18554d956325)
2020-11-18 15:37:49.106157 (MainThread): 
2020-11-18 15:37:49.106211 (MainThread): Runtime Error in test source_not_null_github_pull_request_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.106259 (MainThread):   404 Not found: Table abij-playground:github.pull_request was not found in location EU
2020-11-18 15:37:49.106303 (MainThread):   
2020-11-18 15:37:49.106346 (MainThread):   (job ID: 9236135f-6831-4fc4-863a-6b6787a155b9)
2020-11-18 15:37:49.106392 (MainThread): 
2020-11-18 15:37:49.106443 (MainThread): Runtime Error in test source_not_null_github_pull_request_review_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.106488 (MainThread):   404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
2020-11-18 15:37:49.106534 (MainThread):   
2020-11-18 15:37:49.106579 (MainThread):   (job ID: a6ba08ff-dae1-4237-9eb0-7f3b0c069f58)
2020-11-18 15:37:49.106626 (MainThread): 
2020-11-18 15:37:49.106678 (MainThread): Runtime Error in test source_unique_github_issue_comment_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.106723 (MainThread):   404 Not found: Table abij-playground:github.issue_comment was not found in location EU
2020-11-18 15:37:49.106766 (MainThread):   
2020-11-18 15:37:49.106808 (MainThread):   (job ID: c0b15e2b-3893-4a15-94a4-23919e8654c7)
2020-11-18 15:37:49.106854 (MainThread): 
2020-11-18 15:37:49.106907 (MainThread): Runtime Error in test source_unique_github_issue_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.106955 (MainThread):   404 Not found: Table abij-playground:github.issue was not found in location EU
2020-11-18 15:37:49.106998 (MainThread):   
2020-11-18 15:37:49.107057 (MainThread):   (job ID: df44453a-c91f-4718-aa8f-f7922f4b6cb7)
2020-11-18 15:37:49.107104 (MainThread): 
2020-11-18 15:37:49.107158 (MainThread): Runtime Error in test source_unique_github_pull_request_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.107207 (MainThread):   404 Not found: Table abij-playground:github.pull_request was not found in location EU
2020-11-18 15:37:49.107251 (MainThread):   
2020-11-18 15:37:49.107297 (MainThread):   (job ID: c1b94923-4436-4010-8b5c-528ea3389867)
2020-11-18 15:37:49.107346 (MainThread): 
2020-11-18 15:37:49.107398 (MainThread): Runtime Error in test source_unique_github_pull_request_review_id (models/github_source/src_github.yml)
2020-11-18 15:37:49.107444 (MainThread):   404 Not found: Table abij-playground:github.pull_request_review was not found in location EU
2020-11-18 15:37:49.107490 (MainThread):   
2020-11-18 15:37:49.107533 (MainThread):   (job ID: f5fdee4a-8dc5-4749-9d36-10ed88019742)
2020-11-18 15:37:49.107583 (MainThread): 
2020-11-18 15:37:49.107633 (MainThread): Runtime Error in test unique_github_daily_metrics_day (models/github/github.yml)
2020-11-18 15:37:49.107682 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.107729 (MainThread):   
2020-11-18 15:37:49.107772 (MainThread):   (job ID: 3b1a7505-8b74-45a7-acab-b0b74439d53a)
2020-11-18 15:37:49.107818 (MainThread): 
2020-11-18 15:37:49.107870 (MainThread): Runtime Error in test unique_github_issues_issue_id (models/github/github.yml)
2020-11-18 15:37:49.107916 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.107959 (MainThread):   
2020-11-18 15:37:49.108001 (MainThread):   (job ID: 3f8131ee-756a-4309-b3bb-a171587c3d2a)
2020-11-18 15:37:49.108051 (MainThread): 
2020-11-18 15:37:49.108109 (MainThread): Runtime Error in test unique_github_monthly_metrics_month (models/github/github.yml)
2020-11-18 15:37:49.108156 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.108199 (MainThread):   
2020-11-18 15:37:49.108242 (MainThread):   (job ID: 62f1d341-adc1-4882-be23-e5bdf27e94f5)
2020-11-18 15:37:49.108288 (MainThread): 
2020-11-18 15:37:49.108341 (MainThread): Runtime Error in test unique_github_pull_requests_issue_id (models/github/github.yml)
2020-11-18 15:37:49.108391 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.108437 (MainThread):   
2020-11-18 15:37:49.108485 (MainThread):   (job ID: 01e35d92-ba90-4882-a382-79b22d3d4174)
2020-11-18 15:37:49.108531 (MainThread): 
2020-11-18 15:37:49.108582 (MainThread): Runtime Error in test unique_github_quarterly_metrics_quarter (models/github/github.yml)
2020-11-18 15:37:49.108628 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.108674 (MainThread):   
2020-11-18 15:37:49.108718 (MainThread):   (job ID: 85ac383f-9fc6-4876-9b54-d91f51fadc01)
2020-11-18 15:37:49.108765 (MainThread): 
2020-11-18 15:37:49.108821 (MainThread): Runtime Error in test unique_github_weekly_metrics_week (models/github/github.yml)
2020-11-18 15:37:49.108997 (MainThread):   404 Not found: Table abij-playground:github.requested_reviewer_history was not found in location EU
2020-11-18 15:37:49.109059 (MainThread):   
2020-11-18 15:37:49.109104 (MainThread):   (job ID: 578d3840-c327-4230-9f62-971400d98a44)
2020-11-18 15:37:49.109186 (MainThread): 
Done. PASS=4 WARN=0 ERROR=22 SKIP=0 TOTAL=26
2020-11-18 15:37:49.886013 (Thread-109): handling poll request
2020-11-18 15:37:49.886534 (Thread-109): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc8077908>]}
2020-11-18 15:37:49.992822 (Thread-109): sending response (<Response 503277 bytes [200 OK]>) to 10.0.44.246
2020-11-18 15:37:50.414133 (Thread-110): handling status request
2020-11-18 15:37:50.414657 (Thread-110): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2e2e198>]}
2020-11-18 15:37:50.425304 (Thread-110): sending response (<Response 26373 bytes [200 OK]>) to 10.0.14.186
2020-11-18 16:02:22.497940 (Thread-111): handling status request
2020-11-18 16:02:22.502175 (Thread-111): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3749780>]}
2020-11-18 16:02:22.529198 (Thread-111): sending response (<Response 26373 bytes [200 OK]>) to 10.0.23.22
2020-11-18 16:02:35.210152 (Thread-112): handling status request
2020-11-18 16:02:35.210855 (Thread-112): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3520400>]}
2020-11-18 16:02:35.231481 (Thread-112): sending response (<Response 26373 bytes [200 OK]>) to 10.0.23.22
2020-11-18 16:02:44.570512 (MainThread): writing 1 spans (enabled:True)
2020-11-18 16:02:44.570835 (MainThread): 
      name jinja2.compile
        id 12172549593772701654
  trace_id 12283654407604618503
 parent_id None
   service None
  resource <memory>
      type template
     start 1605715364.56929
       end 1605715364.570289
  duration 0.000999s
     error 0
      tags 
           jinja2.template_name:<memory>
           runtime-id:fbe41a1a9fef4dc6b4d89ae108b31842
2020-11-18 16:02:44.787541 (Thread-113): Parsing macros/adapters.sql
2020-11-18 16:02:44.831472 (Thread-113): Parsing macros/etc.sql
2020-11-18 16:02:44.833846 (Thread-113): Parsing macros/catalog.sql
2020-11-18 16:02:44.844618 (Thread-113): Parsing macros/materializations/table.sql
2020-11-18 16:02:44.863561 (Thread-113): Parsing macros/materializations/view.sql
2020-11-18 16:02:44.869079 (Thread-113): Parsing macros/materializations/copy.sql
2020-11-18 16:02:44.877752 (Thread-113): Parsing macros/materializations/seed.sql
2020-11-18 16:02:44.883153 (Thread-113): Parsing macros/materializations/incremental.sql
2020-11-18 16:02:44.909775 (Thread-113): Parsing macros/materializations/snapshot.sql
2020-11-18 16:02:44.915065 (Thread-113): Parsing macros/core.sql
2020-11-18 16:02:44.922592 (Thread-113): Parsing macros/adapters/common.sql
2020-11-18 16:02:45.001455 (Thread-113): Parsing macros/materializations/helpers.sql
2020-11-18 16:02:45.018513 (Thread-113): Parsing macros/materializations/table/table.sql
2020-11-18 16:02:45.028462 (Thread-114): handling status request
2020-11-18 16:02:45.029164 (Thread-114): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc323cef0>]}
2020-11-18 16:02:45.030496 (Thread-114): sending response (<Response 184 bytes [200 OK]>) to 10.0.14.186
2020-11-18 16:02:45.037881 (Thread-113): Parsing macros/materializations/seed/seed.sql
2020-11-18 16:02:45.082522 (Thread-113): Parsing macros/materializations/view/view.sql
2020-11-18 16:02:45.093759 (Thread-113): Parsing macros/materializations/view/create_or_replace_view.sql
2020-11-18 16:02:45.103630 (Thread-113): Parsing macros/materializations/incremental/helpers.sql
2020-11-18 16:02:45.106386 (Thread-113): Parsing macros/materializations/incremental/incremental.sql
2020-11-18 16:02:45.118263 (Thread-113): Parsing macros/materializations/common/merge.sql
2020-11-18 16:02:45.143520 (AgentWriter): reported 38 traces in 0.06610s
2020-11-18 16:02:45.153470 (AgentWriter): initialized RateSampler, sample 100% of traces, 31 additional messages skipped
2020-11-18 16:02:45.145511 (Thread-113): Parsing macros/materializations/snapshot/strategies.sql
2020-11-18 16:02:45.198908 (Thread-113): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-11-18 16:02:45.202325 (Thread-113): Parsing macros/materializations/snapshot/snapshot.sql
2020-11-18 16:02:45.254074 (Thread-113): Parsing macros/schema_tests/relationships.sql
2020-11-18 16:02:45.262051 (Thread-113): Parsing macros/schema_tests/not_null.sql
2020-11-18 16:02:45.265011 (Thread-113): Parsing macros/schema_tests/unique.sql
2020-11-18 16:02:45.268263 (Thread-113): Parsing macros/schema_tests/accepted_values.sql
2020-11-18 16:02:45.273487 (Thread-113): Parsing macros/etc/get_custom_database.sql
2020-11-18 16:02:45.276695 (Thread-113): Parsing macros/etc/query.sql
2020-11-18 16:02:45.278775 (Thread-113): Parsing macros/etc/datetime.sql
2020-11-18 16:02:45.300280 (Thread-113): Parsing macros/etc/get_custom_alias.sql
2020-11-18 16:02:45.302138 (Thread-113): Parsing macros/etc/is_incremental.sql
2020-11-18 16:02:45.305290 (Thread-113): Parsing macros/etc/get_custom_schema.sql
2020-11-18 16:02:45.313691 (Thread-113): Parsing macros/dummy_coalesce_value.sql
2020-11-18 16:02:45.327621 (Thread-113): Parsing macros/enabled_vars.sql
2020-11-18 16:02:45.336830 (Thread-113): Parsing macros/_get_utils_namespaces.sql
2020-11-18 16:02:45.345705 (Thread-113): Parsing macros/remove_prefix_from_columns.sql
2020-11-18 16:02:45.357915 (Thread-113): Parsing macros/generate_columns_macro.sql
2020-11-18 16:02:45.373482 (Thread-113): Parsing macros/timestamp_add.sql
2020-11-18 16:02:45.388624 (Thread-113): Parsing macros/fill_staging_columns.sql
2020-11-18 16:02:45.398519 (Thread-113): Parsing macros/get_columns_for_macro.sql
2020-11-18 16:02:45.418194 (Thread-113): Parsing macros/string_agg.sql
2020-11-18 16:02:45.427900 (Thread-113): Parsing macros/array_agg.sql
2020-11-18 16:02:45.442105 (Thread-113): Parsing macros/union_relations.sql
2020-11-18 16:02:45.610118 (Thread-113): Acquiring new bigquery connection "model.github_source.github_pull_request_reviewers".
2020-11-18 16:02:46.454127 (Thread-115): handling status request
2020-11-18 16:02:46.454881 (Thread-115): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc31f4c88>]}
2020-11-18 16:02:46.464652 (Thread-115): sending response (<Response 12537 bytes [200 OK]>) to 10.0.14.29
2020-11-18 16:02:56.837832 (Thread-116): handling status request
2020-11-18 16:02:56.838519 (Thread-116): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc31a5b38>]}
2020-11-18 16:02:56.850314 (Thread-116): sending response (<Response 12537 bytes [200 OK]>) to 10.0.14.186
2020-11-18 16:03:15.350407 (Thread-117): handling status request
2020-11-18 16:03:15.351088 (Thread-117): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2fab160>]}
2020-11-18 16:03:15.360263 (Thread-117): sending response (<Response 12537 bytes [200 OK]>) to 10.0.37.56
2020-11-18 16:03:17.586073 (Thread-118): handling status request
2020-11-18 16:03:17.586781 (Thread-118): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2f86208>]}
2020-11-18 16:03:17.611514 (Thread-118): sending response (<Response 12537 bytes [200 OK]>) to 10.0.23.22
2020-11-18 16:03:56.088700 (Thread-119): handling status request
2020-11-18 16:03:56.089242 (Thread-119): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc323c128>]}
2020-11-18 16:03:56.094803 (Thread-119): sending response (<Response 12537 bytes [200 OK]>) to 10.0.37.56
2020-11-18 16:03:56.218283 (Thread-120): handling ps request
2020-11-18 16:03:56.218806 (Thread-120): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc31c8828>]}
2020-11-18 16:03:56.222784 (Thread-120): sending response (<Response 3320 bytes [200 OK]>) to 10.0.18.208
2020-11-18 16:03:56.601531 (Thread-121): handling poll request
2020-11-18 16:03:56.602067 (Thread-121): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc31f4710>]}
2020-11-18 16:03:56.791858 (Thread-121): sending response (<Response 1322742 bytes [200 OK]>) to 10.0.3.20
2020-11-18 16:03:57.226410 (Thread-122): handling status request
2020-11-18 16:03:57.226912 (Thread-122): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc323ceb8>]}
2020-11-18 16:03:57.228564 (Thread-122): Checking header 'user-agent' tracing in whitelist set(), 24 additional messages skipped
2020-11-18 16:03:57.260980 (Thread-122): writing 1 spans (enabled:True), 40 additional messages skipped
2020-11-18 16:03:57.261271 (Thread-122): 
      name requests.request
        id 13518069016340663879
  trace_id 253221004891538136
 parent_id None
   service requests
  resource requests.request
      type http
     start 1605715437.228239
       end 1605715437.260849
  duration 0.032610s
     error 0
      tags 
           http.method:POST
           http.status_code:200
           http.url:https://fishtownanalytics.sinter-collect.com/com.snowplowanalytics.snowplow/tp2
           runtime-id:fbe41a1a9fef4dc6b4d89ae108b31842, 40 additional messages skipped
2020-11-18 16:03:57.270804 (Thread-122): sending response (<Response 12537 bytes [200 OK]>) to 10.0.14.177
2020-11-18 16:03:57.332142 (AgentWriter): reported 1 traces in 0.00576s, 1 additional messages skipped
2020-11-18 16:03:57.332389 (AgentWriter): initialized RateSampler, sample 100% of traces, 63 additional messages skipped
2020-11-18 16:04:24.997306 (Thread-123): handling status request
2020-11-18 16:04:24.997883 (Thread-123): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3591898>]}
2020-11-18 16:04:25.003423 (Thread-123): sending response (<Response 12537 bytes [200 OK]>) to 10.0.44.246
2020-11-18 16:04:32.666933 (Thread-124): handling status request
2020-11-18 16:04:32.667496 (Thread-124): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc31c8128>]}
2020-11-18 16:04:32.672758 (Thread-124): sending response (<Response 12537 bytes [200 OK]>) to 10.0.41.79
2020-11-18 16:04:33.802298 (Thread-125): handling status request
2020-11-18 16:04:33.802924 (Thread-125): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc316d160>]}
2020-11-18 16:04:33.808464 (Thread-125): sending response (<Response 12537 bytes [200 OK]>) to 10.0.23.22
2020-11-18 16:04:49.645069 (Thread-126): handling status request
2020-11-18 16:04:49.645734 (Thread-126): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc358c898>]}
2020-11-18 16:04:49.654032 (Thread-126): sending response (<Response 12537 bytes [200 OK]>) to 10.0.5.154
2020-11-18 16:04:49.664483 (Thread-127): handling status request
2020-11-18 16:04:49.665211 (Thread-127): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2f90048>]}
2020-11-18 16:04:49.673191 (Thread-127): sending response (<Response 12537 bytes [200 OK]>) to 10.0.34.241
2020-11-18 16:04:49.979143 (Thread-128): handling cli_args request
2020-11-18 16:04:49.979678 (Thread-128): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc2fbf550>]}
2020-11-18 16:04:49.980130 (Thread-128): sending response (<Response 964 bytes [200 OK]>) to 10.0.21.190
2020-11-18 16:04:53.925564 (Thread-129): handling status request
2020-11-18 16:04:53.926065 (Thread-129): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc322c978>]}
2020-11-18 16:04:53.933017 (Thread-129): sending response (<Response 12537 bytes [200 OK]>) to 10.0.23.22
2020-11-18 16:05:00.124467 (Thread-130): handling status request
2020-11-18 16:05:00.124972 (Thread-130): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc3315860>]}
2020-11-18 16:05:00.130495 (Thread-130): sending response (<Response 12537 bytes [200 OK]>) to 10.0.34.241
2020-11-18 16:05:00.139469 (Thread-131): handling status request
2020-11-18 16:05:00.139933 (Thread-131): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc31c8a90>]}
2020-11-18 16:05:00.145137 (Thread-131): sending response (<Response 12537 bytes [200 OK]>) to 10.0.30.126
2020-11-18 16:05:00.411020 (Thread-132): handling cli_args request
2020-11-18 16:05:00.411536 (Thread-132): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc316da58>]}
2020-11-18 16:05:00.411937 (Thread-132): sending response (<Response 964 bytes [200 OK]>) to 10.0.23.22
2020-11-18 16:05:04.833013 (Thread-133): handling status request
2020-11-18 16:05:04.834034 (Thread-133): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc316def0>]}
2020-11-18 16:05:04.845595 (Thread-133): sending response (<Response 12537 bytes [200 OK]>) to 10.0.14.29
2020-11-18 16:05:19.922341 (Thread-134): handling status request
2020-11-18 16:05:19.923033 (Thread-134): Sending event: {'category': 'dbt', 'action': 'rpc_request', 'label': '81158aaf-969c-4160-99b9-54f6d9cb0f8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fedc31f41d0>]}
2020-11-18 16:05:19.931641 (Thread-134): sending response (<Response 12537 bytes [200 OK]>) to 10.0.23.22
